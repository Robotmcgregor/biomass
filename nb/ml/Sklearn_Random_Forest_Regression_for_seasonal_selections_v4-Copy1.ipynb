{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Random Forest Regression for seasonal selections v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load modules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following conditions apply:\n",
    "\n",
    " - env = biomass_zonal\n",
    " - data merged_slats_field_agb_dp1_start.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import ExtraTreesRegressor as etr\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.ensemble import AdaBoostRegressor as abr\n",
    "from sklearn.tree import DecisionTreeRegressor as dtr\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import plotting and stats modules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import scipy\n",
    "import scipy.stats as sc\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# stats module\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# from bokeh.io import output_notebook, output_file\n",
    "# from bokeh.plotting import figure, show, save\n",
    "#%matplotlib inline\n",
    "\n",
    "# Bokeh Libraries\n",
    "# from bokeh.plotting import figure, show\n",
    "# from bokeh.io import output_file\n",
    "#from bokeh.models import ColumnDataSource, NumeralTickFormatter, HoverTool\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "#sklearn.model_selection.cross_validate\n",
    "# from sklearn import cross_validation\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.cross_validation import KFold\n",
    "#import pickle5 as Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230213\n",
      "20230213_112618\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    " \n",
    "date_str = now.strftime(\"%Y%m%d\")\n",
    "date_time_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(date_str)\n",
    "print(date_time_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_str = \"20230201\"\n",
    "drive = \"D\"\n",
    "data_date = \"20230201\"\n",
    "# define output directory\n",
    "output_dir = r\"{0}:\\cdu\\data\\zonal_stats\\output\\{1}\".format(drive, date_str)\n",
    "export_dir = os.path.join(output_dir, date_time_str)\n",
    "\n",
    "# data dir\n",
    "dir_ = r\"{0}:\\cdu\\data\\zonal_stats\\output\\{1}\\ml_data_si_dir\".format(drive, data_date)\n",
    "\n",
    "index_ = 1\n",
    "\n",
    "runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_dir_fn(dir_):\n",
    "    \"\"\" Create a new directory if one does not already exist. \"\"\"\n",
    "    if not os.path.isdir(dir_):\n",
    "        os.mkdir(dir_)\n",
    "\n",
    "        \n",
    "def export_csv_fn(list_, dir_, file_name):\n",
    "    \n",
    "    \"\"\" Create and export path from directory and file name and exports csv with no dropping the index column. \"\"\"\n",
    "    \n",
    "    df_final = pd.concat(list_, axis =0)    \n",
    "    output_path = os.path.join(dir_, file_name)\n",
    "    df_final.to_csv(os.path.join(output_path), index=False)\n",
    "    print(\"File output to: \", output_path)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\cdu\\data\\zonal_stats\\output\\20230201\\ml_data_si_dir\\season_climate_fillna_mean_fms_NOT_si_reg.csv\n",
      "D:\\cdu\\data\\zonal_stats\\output\\20230201\\ml_data_si_dir\\r2_best_season_climate_fillna_fms_NOT_si_reg.csv\n",
      "D:\\cdu\\data\\zonal_stats\\output\\20230201\\ml_data_si_dir\\season_NO_climate_fillna_mean_fms_NOT_si_reg.csv\n",
      "D:\\cdu\\data\\zonal_stats\\output\\20230201\\ml_data_si_dir\\r2_best_season_NO_climate_fillna_fms_NOT_si_reg.csv\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "for f in glob(os.path.join(dir_, \"*reg.csv\")):\n",
    "    print(f)\n",
    "    file_list.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, file_name = os.path.split(file_list[index_])\n",
    "split_list = file_name.split(\".\")\n",
    "data_set = split_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r2_best_season_climate_fillna_fms_NOT_si_reg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set output file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_rf_reg_dir= os.path.join(output_dir, \"ml_rf_reg_dir\")\n",
    "plots_dir = os.path.join(ml_rf_reg_dir, \"ml_rf_reg_plots_dir\")\n",
    "all_plots_dir = os.path.join(plots_dir, \"all\")\n",
    "no_tern_plots_dir = os.path.join(plots_dir, \"no_tern\")\n",
    "mk_dir_fn(output_dir)\n",
    "mk_dir_fn(ml_rf_reg_dir)\n",
    "mk_dir_fn(plots_dir)\n",
    "mk_dir_fn(all_plots_dir)\n",
    "mk_dir_fn(no_tern_plots_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_rf_reg_dir= os.path.join(output_dir, \"ml_rf_reg_dir\")\n",
    "# mk_dir_fn(ml_rf_reg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set_dir = os.path.join(ml_rf_reg_dir, data_set)\n",
    "# mk_dir_fn(data_set_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots_dir = os.path.join(data_set_dir, \"plots\")\n",
    "# mk_dir_fn(plots_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_ml_rf_reg_dir = os.path.join(data_set_dir, date_time_str\n",
    "#                                     mk_dir_fn(all_plots_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\cdu\\\\data\\\\zonal_stats\\\\output\\\\20230213\\\\ml_rf_reg_dir\\\\r2_best_season_climate_fillna_fms_NOT_si_reg\\\\20230213_112618'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export_ml_rf_reg_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_rf_reg_dir= os.path.join(output_dir, \"ml_rf_reg_dir\")\n",
    "# data_set_dir = os.path.join(ml_rf_reg_dir, data_set)\n",
    "# export_ml_rf_reg_dir = os.path.join(data_set_dir, date_time_str)\n",
    "# # plots_dir = os.path.join(export_ml_rf_reg_dir, data_set)\n",
    "# all_plots_dir = os.path.join(export_ml_rf_reg_dir, \"all_plots\")\n",
    "# # no_tern_plots_dir = os.path.join(plots_dir, \"no_tern\")\n",
    "# # mk_dir_fn(output_dir)\n",
    "# mk_dir_fn(ml_rf_reg_dir)\n",
    "# mk_dir_fn(data_set_dir)\n",
    "# mk_dir_fn(export_ml_rf_reg_dir)\n",
    "# # mk_dir_fn(plots_dir)\n",
    "# mk_dir_fn(all_plots_dir)\n",
    "# # mk_dir_fn(no_tern_plots_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_ml_rf_reg_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_list[index_], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 180)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_list = ['dis_one', 'dis_two', 'dis_three', 'dis_four', 'dis_five', 'dis_six', 'dis_seven', 'dis_eight', 'dis_nine', 'dis_ten',\n",
    "#  'dka_jan', 'dka_feb', 'dka_mar', 'dka_april', 'dka_may', 'dka_june', 'dka_july', 'dka_aug', 'dka_sep', 'dka_oct', 'dka_nov', 'dka_dec',\n",
    "#     'stc_one', 'stc_two', 'stc_three', 'stc_four', 'stc_five', 'stc_six', 'stc_seven', 'stc_eight', 'stc_nine', 'stc_ten', 'stc_elev', \n",
    "#     'stc_twelv', 'stc_thirt', 'stc_fourt', 'stc_fift', 'stc_sixt', 'stc_sevent', 'dka_sum', 'dka_sum.1', 'dka_sum.2', 'dka_sum.3', \n",
    "#              'stc_sum', 'stc_sum.1', 'stc_sum.2', 'stc_sum.3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target', 'site', 'uid', 'date', 'bio_agb_kg1ha', 'b1_fpca2_0509_min', 'b1_fpca2_0509_max', 'b1_fpca2_0509_mean', 'b1_fpca2_0509_med', 'b1_fpca2_0509_std', 'b1_h99a_01122_min', 'b1_h99a_01122_max', 'b1_h99a_01122_mean', 'b1_h99a_01122_med', 'b1_h99a_01122_std', 'b1_dbi_0608_min', 'b1_dbi_0608_max', 'b1_dbi_0608_mean', 'b1_dbi_0608_med', 'b1_dbi_0608_std', 'b2_dbi_0608_min', 'b2_dbi_0608_max', 'b2_dbi_0608_mean', 'b2_dbi_0608_med', 'b2_dbi_0608_std', 'b3_dbi_0608_min', 'b3_dbi_0608_max', 'b3_dbi_0608_mean', 'b3_dbi_0608_med', 'b3_dbi_0608_std', 'b4_dbi_0608_min', 'b4_dbi_0608_max', 'b4_dbi_0608_mean', 'b4_dbi_0608_med', 'b4_dbi_0608_std', 'b5_dbi_0608_min', 'b5_dbi_0608_max', 'b5_dbi_0608_mean', 'b5_dbi_0608_med', 'b5_dbi_0608_std', 'b6_dbi_0608_min', 'b6_dbi_0608_max', 'b6_dbi_0608_mean', 'b6_dbi_0608_med', 'b6_dbi_0608_std', 'b1_dja_0305_min', 'b1_dja_0305_max', 'b1_dja_0305_mean', 'b1_dja_0305_med', 'b1_dja_0305_std', 'b1_dp1_0112_min', 'b1_dp1_0112_max', 'b1_dp1_0112_mean', 'b1_dp1_0112_std', 'b1_dp1_0112_med', 'b2_dp1_0112_min', 'b2_dp1_0112_max', 'b2_dp1_0112_mean', 'b2_dp1_0112_std', 'b2_dp1_0112_med', 'b3_dp1_0112_min', 'b3_dp1_0112_max', 'b3_dp1_0112_mean', 'b3_dp1_0112_med', 'b3_dp1_0112_std', 'b1_dp1_0509_min', 'b1_dp1_0509_max', 'b1_dp1_0509_mean', 'b1_dp1_0509_std', 'b1_dp1_0509_med', 'b2_dp1_0509_min', 'b2_dp1_0509_max', 'b2_dp1_0509_mean', 'b2_dp1_0509_std', 'b2_dp1_0509_med', 'b3_dp1_0509_min', 'b3_dp1_0509_max', 'b3_dp1_0509_mean', 'b3_dp1_0509_med', 'b3_dp1_0509_std', 'b1_dim_0305_min', 'b1_dim_0305_max', 'b1_dim_0305_mean', 'b1_dim_0305_med', 'b1_dim_0305_std', 'b2_dim_0305_min', 'b2_dim_0305_max', 'b2_dim_0305_mean', 'b2_dim_0305_med', 'b2_dim_0305_std', 'b3_dim_0305_min', 'b3_dim_0305_max', 'b3_dim_0305_mean', 'b3_dim_0305_med', 'b3_dim_0305_std', 'b1_dim_0608_min', 'b1_dim_0608_max', 'b1_dim_0608_mean', 'b1_dim_0608_med', 'b1_dim_0608_std', 'b2_dim_0608_min', 'b2_dim_0608_max', 'b2_dim_0608_mean', 'b2_dim_0608_med', 'b2_dim_0608_std', 'b3_dim_0608_min', 'b3_dim_0608_max', 'b3_dim_0608_mean', 'b3_dim_0608_med', 'b3_dim_0608_std', 'b1_dim_0911_min', 'b1_dim_0911_max', 'b1_dim_0911_mean', 'b1_dim_0911_med', 'b1_dim_0911_std', 'b2_dim_0911_min', 'b2_dim_0911_max', 'b2_dim_0911_mean', 'b2_dim_0911_med', 'b2_dim_0911_std', 'b3_dim_0911_min', 'b3_dim_0911_max', 'b3_dim_0911_mean', 'b3_dim_0911_med', 'b3_dim_0911_std', 'b1_dim_1202_min', 'b1_dim_1202_max', 'b1_dim_1202_mean', 'b1_dim_1202_med', 'b1_dim_1202_std', 'b2_dim_1202_min', 'b2_dim_1202_max', 'b2_dim_1202_mean', 'b2_dim_1202_med', 'b2_dim_1202_std', 'b3_dim_1202_min', 'b3_dim_1202_max', 'b3_dim_1202_mean', 'b3_dim_1202_med', 'b3_dim_1202_std', 'rain_d_mean', 'et_ma_mean', 'et_mp_mean', 'et_mw_mean', 'et_sc_mean', 'et_tc_mean', 'evp_ml_mean', 'evp_s_mean', 'tmax_mean', 'tmin_mean', 'rain_m_mean', 'mslp_mean', 'rad_mean', 'rh_tmax_mean', 'rh_tmin_mean', 'vp_mean', 'vp_d_mean', 'ratio32m', 'ratio42m', 'ratio43m', 'ratio52m', 'ratio53m', 'ratio54m', 'ratio62m', 'ratio63m', 'ratio64m', 'ratio65m', 'GSAVIm', 'GNDVIm', 'CVIm', 'NDGIm', 'RIm', 'NBRm', 'NDIIm', 'GDVIm', 'MSAVIm', 'DVIm', 'SAVIm', 'NDVIm', 'MSRm']\n"
     ]
    }
   ],
   "source": [
    "print(list(df2.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(value_x, value_y, value_a, value_b, out_file):\n",
    "    # Output to file\n",
    "    output_file(out_file, \n",
    "                title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")))\n",
    "\n",
    "\n",
    "\n",
    "    #Specify the selection tools to be made available\n",
    "    select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'zoom_in', 'zoom_out', 'wheel_zoom', 'reset']\n",
    "\n",
    "    #print(test)\n",
    "    # Format the tooltip\n",
    "    tooltips = [\n",
    "                ('Site', '@site'),\n",
    "                ('Date', '@date'),\n",
    "                (value_x, '@{0}'.format(value_x)),\n",
    "                (value_y, '@{0}'.format(value_y)),   \n",
    "                (value_a, '@{0}'.format(value_a)),\n",
    "                (value_b, '@{0}'.format(value_b)) \n",
    "               ]\n",
    "\n",
    "    # Create the figure\n",
    "    fig = figure(plot_height=400,\n",
    "                 plot_width=1500,\n",
    "                 y_axis_label= value_y.replace(\"_\", \" \"), \n",
    "                 x_axis_label= value_x.replace(\"_\", \" \"),\n",
    "                 title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")),\n",
    "                 toolbar_location='below',\n",
    "                 tools=select_tools)\n",
    "\n",
    "    # # Format the y-axis tick label\n",
    "    fig.yaxis[0].formatter = NumeralTickFormatter(format='0')\n",
    "\n",
    "    # Add square representing each site\n",
    "    fig.square(x= value_x,\n",
    "               y= value_y,\n",
    "               source=df2.round(4),\n",
    "               size=5,\n",
    "               color='royalblue',\n",
    "               selection_color='deepskyblue',\n",
    "               nonselection_color='lightgray',\n",
    "               nonselection_alpha=0.3)\n",
    "\n",
    "    # Add the HoverTool to the figure\n",
    "    fig.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "    # Visualize\n",
    "    save(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot exported to: D:\\cdu\\data\\zonal_stats\\output\\20230213\\ml_rf_reg_dir\\ml_rf_reg_plots_dir\\all\\all_sites_target_b1_fpca2_0509_min.html\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-9c68732d1ff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mout_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_plots_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'all_sites_{0}_{1}.html'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Plot exported to: {out_file}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msave_fig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-55-a824bd3aac9c>\u001b[0m in \u001b[0;36msave_fig\u001b[1;34m(value_x, value_y, value_a, value_b, out_file)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msave_fig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Output to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     output_file(out_file, \n\u001b[0m\u001b[0;32m      4\u001b[0m                 title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")))\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_file' is not defined"
     ]
    }
   ],
   "source": [
    "column_list = df2.columns.to_list()\n",
    "y_list = column_list[5:]\n",
    "value_x = column_list[:1][0]\n",
    "\n",
    "value_a = 'date'\n",
    "value_b = 'b1_fpca2_0509_mean'\n",
    "\n",
    "\n",
    "for i in y_list:\n",
    "    value_y = i\n",
    "    \n",
    "    out_file = os.path.join(all_plots_dir,'all_sites_{0}_{1}.html'.format(value_x, value_y))\n",
    "    print(f\"Plot exported to: {out_file}\")\n",
    "    save_fig(value_x, value_y, value_a, value_b, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predicted value is x\n",
    "# value_x = 'bio_agb_kg1ha'\n",
    "# # variable is y\n",
    "# value_y = \"b1_h99a_01122_mean\"\n",
    "# value_a = 'date'\n",
    "# value_b = 'b1_fpca2_0509_mean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(value_x, value_y, value_a, value_b, out_file):\n",
    "    # Output to file\n",
    "    output_file(out_file, title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), \n",
    "                                                                          value_y.replace(\"_\", \" \")))\n",
    "\n",
    "\n",
    "\n",
    "    #Specify the selection tools to be made available\n",
    "    select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'zoom_in', 'zoom_out', 'wheel_zoom', 'reset']\n",
    "\n",
    "    #print(test)\n",
    "    # Format the tooltip\n",
    "    tooltips = [\n",
    "                ('Site', '@site'),\n",
    "                ('Date', '@date'),\n",
    "                (value_x, '@{0}'.format(value_x)),\n",
    "                (value_y, '@{0}'.format(value_y)),   \n",
    "                (value_a, '@{0}'.format(value_a)),\n",
    "                (value_b, '@{0}'.format(value_b)) \n",
    "               ]\n",
    "\n",
    "    # Create the figure\n",
    "    fig = figure(plot_height=400,\n",
    "                 plot_width=1500,\n",
    "                 y_axis_label= value_y.replace(\"_\", \" \"), \n",
    "                 x_axis_label= value_x.replace(\"_\", \" \"),\n",
    "                 title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")),\n",
    "                 toolbar_location='below',\n",
    "                 tools=select_tools)\n",
    "\n",
    "    # # Format the y-axis tick label\n",
    "    fig.yaxis[0].formatter = NumeralTickFormatter(format='0')\n",
    "\n",
    "    # Add square representing each site\n",
    "    fig.square(x= value_x,\n",
    "               y= value_y,\n",
    "               source=df2.round(4),\n",
    "               size=5,\n",
    "               color='royalblue',\n",
    "               selection_color='deepskyblue',\n",
    "               nonselection_color='lightgray',\n",
    "               nonselection_alpha=0.3)\n",
    "\n",
    "    # Add the HoverTool to the figure\n",
    "    fig.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "    # Visualize\n",
    "    save(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_fig(value_x, value_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\cdu\\data\\zonal_stats\\output\\20230213\\ml_rf_reg_dir\\r2_best_season_climate_fillna_fms_NOT_si_reg\\plots\\all_sites_target_b1_fpca2_0509_min.html\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-adc019b7a257>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mout_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplots_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'all_sites_{0}_{1}.html'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msave_fig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-38946798ea36>\u001b[0m in \u001b[0;36msave_fig\u001b[1;34m(value_x, value_y, value_a, value_b, out_file)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msave_fig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Output to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     output_file(out_file, title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), \n\u001b[0m\u001b[0;32m      4\u001b[0m                                                                           value_y.replace(\"_\", \" \")))\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_file' is not defined"
     ]
    }
   ],
   "source": [
    "column_list = df2.columns.to_list()\n",
    "y_list = column_list[5:]\n",
    "value_x = column_list[:1][0]\n",
    "\n",
    "value_a = 'date'\n",
    "value_b = 'b1_fpca2_0509_mean'\n",
    "\n",
    "\n",
    "for i in y_list:\n",
    "    value_y = i\n",
    "    \n",
    "    out_file = os.path.join(plots_dir,'all_sites_{0}_{1}.html'.format(value_x, value_y))\n",
    "    print(out_file)\n",
    "    save_fig(value_x, value_y, value_a, value_b, out_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-efeef7d60a66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m output_file(out_file, title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), \n\u001b[0m\u001b[0;32m      2\u001b[0m                                                                           value_y.replace(\"_\", \" \")))\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_file' is not defined"
     ]
    }
   ],
   "source": [
    "output_file(out_file, title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), \n",
    "                                                                          value_y.replace(\"_\", \" \")))\n",
    "\n",
    "\n",
    "\n",
    "#Specify the selection tools to be made available\n",
    "select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'zoom_in', 'zoom_out', 'wheel_zoom', 'reset']\n",
    "\n",
    "#print(test)\n",
    "# Format the tooltip\n",
    "tooltips = [\n",
    "            ('Site', '@site'),\n",
    "            ('Date', '@date'),\n",
    "            (value_x, '@{0}'.format(value_x)),\n",
    "            (value_y, '@{0}'.format(value_y)),   \n",
    "            (value_a, '@{0}'.format(value_a)),\n",
    "            (value_b, '@{0}'.format(value_b)) \n",
    "           ]\n",
    "\n",
    "# Create the figure\n",
    "fig = figure(plot_height=400,\n",
    "             plot_width=1500,\n",
    "             y_axis_label= value_y.replace(\"_\", \" \"), \n",
    "             x_axis_label= value_x.replace(\"_\", \" \"),\n",
    "             title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")),\n",
    "             toolbar_location='below',\n",
    "             tools=select_tools)\n",
    "\n",
    "# # Format the y-axis tick label\n",
    "fig.yaxis[0].formatter = NumeralTickFormatter(format='0')\n",
    "\n",
    "# Add square representing each site\n",
    "fig.square(x= value_x,\n",
    "           y= value_y,\n",
    "           source=df2.round(4),\n",
    "           size=5,\n",
    "           color='royalblue',\n",
    "           selection_color='deepskyblue',\n",
    "           nonselection_color='lightgray',\n",
    "           nonselection_alpha=0.3)\n",
    "\n",
    "# Add the HoverTool to the figure\n",
    "fig.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "# Visualize\n",
    "save(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop AGB numbers which are high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop the 7 tern sites that apear to be outliers\n",
    "# df3 =df2[df2[value_x] <= 100000]\n",
    "# df3.to_csv(os.path.join(output_dir, \"{0}_lt_100000.csv\".format(value_x)))\n",
    "# drop_sites =df2[df2[value_x] > 100000]\n",
    "# drop_sites.value_counts(['site', value_x, value_y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Output to file\n",
    "# output_file(os.path.join(output_, 'TERN7_removed_sites_{0}_{1}.html'.format(value_x, value_y)),\n",
    "#             title='Seven TERN sites removed - relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")))\n",
    "\n",
    "\n",
    "# #Specify the selection tools to be made available\n",
    "# select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'zoom_in', 'zoom_out', 'wheel_zoom', 'reset']\n",
    "\n",
    "# # Format the tooltip\n",
    "# tooltips = [\n",
    "#             ('Site', '@site'),\n",
    "#             ('Date', '@date'),\n",
    "#             (value_x, '@{0}'.format(value_x)),\n",
    "#             (value_y, '@{0}'.format(value_y)),\n",
    "#             (value_a, '@{0}'.format(value_a)),\n",
    "#             (value_b, '@{0}'.format(value_b)) \n",
    "#            ]\n",
    "\n",
    "# # Create the figure\n",
    "# fig = figure(plot_height=400,\n",
    "#              plot_width=1500,\n",
    "#              y_axis_label= value_y.replace(\"_\", \" \"), \n",
    "#              x_axis_label= value_x.replace(\"_\", \" \"),\n",
    "#              title='Seven TERN sites removed - relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")),\n",
    "#              toolbar_location='below',\n",
    "#              tools=select_tools)\n",
    "\n",
    "# # # Format the y-axis tick label\n",
    "# fig.yaxis[0].formatter = NumeralTickFormatter(format='0')\n",
    "\n",
    "# # Add square representing each site\n",
    "# fig.square(x= value_x,\n",
    "#            y= value_y,\n",
    "#            source=df3,\n",
    "#            size=5,\n",
    "#            color='royalblue',\n",
    "#            selection_color='deepskyblue',\n",
    "#            nonselection_color='lightgray',\n",
    "#            nonselection_alpha=0.3)\n",
    "\n",
    "# # Add the HoverTool to the figure\n",
    "# fig.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "# # Visualize\n",
    "# show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the TERN sites for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop the TERN sites due to \n",
    "# df4=df3[df3.site.apply(lambda x: len(str(x))<=9)]\n",
    "# df4.to_csv(os.path.join(output_dir, \"{0}_NTG_only.csv\".format(value_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_list = df4.columns.to_list()\n",
    "# y_list = column_list[5:]\n",
    "# value_x = column_list[:1][0]\n",
    "\n",
    "# value_a = 'date'\n",
    "# value_b = 'b1_fpca2_0509_mean'\n",
    "\n",
    "\n",
    "# for i in y_list:\n",
    "#     value_y = i\n",
    "    \n",
    "#     out_file = os.path.join(no_tern_plots_dir,'no_tern_sites_{0}_{1}.html'.format(value_x, value_y))\n",
    "#     save_fig(value_x, value_y, value_a, value_b, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which data set to run the models from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df2\n",
    "# df_ml = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_ml.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some of the unwanted values\n",
    "df_ml.drop(['site', 'uid', 'date', 'bio_agb_kg1ha'], axis=1, inplace=True) # 'date',\n",
    "#df_ml.drop(['fpca2_imdate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qty of 0 values dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = df_ml\n",
    "model_data_name = \"all_values\"\n",
    "\n",
    "# ## Filter out all taregt == 0 values\n",
    "# model_data = df_ml[df_ml['target']>0.0]\n",
    "# model_data_name = \"no0_values\"\n",
    "\n",
    "# ## Select a randon number of 0 values\n",
    "# n = 3\n",
    "# agb_0 = df_ml[df_ml['target']==0.0].sample(n)\n",
    "# model_data = pd.concat([df_ml[df_ml['target']>0.0], agb_0])\n",
    "# model_data_name = f\"s{n}_0_values\"\n",
    "\n",
    "\n",
    "model_outputs = os.path.join(export_ml_rf_reg_dir, f\"{model_data_name}\")\n",
    "mk_dir_fn(model_outputs)\n",
    "\n",
    "print(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define if you are using all variabes or selected variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plots with error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in model_data.columns[1:]:\n",
    "    print(i)\n",
    "    value_x = 'target'\n",
    "    value_y_loop = str(i)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # left plot\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.regplot(model_data[value_x], model_data[value_y_loop], line_kws={\"color\":\"red\"})\n",
    "    plt.xlabel(value_x)\n",
    "    plt.ylabel(value_y_loop)\n",
    "    plt.title(\"Regression {0} and {1}\".format(value_x, value_y_loop))\n",
    "    \n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(model_data[value_x], model_data[value_y_loop])\n",
    "\n",
    "    print(\"slope: \", slope)\n",
    "    print(\"intersept: \", intercept)\n",
    "    print(\"r2: \", r_value)\n",
    "    print(\"P_value: \", p_value)\n",
    "    print(\"std error: \", std_err)\n",
    "\n",
    "    # right plot\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.regplot(model_data[value_x], model_data[value_y_loop], lowess=True, line_kws={\"color\":\"green\"})\n",
    "    plt.xlabel(value_x)\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.title(\"Residual Error {0} and {1}\".format(value_x, value_y_loop))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#     slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df[value_x], df[value_y])\n",
    "\n",
    "#     print(\"slope: \", slope)\n",
    "#     print(\"intersept: \", intercept)\n",
    "#     print(\"r2: \", r_value)\n",
    "#     print(\"P_value: \", p_value)\n",
    "#     print(\"std error: \", std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_x = 'bio_agb_kg1ha'\n",
    "# value_y = 'b2_dbi_mean'\n",
    "sns.regplot(x= value_x, y=value_y, data=df)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df[value_x], df[value_y])\n",
    "\n",
    "print(\"slope: \", slope)\n",
    "print(\"intersept: \", intercept)\n",
    "print(\"r2: \", r_value)\n",
    "print(\"P_value: \", p_value)\n",
    "print(\"std error: \", std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_x = 'bio_agb_kg1ha'\n",
    "# value_y = 'b3_dbi_mean'\n",
    "sns.scatterplot(x= value_x, y=value_y, data=df)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df[value_x], df[value_y])\n",
    "\n",
    "print(\"slope: \", slope)\n",
    "print(\"intersept: \", intercept)\n",
    "print(\"r2: \", r_value)\n",
    "print(\"P_value: \", p_value)\n",
    "print(\"std error: \", std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# randomly split data into train and test datasets, the user needs to define the variables \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m xdata1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_data\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m ydata1 \u001b[38;5;241m=\u001b[39m model_data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m ydata2 \u001b[38;5;241m=\u001b[39m ydata1\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_data' is not defined"
     ]
    }
   ],
   "source": [
    "# randomly split data into train and test datasets, the user needs to define the variables \n",
    "xdata1 = model_data.iloc[:, 1:].astype('float32')\n",
    "ydata1 = model_data[[\"target\"]].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata = ydata2.ravel()\n",
    "\n",
    "X_1, X_2, y_1, y_2 = train_test_split(xdata1, ydata, train_size=0.70)  \n",
    "         \n",
    "print(X_1.shape, y_1.shape)\n",
    "print(X_2.shape, y_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot up Histograms of  train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(y_1)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(y_2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterise the Random Forest Regressor alogorthim\n",
    "\n",
    "for details see: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 300\n",
    "rs = 1\n",
    "maxd = 4\n",
    "\n",
    "rng = np.random.RandomState(rs)\n",
    "rfrModel_1 = abr(dtr(max_depth=maxd), n_estimators=n_est, random_state=rng)\n",
    "print(rfrModel_1)\n",
    "mdl = \"abr\"\n",
    "str_model = f\"rf_{abr}_{model_data_name}_n_est_{n_est}_rs_{rs}_maxd_{maxd}_{date_time_str}\"\n",
    "print(str_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 100\n",
    "lr=0.1\n",
    "rs = 1\n",
    "maxd = 4\n",
    "loss = 'squared_error'\n",
    "\n",
    "rfrModel_1 = gbr(n_estimators=n_est, learning_rate=lr, max_depth=maxd, random_state=1, loss=loss)\n",
    "print(rfrModel_1)\n",
    "mdl = \"gbr\"\n",
    "str_model = f\"rf_{mdl}_{model_data_name}_n_est_{n_est}_lr{lr}_{loss}_rs_{rs}_maxd_{maxd}_{date_time_str}\"\n",
    "print(str_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfrModel_1 = etr(n_estimators=100, bootstrap=True, oob_score=True,  max_features='log2', min_samples_split=1,n_jobs=-1) \n",
    "# rfrModel_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rfrModel_1 = rfr(n_estimators=100, oob_score=True,  max_depth=None, max_features='log2', min_samples_split=1.0,n_jobs=-1) \n",
    "# rfrModel_1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfrModel_1 = rfr(n_estimators=100, oob_score=True) #,  max_depth=None, max_features='log2', min_samples_split=1.0,n_jobs=-1) \n",
    "# rfrModel_1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(X_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit random forest regressor model and compute variable importance score \n",
    "\n",
    "may need to restrict the number of variables for the bar graph to be legible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfrLCHM = rfrModel_1.fit(X_1, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rfrModel_1.feature_importances_\n",
    "\n",
    "### TRY THIS\n",
    "# use \"feature importance\" scores to see what the top 10 important features are\n",
    "fi = enumerate(rfrModel_1.feature_importances_)\n",
    "cols = xdata1.columns\n",
    "fiResult = [(value,cols[i]) for (i,value) in fi]\n",
    "#fiResult = [(value,cols[i]) for (i,value) in fi if value > 0.001]\n",
    "## Change the value 0.04 which we picked empirically to give us 10 variables\n",
    "## try running this code after changing the value up and down so you get more or less variables\n",
    "## do you see how this might be useful in refining the model?\n",
    "## Here is the code in case you mess up the line above\n",
    "## [(value,cols[i]) for (i,value) in fi if value > 0.04]\n",
    "#print fiResult\n",
    "r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "# print(r2)\n",
    "# print('Fitted model r2 =' ,  format(rfrLCHM.score(X_1, y_1), '.2f'))\n",
    "# print('Fitted model mse =', format(np.mean((y_1 - rfrLCHM.predict(X_1))**2), '.2f'))\n",
    "# print('n =', len(y_1))\n",
    "plt.scatter(rfrLCHM.predict(X_1), y_1,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [0,35000]\n",
    "y = [0,35000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "#plt.xlim(-1,35)\n",
    "#plt.ylim(-1,35)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(100, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(100, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(100, 27000, f'$n = {len(y_1)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiResult = np.array(fiResult)\n",
    "score = (fiResult[:,0])\n",
    "band = fiResult[:,1]\n",
    "a = fiResult[np.argsort(fiResult[:, 1])]\n",
    "\n",
    "df_band = pd.DataFrame(dict(band=band,n=score))\n",
    "df_band['n'].astype('float')\n",
    "dfsort = df_band.sort_values(['n'], ascending=[False])\n",
    "print(dfsort)\n",
    " \n",
    "## my complicated way to get the bar plot to sort in ascending order and display the assocated band names in the y axis\n",
    "dfsort2 = df_band.sort_values(['n'], ascending=[True])\n",
    "b = dfsort2[['band']]\n",
    "c = b.values.tolist()\n",
    "# convert the list of band names in the correct order to a string\n",
    "e = str(c)\n",
    "# strips all the rubbish from the string\n",
    "f = e.replace('[','').replace(']','').replace(\"'\",'').replace(\",\",' ')\n",
    "# convert the cleaned up string back into a list to plot the band names in the bar graph\n",
    "g = f.split()\n",
    " \n",
    "ind = np.arange(len(df_band))\n",
    "width = 0.4\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(ind, dfsort2.n, width, color='blue')\n",
    "ax.set(yticks=ind + width, yticklabels= g, ylim=[2*width - 1, len(df_band)])\n",
    "ax.set_xlabel('Performance')\n",
    "ax.set_ylabel('Ranked variables')\n",
    "plt.xticks(rotation='vertical')\n",
    "ax.set_title('Variable Importance Rank')\n",
    "\n",
    "plt.show()\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_feature_importance_plot.jpg')\n",
    "fig.savefig(plot_out,dpi=600)# save out your figure to a pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsort['n'].astype('float')\n",
    "dfsort.info()\n",
    "dfsort['n'] = dfsort['n'].astype('float')\n",
    "dfsort.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bf_selection = 0.01\n",
    "df_var = dfsort[dfsort['n'] > num_bf_selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_var = df_var.band.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_var.insert(0, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_model_data = df_ml[column_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = select_model_data.corr()\n",
    "df_corr.to_csv(os.path.join(model_outputs, f'{str_model}_feature_imp_n_{num_bf_selection}_.csv'), index=False)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_imp_list = dfsort.band.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_imp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run same model and same parameters with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into train and test datasets, the user needs to define the variables \n",
    "xdata1 = select_model_data.iloc[:, 1:].astype('float32')\n",
    "ydata1 = select_model_data[[value_x]].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata = ydata2.ravel()\n",
    "\n",
    "X_1, X_2, y_1, y_2 = train_test_split(xdata1, ydata, train_size=0.70)  \n",
    "         \n",
    "print(X_1.shape, y_1.shape)\n",
    "print(X_2.shape, y_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mdl == \"abr\":\n",
    "    \n",
    "    rng = np.random.RandomState(rs)\n",
    "    rfrModel_1 = abr(dtr(max_depth=maxd), n_estimators=n_est, random_state=rng)\n",
    "    str_model = f\"rf_abr_{model_data_name}_slc_feat_n_est_{n_est}_rs_{rs}_maxd_{maxd}_{date_time_str}\"\n",
    "    print(str_model)\n",
    "\n",
    "\n",
    "elif mdl== gbr:\n",
    "    rfrModel_1 = gbr(n_estimators=n_est, learning_rate=lr, max_depth=maxd, random_state=1, loss=loss)\n",
    "    str_model = f\"rf_gbr_{model_data_name}_slc_feat_n_est_{n_est}_lr{lr}_{loss}_rs_{rs}_maxd_{maxd}_{date_time_str}\"\n",
    "    print(str_model)\n",
    "else:\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(X_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit random forest regressor model and compute variable importance score \n",
    "\n",
    "may need to restrict the number of variables for the bar graph to be legible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfrLCHM = rfrModel_1.fit(X_1, y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### good info on the feature importance score - http://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rfrModel_1.feature_importances_\n",
    "\n",
    "### TRY THIS\n",
    "# use \"feature importance\" scores to see what the top 10 important features are\n",
    "fi = enumerate(rfrModel_1.feature_importances_)\n",
    "cols = xdata1.columns\n",
    "fiResult = [(value,cols[i]) for (i,value) in fi]\n",
    "#fiResult = [(value,cols[i]) for (i,value) in fi if value > 0.001]\n",
    "## Change the value 0.04 which we picked empirically to give us 10 variables\n",
    "## try running this code after changing the value up and down so you get more or less variables\n",
    "## do you see how this might be useful in refining the model?\n",
    "## Here is the code in case you mess up the line above\n",
    "## [(value,cols[i]) for (i,value) in fi if value > 0.04]\n",
    "#print fiResult\n",
    "r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "# print(r2)\n",
    "# print('Fitted model r2 =' ,  format(rfrLCHM.score(X_1, y_1), '.2f'))\n",
    "# print('Fitted model mse =', format(np.mean((y_1 - rfrLCHM.predict(X_1))**2), '.2f'))\n",
    "# print('n =', len(y_1))\n",
    "plt.scatter(rfrLCHM.predict(X_1), y_1,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [0,35000]\n",
    "y = [0,35000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "#plt.xlim(-1,35)\n",
    "#plt.ylim(-1,35)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(100, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(100, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(100, 27000, f'$n = {len(y_1)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_select_feat_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiResult = np.array(fiResult)\n",
    "score = (fiResult[:,0])\n",
    "band = fiResult[:,1]\n",
    "a = fiResult[np.argsort(fiResult[:, 1])]\n",
    "\n",
    "df_band = pd.DataFrame(dict(band=band,n=score))\n",
    "df_band['n'].astype('float')\n",
    "dfsort = df_band.sort_values(['n'], ascending=[False])\n",
    "print(dfsort)\n",
    " \n",
    "## my complicated way to get the bar plot to sort in ascending order and display the assocated band names in the y axis\n",
    "dfsort2 = df_band.sort_values(['n'], ascending=[True])\n",
    "b = dfsort2[['band']]\n",
    "c = b.values.tolist()\n",
    "# convert the list of band names in the correct order to a string\n",
    "e = str(c)\n",
    "# strips all the rubbish from the string\n",
    "f = e.replace('[','').replace(']','').replace(\"'\",'').replace(\",\",' ')\n",
    "# convert the cleaned up string back into a list to plot the band names in the bar graph\n",
    "g = f.split()\n",
    " \n",
    "ind = np.arange(len(df_band))\n",
    "width = 0.4\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(ind, dfsort2.n, width, color='blue')\n",
    "ax.set(yticks=ind + width, yticklabels= g, ylim=[2*width - 1, len(df_band)])\n",
    "ax.set_xlabel('Performance')\n",
    "ax.set_ylabel('Ranked variables')\n",
    "plt.xticks(rotation='vertical')\n",
    "ax.set_title('Variable Importance Rank')\n",
    "\n",
    "plt.show()\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_select_features_feature_importance_plot.jpg')\n",
    "fig.savefig(plot_out,dpi=600)# save out your figure to a pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the selected model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(y2_predict, y_2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_predict = rfrLCHM.predict(X_2)\n",
    "\n",
    "print('Predicted data r2 =', rfrLCHM.score(X_2, y_2))\n",
    "print('MSE =', format(np.mean((y_2 - rfrLCHM.predict(X_2))** 2), '.3f'))\n",
    "print('RMSE =', format(np.sqrt(np.mean((y2_predict - y_2) ** 2)), '.3f'))\n",
    "#print 'explained_var =',format(explained_variance_score(y_2, y2_predict),  '.3f') \n",
    "print('bias =' , format(np.mean(y_2) - np.mean(y2_predict), '.3f'))\n",
    "print('n =' , len(y_2))\n",
    "\n",
    "\n",
    "r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "rmse = round(np.sqrt(np.mean((y2_predict - y_2) ** 2)), 2)\n",
    "bias = round(np.mean(y_2) - np.mean(y2_predict), 2)\n",
    "\n",
    "plt.scatter(y2_predict, y_2 ,s=10, c='b', marker='o')\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,40000]\n",
    "y = [-1,40000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,40000)\n",
    "plt.ylim(-1, 40000)\n",
    "plt.ylabel('Observed mean AGB')\n",
    "plt.xlabel('Predicted mean AGB')\n",
    "# 1 for 1 line\n",
    "\n",
    "#adding text inside the plot\n",
    "plt.text(300, 37000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(300, 35000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(300, 33000, f'$RMSE = {mse}$', fontsize = 12)\n",
    "plt.text(300, 31000, f'$Bias = {bias}$', fontsize = 12)\n",
    "plt.text(300, 29000, f'$n = {len(y_1)}$', fontsize = 12)\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_test_data.jpg')\n",
    "fig.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = y2_predict\n",
    "y = y_2\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(x, y, c=z, s=0.8, edgecolor='')\n",
    "\n",
    "# # data for the 1 for 1 line\n",
    "# a = [-1,25]\n",
    "# b = [-1,25]\n",
    "\n",
    "# #sets the limits of the axis\n",
    "# plt.xlim(-1,25)\n",
    "# plt.ylim(-1,25)\n",
    "# plt.ylabel('Observed mean CHM')\n",
    "# plt.xlabel('Predicted mean CHM')\n",
    "# # 1 for 1 line\n",
    "# ax.plot(a, b, color = 'black')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP - do you realy want to save this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remember to change the cPickle file name !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save current fitted model and apply to unseen validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#rfrL8CHM = rfr()\n",
    "#rfrL8CHM.fit(X_1, y_1)\n",
    "\n",
    "pkl_out = os.path.join(model_outputs, f'rf_model_{str_model}')\n",
    "\n",
    "\n",
    "with open(pkl_out, 'wb') as f:\n",
    "    pickle.dump(rfrLCHM, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in unseen data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in your validation dataset which has never been seen by rfr model - NOTE in this example I am just reading the same data used to train the model\n",
    "new_data = select_model_data\n",
    "# df = pd.read_csv(csv_file, header=0)\n",
    "# df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = new_data.columns.tolist()\n",
    "c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df[(df['comp'] == 'l57')]\n",
    "df1 = new_data[(new_data['target'] > 0.01)]\n",
    "df1.dropna(inplace=True)\n",
    "print (df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[column_var].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata2 = df1[column_var].astype('float32')\n",
    "xdata2.drop(\"target\", axis=1, inplace=True)\n",
    "\n",
    "ydata1 = df1[['target']].astype('float32')\n",
    "\n",
    "ydata2 = ydata1.values\n",
    "\n",
    "ydata = ydata2.ravel()\n",
    "\n",
    "print(len(ydata1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_out, 'rb') as f:\n",
    "        rf = pickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print('Predicted data r2 =', rf.score(xdata2, ydata))\n",
    "print('MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f'))\n",
    "print('RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f'))\n",
    "print('explained_var =',format(explained_variance_score(ydata, predicted),  '.3f'))\n",
    "print('bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f'))\n",
    "print('n =' , len(ydata))\n",
    "\n",
    "r2 = round(rf.score(xdata2, ydata), 2)\n",
    "mse = round(np.mean((ydata - rf.predict(xdata2))** 2), 2)\n",
    "rmse = round(np.sqrt(np.mean((predicted - ydata) ** 2)), 2)\n",
    "exp_var = round(explained_variance_score(ydata, predicted), 2)\n",
    "bias = round(np.mean(ydata) - np.mean(predicted), 2)\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=8, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,40000]\n",
    "y = [-1,40000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 40000)\n",
    "plt.ylim(-1, 40000)\n",
    "\n",
    "#adding text inside the plot\n",
    "plt.text(300, 37000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(300, 35000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(300, 33000, f'$RMSE = {mse}$', fontsize = 12)\n",
    "plt.text(300, 31000, f'$Bias = {bias}$', fontsize = 12)\n",
    "plt.text(300, 29000, f'$Var = {exp_var}$', fontsize = 12)\n",
    "plt.text(300, 27000, f'$n = {len(y_1)}$', fontsize = 12)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_unseen_data.jpg')\n",
    "\n",
    "fig.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
