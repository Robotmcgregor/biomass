{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn_regression_models_for_seasonal_selections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.projectpro.io/article/multi-class-classification-python-example/547#mcetoc_1fpjsn4g8g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.educba.com/keras-sequential/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load modules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following conditions apply:\n",
    "\n",
    " - env = biomass_zonal\n",
    " - data merged_slats_field_agb_dp1_start.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.linear_model.ridge import KernelRidge\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import scipy\n",
    "import scipy.stats as sc\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230219\n",
      "20230219_092646\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    " \n",
    "date_str = now.strftime(\"%Y%m%d\")\n",
    "date_time_str = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(date_str)\n",
    "print(date_time_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_str = \"20230201\"\n",
    "drive = \"D\"\n",
    "data_date = \"20230205\"\n",
    "# define output directory\n",
    "output_dir = r\"{0}:\\cdu\\data\\zonal_stats\\output\\{1}\".format(drive, date_str)\n",
    "export_dir = os.path.join(output_dir, date_time_str)\n",
    "\n",
    "# data dir\n",
    "dir_ = r\"{0}:\\cdu\\data\\zonal_stats\\output\\{1}\\ml_data_si_dir\".format(drive, data_date)\n",
    "\n",
    "index_ = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_dir_fn(dir_):\n",
    "    \"\"\" Create a new directory if one does not already exist. \"\"\"\n",
    "    print(\"pathway \", dir_)\n",
    "    if not os.path.isdir(dir_):\n",
    "        os.mkdir(dir_)\n",
    "\n",
    "        \n",
    "def export_csv_fn(list_, dir_, file_name):\n",
    "    \n",
    "    \"\"\" Create and export path from directory and file name and exports csv with no dropping the index column. \"\"\"\n",
    "    \n",
    "    df_final = pd.concat(list_, axis =0)    \n",
    "    output_path = os.path.join(dir_, file_name)\n",
    "    df_final.to_csv(os.path.join(output_path), index=False)\n",
    "    print(\"File output to: \", output_path)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set output file locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\cdu\\data\\zonal_stats\\output\\20230205\\ml_data_si_dir\\s_mean_max_min_med_std__fnm_fms_si_reg.csv\n",
      "D:\\cdu\\data\\zonal_stats\\output\\20230205\\ml_data_si_dir\\r2_bs_mean_max_min_med_std__fnm_fms_si_reg.csv\n",
      "D:\\cdu\\data\\zonal_stats\\output\\20230205\\ml_data_si_dir\\s_mean_max_min_med_std_met_fnm_fms_si_reg.csv\n",
      "D:\\cdu\\data\\zonal_stats\\output\\20230205\\ml_data_si_dir\\r2_bs_mean_max_min_med_std_met_fnm_fms_si_reg.csv\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "for f in glob(os.path.join(dir_, \"*reg.csv\")):\n",
    "    print(f)\n",
    "    file_list.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, file_name = os.path.split(file_list[index_])\n",
    "split_list = file_name.split(\".\")\n",
    "data_set = split_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r2_bs_mean_max_min_med_std__fnm_fms_si_reg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_rf_reg_dir= os.path.join(output_dir, \"ml_reg_dir\")\n",
    "data_set_dir= os.path.join(ml_rf_reg_dir, \"data_set\")\n",
    "export_ml_rf_reg_dir = os.path.join(data_set_dir, date_time_str)\n",
    "# plots_dir = os.path.join(export_ml_rf_reg_dir, data_set)\n",
    "all_plots_dir = os.path.join(export_ml_rf_reg_dir, \"all_plots\")\n",
    "# no_tern_plots_dir = os.path.join(plots_dir, \"no_tern\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathway  D:\\cdu\\data\\zonal_stats\\output\\20230219\n",
      "pathway  D:\\cdu\\data\\zonal_stats\\output\\20230219\\ml_reg_dir\n",
      "pathway  D:\\cdu\\data\\zonal_stats\\output\\20230219\\ml_reg_dir\\data_set\n",
      "pathway  D:\\cdu\\data\\zonal_stats\\output\\20230219\\ml_reg_dir\\data_set\\20230219_092646\n",
      "pathway  D:\\cdu\\data\\zonal_stats\\output\\20230219\\ml_reg_dir\\data_set\\20230219_092646\\all_plots\n"
     ]
    }
   ],
   "source": [
    "mk_dir_fn(output_dir)\n",
    "mk_dir_fn(ml_rf_reg_dir)\n",
    "mk_dir_fn(data_set_dir)\n",
    "mk_dir_fn(export_ml_rf_reg_dir)\n",
    "# mk_dir_fn(plots_dir)\n",
    "mk_dir_fn(all_plots_dir)\n",
    "# mk_dir_fn(no_tern_plots_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\cdu\\\\data\\\\zonal_stats\\\\output\\\\20230219\\\\ml_reg_dir\\\\data_set\\\\20230219_092646'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_ml_rf_reg_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_list[index_], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>site</th>\n",
       "      <th>uid</th>\n",
       "      <th>date</th>\n",
       "      <th>b1_fpca2_0509_min</th>\n",
       "      <th>b1_fpca2_0509_max</th>\n",
       "      <th>b1_fpca2_0509_mean</th>\n",
       "      <th>b1_fpca2_0509_med</th>\n",
       "      <th>b1_fpca2_0509_std</th>\n",
       "      <th>b1_h99a_01122_min</th>\n",
       "      <th>...</th>\n",
       "      <th>NDGIm</th>\n",
       "      <th>RIm</th>\n",
       "      <th>NBRm</th>\n",
       "      <th>NDIIm</th>\n",
       "      <th>GDVIm</th>\n",
       "      <th>MSAVIm</th>\n",
       "      <th>DVIm</th>\n",
       "      <th>SAVIm</th>\n",
       "      <th>NDVIm</th>\n",
       "      <th>MSRm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>nt001</td>\n",
       "      <td>71</td>\n",
       "      <td>20110523</td>\n",
       "      <td>13.78</td>\n",
       "      <td>47.00</td>\n",
       "      <td>25.85</td>\n",
       "      <td>23.87</td>\n",
       "      <td>8.48</td>\n",
       "      <td>7.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-1797183</td>\n",
       "      <td>1797183</td>\n",
       "      <td>803085</td>\n",
       "      <td>-1648544</td>\n",
       "      <td>1653000</td>\n",
       "      <td>2108509</td>\n",
       "      <td>1334000</td>\n",
       "      <td>2374229</td>\n",
       "      <td>3891482</td>\n",
       "      <td>5080174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>barkely01</td>\n",
       "      <td>24</td>\n",
       "      <td>20111025</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-1237840</td>\n",
       "      <td>1237840</td>\n",
       "      <td>145478</td>\n",
       "      <td>-1258856</td>\n",
       "      <td>1100000</td>\n",
       "      <td>1063379</td>\n",
       "      <td>731000</td>\n",
       "      <td>1207466</td>\n",
       "      <td>1791228</td>\n",
       "      <td>1985065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>barkely04</td>\n",
       "      <td>27</td>\n",
       "      <td>20111026</td>\n",
       "      <td>2.12</td>\n",
       "      <td>6.42</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.47</td>\n",
       "      <td>1.22</td>\n",
       "      <td>5.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-1493838</td>\n",
       "      <td>1493838</td>\n",
       "      <td>965693</td>\n",
       "      <td>-982236</td>\n",
       "      <td>1174000</td>\n",
       "      <td>951763</td>\n",
       "      <td>677000</td>\n",
       "      <td>1068835</td>\n",
       "      <td>1504110</td>\n",
       "      <td>1636492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>barkely03</td>\n",
       "      <td>26</td>\n",
       "      <td>20111026</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.66</td>\n",
       "      <td>...</td>\n",
       "      <td>-1481481</td>\n",
       "      <td>1481481</td>\n",
       "      <td>-2046</td>\n",
       "      <td>-1713026</td>\n",
       "      <td>1178000</td>\n",
       "      <td>1068186</td>\n",
       "      <td>738000</td>\n",
       "      <td>1210101</td>\n",
       "      <td>1779171</td>\n",
       "      <td>1970149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>barkely02</td>\n",
       "      <td>25</td>\n",
       "      <td>20111026</td>\n",
       "      <td>2.12</td>\n",
       "      <td>13.78</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-1563211</td>\n",
       "      <td>1563211</td>\n",
       "      <td>758167</td>\n",
       "      <td>-969300</td>\n",
       "      <td>1320000</td>\n",
       "      <td>1195078</td>\n",
       "      <td>839000</td>\n",
       "      <td>1339257</td>\n",
       "      <td>1908119</td>\n",
       "      <td>2131007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>20805.22</td>\n",
       "      <td>ntadac0002</td>\n",
       "      <td>79</td>\n",
       "      <td>20160506</td>\n",
       "      <td>15.54</td>\n",
       "      <td>42.39</td>\n",
       "      <td>29.12</td>\n",
       "      <td>29.27</td>\n",
       "      <td>6.84</td>\n",
       "      <td>16.05</td>\n",
       "      <td>...</td>\n",
       "      <td>-652174</td>\n",
       "      <td>652174</td>\n",
       "      <td>4386747</td>\n",
       "      <td>1261845</td>\n",
       "      <td>1828000</td>\n",
       "      <td>3096442</td>\n",
       "      <td>1768000</td>\n",
       "      <td>3422819</td>\n",
       "      <td>6433770</td>\n",
       "      <td>11466633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>30472.45</td>\n",
       "      <td>ntaarp0001</td>\n",
       "      <td>75</td>\n",
       "      <td>20160602</td>\n",
       "      <td>27.61</td>\n",
       "      <td>38.92</td>\n",
       "      <td>34.75</td>\n",
       "      <td>34.33</td>\n",
       "      <td>3.24</td>\n",
       "      <td>17.31</td>\n",
       "      <td>...</td>\n",
       "      <td>-1485714</td>\n",
       "      <td>1485714</td>\n",
       "      <td>4017258</td>\n",
       "      <td>1123510</td>\n",
       "      <td>1746000</td>\n",
       "      <td>2727661</td>\n",
       "      <td>1590000</td>\n",
       "      <td>3059261</td>\n",
       "      <td>5686695</td>\n",
       "      <td>9070438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>24414.13</td>\n",
       "      <td>ntaarp0002</td>\n",
       "      <td>76</td>\n",
       "      <td>20160602</td>\n",
       "      <td>9.06</td>\n",
       "      <td>22.31</td>\n",
       "      <td>14.40</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.60</td>\n",
       "      <td>9.74</td>\n",
       "      <td>...</td>\n",
       "      <td>-2065698</td>\n",
       "      <td>2065698</td>\n",
       "      <td>2615783</td>\n",
       "      <td>222222</td>\n",
       "      <td>1810000</td>\n",
       "      <td>2372051</td>\n",
       "      <td>1483000</td>\n",
       "      <td>2650423</td>\n",
       "      <td>4370763</td>\n",
       "      <td>5977733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>17598.35</td>\n",
       "      <td>ntaarp0003</td>\n",
       "      <td>77</td>\n",
       "      <td>20160603</td>\n",
       "      <td>5.26</td>\n",
       "      <td>25.45</td>\n",
       "      <td>13.08</td>\n",
       "      <td>12.11</td>\n",
       "      <td>5.79</td>\n",
       "      <td>9.61</td>\n",
       "      <td>...</td>\n",
       "      <td>-1885790</td>\n",
       "      <td>1885790</td>\n",
       "      <td>2958064</td>\n",
       "      <td>395123</td>\n",
       "      <td>1691000</td>\n",
       "      <td>2284112</td>\n",
       "      <td>1407000</td>\n",
       "      <td>2574722</td>\n",
       "      <td>4401001</td>\n",
       "      <td>6037665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>9995.51</td>\n",
       "      <td>buff01</td>\n",
       "      <td>31</td>\n",
       "      <td>20210713</td>\n",
       "      <td>19.30</td>\n",
       "      <td>40.08</td>\n",
       "      <td>30.47</td>\n",
       "      <td>32.06</td>\n",
       "      <td>6.23</td>\n",
       "      <td>12.00</td>\n",
       "      <td>...</td>\n",
       "      <td>770925</td>\n",
       "      <td>-770925</td>\n",
       "      <td>5614599</td>\n",
       "      <td>2339640</td>\n",
       "      <td>2185000</td>\n",
       "      <td>3960474</td>\n",
       "      <td>2255000</td>\n",
       "      <td>4179538</td>\n",
       "      <td>7290656</td>\n",
       "      <td>15262347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target        site  uid      date  b1_fpca2_0509_min  b1_fpca2_0509_max  \\\n",
       "0       0.00       nt001   71  20110523              13.78              47.00   \n",
       "1       0.00   barkely01   24  20111025               0.75               2.87   \n",
       "2       0.00   barkely04   27  20111026               2.12               6.42   \n",
       "3       0.00   barkely03   26  20111026               0.75               3.29   \n",
       "4       0.00   barkely02   25  20111026               2.12              13.78   \n",
       "..       ...         ...  ...       ...                ...                ...   \n",
       "162 20805.22  ntadac0002   79  20160506              15.54              42.39   \n",
       "163 30472.45  ntaarp0001   75  20160602              27.61              38.92   \n",
       "164 24414.13  ntaarp0002   76  20160602               9.06              22.31   \n",
       "165 17598.35  ntaarp0003   77  20160603               5.26              25.45   \n",
       "166  9995.51      buff01   31  20210713              19.30              40.08   \n",
       "\n",
       "     b1_fpca2_0509_mean  b1_fpca2_0509_med  b1_fpca2_0509_std  \\\n",
       "0                 25.85              23.87               8.48   \n",
       "1                  1.69               1.49               0.70   \n",
       "2                  4.37               4.47               1.22   \n",
       "3                  1.82               1.64               0.70   \n",
       "4                  4.97               4.73               2.43   \n",
       "..                  ...                ...                ...   \n",
       "162               29.12              29.27               6.84   \n",
       "163               34.75              34.33               3.24   \n",
       "164               14.40              14.21               3.60   \n",
       "165               13.08              12.11               5.79   \n",
       "166               30.47              32.06               6.23   \n",
       "\n",
       "     b1_h99a_01122_min  ...    NDGIm      RIm     NBRm    NDIIm    GDVIm  \\\n",
       "0                 7.27  ... -1797183  1797183   803085 -1648544  1653000   \n",
       "1                 4.38  ... -1237840  1237840   145478 -1258856  1100000   \n",
       "2                 5.93  ... -1493838  1493838   965693  -982236  1174000   \n",
       "3                 3.66  ... -1481481  1481481    -2046 -1713026  1178000   \n",
       "4                 3.13  ... -1563211  1563211   758167  -969300  1320000   \n",
       "..                 ...  ...      ...      ...      ...      ...      ...   \n",
       "162              16.05  ...  -652174   652174  4386747  1261845  1828000   \n",
       "163              17.31  ... -1485714  1485714  4017258  1123510  1746000   \n",
       "164               9.74  ... -2065698  2065698  2615783   222222  1810000   \n",
       "165               9.61  ... -1885790  1885790  2958064   395123  1691000   \n",
       "166              12.00  ...   770925  -770925  5614599  2339640  2185000   \n",
       "\n",
       "      MSAVIm     DVIm    SAVIm    NDVIm      MSRm  \n",
       "0    2108509  1334000  2374229  3891482   5080174  \n",
       "1    1063379   731000  1207466  1791228   1985065  \n",
       "2     951763   677000  1068835  1504110   1636492  \n",
       "3    1068186   738000  1210101  1779171   1970149  \n",
       "4    1195078   839000  1339257  1908119   2131007  \n",
       "..       ...      ...      ...      ...       ...  \n",
       "162  3096442  1768000  3422819  6433770  11466633  \n",
       "163  2727661  1590000  3059261  5686695   9070438  \n",
       "164  2372051  1483000  2650423  4370763   5977733  \n",
       "165  2284112  1407000  2574722  4401001   6037665  \n",
       "166  3960474  2255000  4179538  7290656  15262347  \n",
       "\n",
       "[167 rows x 174 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope:  398.39405526585966\n",
      "intersept:  -1545.2575127961409\n",
      "r2:  0.6680461286822867\n",
      "P_value:  6.104388470146404e-23\n",
      "std error:  34.54675999706051\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "value_y = 'target'\n",
    "value_x = 'b1_fpca2_0509_max'\n",
    "sns.regplot(x= value_x, y=value_y, data=df)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df[value_x], df[value_y])\n",
    "\n",
    "print(\"slope: \", slope)\n",
    "print(\"intersept: \", intercept)\n",
    "print(\"r2: \", r_value)\n",
    "print(\"P_value: \", p_value)\n",
    "print(\"std error: \", std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables to plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which data set to run the models from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>site</th>\n",
       "      <th>uid</th>\n",
       "      <th>date</th>\n",
       "      <th>b1_fpca2_0509_min</th>\n",
       "      <th>b1_fpca2_0509_max</th>\n",
       "      <th>b1_fpca2_0509_mean</th>\n",
       "      <th>b1_fpca2_0509_med</th>\n",
       "      <th>b1_fpca2_0509_std</th>\n",
       "      <th>b1_h99a_01122_min</th>\n",
       "      <th>...</th>\n",
       "      <th>NDGIm</th>\n",
       "      <th>RIm</th>\n",
       "      <th>NBRm</th>\n",
       "      <th>NDIIm</th>\n",
       "      <th>GDVIm</th>\n",
       "      <th>MSAVIm</th>\n",
       "      <th>DVIm</th>\n",
       "      <th>SAVIm</th>\n",
       "      <th>NDVIm</th>\n",
       "      <th>MSRm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>nt001</td>\n",
       "      <td>71</td>\n",
       "      <td>20110523</td>\n",
       "      <td>13.78</td>\n",
       "      <td>47.00</td>\n",
       "      <td>25.85</td>\n",
       "      <td>23.87</td>\n",
       "      <td>8.48</td>\n",
       "      <td>7.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-1797183</td>\n",
       "      <td>1797183</td>\n",
       "      <td>803085</td>\n",
       "      <td>-1648544</td>\n",
       "      <td>1653000</td>\n",
       "      <td>2108509</td>\n",
       "      <td>1334000</td>\n",
       "      <td>2374229</td>\n",
       "      <td>3891482</td>\n",
       "      <td>5080174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>barkely01</td>\n",
       "      <td>24</td>\n",
       "      <td>20111025</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-1237840</td>\n",
       "      <td>1237840</td>\n",
       "      <td>145478</td>\n",
       "      <td>-1258856</td>\n",
       "      <td>1100000</td>\n",
       "      <td>1063379</td>\n",
       "      <td>731000</td>\n",
       "      <td>1207466</td>\n",
       "      <td>1791228</td>\n",
       "      <td>1985065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>barkely04</td>\n",
       "      <td>27</td>\n",
       "      <td>20111026</td>\n",
       "      <td>2.12</td>\n",
       "      <td>6.42</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.47</td>\n",
       "      <td>1.22</td>\n",
       "      <td>5.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-1493838</td>\n",
       "      <td>1493838</td>\n",
       "      <td>965693</td>\n",
       "      <td>-982236</td>\n",
       "      <td>1174000</td>\n",
       "      <td>951763</td>\n",
       "      <td>677000</td>\n",
       "      <td>1068835</td>\n",
       "      <td>1504110</td>\n",
       "      <td>1636492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>barkely03</td>\n",
       "      <td>26</td>\n",
       "      <td>20111026</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.66</td>\n",
       "      <td>...</td>\n",
       "      <td>-1481481</td>\n",
       "      <td>1481481</td>\n",
       "      <td>-2046</td>\n",
       "      <td>-1713026</td>\n",
       "      <td>1178000</td>\n",
       "      <td>1068186</td>\n",
       "      <td>738000</td>\n",
       "      <td>1210101</td>\n",
       "      <td>1779171</td>\n",
       "      <td>1970149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>barkely02</td>\n",
       "      <td>25</td>\n",
       "      <td>20111026</td>\n",
       "      <td>2.12</td>\n",
       "      <td>13.78</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-1563211</td>\n",
       "      <td>1563211</td>\n",
       "      <td>758167</td>\n",
       "      <td>-969300</td>\n",
       "      <td>1320000</td>\n",
       "      <td>1195078</td>\n",
       "      <td>839000</td>\n",
       "      <td>1339257</td>\n",
       "      <td>1908119</td>\n",
       "      <td>2131007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target       site  uid      date  b1_fpca2_0509_min  b1_fpca2_0509_max  \\\n",
       "0    0.00      nt001   71  20110523              13.78              47.00   \n",
       "1    0.00  barkely01   24  20111025               0.75               2.87   \n",
       "2    0.00  barkely04   27  20111026               2.12               6.42   \n",
       "3    0.00  barkely03   26  20111026               0.75               3.29   \n",
       "4    0.00  barkely02   25  20111026               2.12              13.78   \n",
       "\n",
       "   b1_fpca2_0509_mean  b1_fpca2_0509_med  b1_fpca2_0509_std  \\\n",
       "0               25.85              23.87               8.48   \n",
       "1                1.69               1.49               0.70   \n",
       "2                4.37               4.47               1.22   \n",
       "3                1.82               1.64               0.70   \n",
       "4                4.97               4.73               2.43   \n",
       "\n",
       "   b1_h99a_01122_min  ...    NDGIm      RIm    NBRm    NDIIm    GDVIm  \\\n",
       "0               7.27  ... -1797183  1797183  803085 -1648544  1653000   \n",
       "1               4.38  ... -1237840  1237840  145478 -1258856  1100000   \n",
       "2               5.93  ... -1493838  1493838  965693  -982236  1174000   \n",
       "3               3.66  ... -1481481  1481481   -2046 -1713026  1178000   \n",
       "4               3.13  ... -1563211  1563211  758167  -969300  1320000   \n",
       "\n",
       "    MSAVIm     DVIm    SAVIm    NDVIm     MSRm  \n",
       "0  2108509  1334000  2374229  3891482  5080174  \n",
       "1  1063379   731000  1207466  1791228  1985065  \n",
       "2   951763   677000  1068835  1504110  1636492  \n",
       "3  1068186   738000  1210101  1779171  1970149  \n",
       "4  1195078   839000  1339257  1908119  2131007  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some of the unwanted values\n",
    "df_ml.drop(['site', 'uid', 'date'], axis=1, inplace=True) # 'date',\n",
    "#df_ml.drop(['fpca2_imdate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>b1_fpca2_0509_min</th>\n",
       "      <th>b1_fpca2_0509_max</th>\n",
       "      <th>b1_fpca2_0509_mean</th>\n",
       "      <th>b1_fpca2_0509_med</th>\n",
       "      <th>b1_fpca2_0509_std</th>\n",
       "      <th>b1_h99a_01122_min</th>\n",
       "      <th>b1_h99a_01122_max</th>\n",
       "      <th>b1_h99a_01122_mean</th>\n",
       "      <th>b1_h99a_01122_med</th>\n",
       "      <th>...</th>\n",
       "      <th>NDGIm</th>\n",
       "      <th>RIm</th>\n",
       "      <th>NBRm</th>\n",
       "      <th>NDIIm</th>\n",
       "      <th>GDVIm</th>\n",
       "      <th>MSAVIm</th>\n",
       "      <th>DVIm</th>\n",
       "      <th>SAVIm</th>\n",
       "      <th>NDVIm</th>\n",
       "      <th>MSRm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>13.78</td>\n",
       "      <td>47.00</td>\n",
       "      <td>25.85</td>\n",
       "      <td>23.87</td>\n",
       "      <td>8.48</td>\n",
       "      <td>7.27</td>\n",
       "      <td>11.78</td>\n",
       "      <td>9.24</td>\n",
       "      <td>8.86</td>\n",
       "      <td>...</td>\n",
       "      <td>-1797183</td>\n",
       "      <td>1797183</td>\n",
       "      <td>803085</td>\n",
       "      <td>-1648544</td>\n",
       "      <td>1653000</td>\n",
       "      <td>2108509</td>\n",
       "      <td>1334000</td>\n",
       "      <td>2374229</td>\n",
       "      <td>3891482</td>\n",
       "      <td>5080174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.38</td>\n",
       "      <td>8.97</td>\n",
       "      <td>6.83</td>\n",
       "      <td>7.18</td>\n",
       "      <td>...</td>\n",
       "      <td>-1237840</td>\n",
       "      <td>1237840</td>\n",
       "      <td>145478</td>\n",
       "      <td>-1258856</td>\n",
       "      <td>1100000</td>\n",
       "      <td>1063379</td>\n",
       "      <td>731000</td>\n",
       "      <td>1207466</td>\n",
       "      <td>1791228</td>\n",
       "      <td>1985065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>6.42</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.47</td>\n",
       "      <td>1.22</td>\n",
       "      <td>5.93</td>\n",
       "      <td>8.85</td>\n",
       "      <td>7.68</td>\n",
       "      <td>7.68</td>\n",
       "      <td>...</td>\n",
       "      <td>-1493838</td>\n",
       "      <td>1493838</td>\n",
       "      <td>965693</td>\n",
       "      <td>-982236</td>\n",
       "      <td>1174000</td>\n",
       "      <td>951763</td>\n",
       "      <td>677000</td>\n",
       "      <td>1068835</td>\n",
       "      <td>1504110</td>\n",
       "      <td>1636492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.66</td>\n",
       "      <td>7.09</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>-1481481</td>\n",
       "      <td>1481481</td>\n",
       "      <td>-2046</td>\n",
       "      <td>-1713026</td>\n",
       "      <td>1178000</td>\n",
       "      <td>1068186</td>\n",
       "      <td>738000</td>\n",
       "      <td>1210101</td>\n",
       "      <td>1779171</td>\n",
       "      <td>1970149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>13.78</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.13</td>\n",
       "      <td>5.82</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.43</td>\n",
       "      <td>...</td>\n",
       "      <td>-1563211</td>\n",
       "      <td>1563211</td>\n",
       "      <td>758167</td>\n",
       "      <td>-969300</td>\n",
       "      <td>1320000</td>\n",
       "      <td>1195078</td>\n",
       "      <td>839000</td>\n",
       "      <td>1339257</td>\n",
       "      <td>1908119</td>\n",
       "      <td>2131007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>20805.22</td>\n",
       "      <td>15.54</td>\n",
       "      <td>42.39</td>\n",
       "      <td>29.12</td>\n",
       "      <td>29.27</td>\n",
       "      <td>6.84</td>\n",
       "      <td>16.05</td>\n",
       "      <td>20.42</td>\n",
       "      <td>18.75</td>\n",
       "      <td>18.77</td>\n",
       "      <td>...</td>\n",
       "      <td>-652174</td>\n",
       "      <td>652174</td>\n",
       "      <td>4386747</td>\n",
       "      <td>1261845</td>\n",
       "      <td>1828000</td>\n",
       "      <td>3096442</td>\n",
       "      <td>1768000</td>\n",
       "      <td>3422819</td>\n",
       "      <td>6433770</td>\n",
       "      <td>11466633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>30472.45</td>\n",
       "      <td>27.61</td>\n",
       "      <td>38.92</td>\n",
       "      <td>34.75</td>\n",
       "      <td>34.33</td>\n",
       "      <td>3.24</td>\n",
       "      <td>17.31</td>\n",
       "      <td>21.59</td>\n",
       "      <td>19.37</td>\n",
       "      <td>19.22</td>\n",
       "      <td>...</td>\n",
       "      <td>-1485714</td>\n",
       "      <td>1485714</td>\n",
       "      <td>4017258</td>\n",
       "      <td>1123510</td>\n",
       "      <td>1746000</td>\n",
       "      <td>2727661</td>\n",
       "      <td>1590000</td>\n",
       "      <td>3059261</td>\n",
       "      <td>5686695</td>\n",
       "      <td>9070438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>24414.13</td>\n",
       "      <td>9.06</td>\n",
       "      <td>22.31</td>\n",
       "      <td>14.40</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.60</td>\n",
       "      <td>9.74</td>\n",
       "      <td>16.81</td>\n",
       "      <td>13.63</td>\n",
       "      <td>13.79</td>\n",
       "      <td>...</td>\n",
       "      <td>-2065698</td>\n",
       "      <td>2065698</td>\n",
       "      <td>2615783</td>\n",
       "      <td>222222</td>\n",
       "      <td>1810000</td>\n",
       "      <td>2372051</td>\n",
       "      <td>1483000</td>\n",
       "      <td>2650423</td>\n",
       "      <td>4370763</td>\n",
       "      <td>5977733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>17598.35</td>\n",
       "      <td>5.26</td>\n",
       "      <td>25.45</td>\n",
       "      <td>13.08</td>\n",
       "      <td>12.11</td>\n",
       "      <td>5.79</td>\n",
       "      <td>9.61</td>\n",
       "      <td>20.05</td>\n",
       "      <td>13.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-1885790</td>\n",
       "      <td>1885790</td>\n",
       "      <td>2958064</td>\n",
       "      <td>395123</td>\n",
       "      <td>1691000</td>\n",
       "      <td>2284112</td>\n",
       "      <td>1407000</td>\n",
       "      <td>2574722</td>\n",
       "      <td>4401001</td>\n",
       "      <td>6037665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>9995.51</td>\n",
       "      <td>19.30</td>\n",
       "      <td>40.08</td>\n",
       "      <td>30.47</td>\n",
       "      <td>32.06</td>\n",
       "      <td>6.23</td>\n",
       "      <td>12.00</td>\n",
       "      <td>18.40</td>\n",
       "      <td>16.60</td>\n",
       "      <td>17.50</td>\n",
       "      <td>...</td>\n",
       "      <td>770925</td>\n",
       "      <td>-770925</td>\n",
       "      <td>5614599</td>\n",
       "      <td>2339640</td>\n",
       "      <td>2185000</td>\n",
       "      <td>3960474</td>\n",
       "      <td>2255000</td>\n",
       "      <td>4179538</td>\n",
       "      <td>7290656</td>\n",
       "      <td>15262347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  b1_fpca2_0509_min  b1_fpca2_0509_max  b1_fpca2_0509_mean  \\\n",
       "0       0.00              13.78              47.00               25.85   \n",
       "1       0.00               0.75               2.87                1.69   \n",
       "2       0.00               2.12               6.42                4.37   \n",
       "3       0.00               0.75               3.29                1.82   \n",
       "4       0.00               2.12              13.78                4.97   \n",
       "..       ...                ...                ...                 ...   \n",
       "162 20805.22              15.54              42.39               29.12   \n",
       "163 30472.45              27.61              38.92               34.75   \n",
       "164 24414.13               9.06              22.31               14.40   \n",
       "165 17598.35               5.26              25.45               13.08   \n",
       "166  9995.51              19.30              40.08               30.47   \n",
       "\n",
       "     b1_fpca2_0509_med  b1_fpca2_0509_std  b1_h99a_01122_min  \\\n",
       "0                23.87               8.48               7.27   \n",
       "1                 1.49               0.70               4.38   \n",
       "2                 4.47               1.22               5.93   \n",
       "3                 1.64               0.70               3.66   \n",
       "4                 4.73               2.43               3.13   \n",
       "..                 ...                ...                ...   \n",
       "162              29.27               6.84              16.05   \n",
       "163              34.33               3.24              17.31   \n",
       "164              14.21               3.60               9.74   \n",
       "165              12.11               5.79               9.61   \n",
       "166              32.06               6.23              12.00   \n",
       "\n",
       "     b1_h99a_01122_max  b1_h99a_01122_mean  b1_h99a_01122_med  ...    NDGIm  \\\n",
       "0                11.78                9.24               8.86  ... -1797183   \n",
       "1                 8.97                6.83               7.18  ... -1237840   \n",
       "2                 8.85                7.68               7.68  ... -1493838   \n",
       "3                 7.09                4.98               4.85  ... -1481481   \n",
       "4                 5.82                4.55               4.43  ... -1563211   \n",
       "..                 ...                 ...                ...  ...      ...   \n",
       "162              20.42               18.75              18.77  ...  -652174   \n",
       "163              21.59               19.37              19.22  ... -1485714   \n",
       "164              16.81               13.63              13.79  ... -2065698   \n",
       "165              20.05               13.89              13.26  ... -1885790   \n",
       "166              18.40               16.60              17.50  ...   770925   \n",
       "\n",
       "         RIm     NBRm    NDIIm    GDVIm   MSAVIm     DVIm    SAVIm    NDVIm  \\\n",
       "0    1797183   803085 -1648544  1653000  2108509  1334000  2374229  3891482   \n",
       "1    1237840   145478 -1258856  1100000  1063379   731000  1207466  1791228   \n",
       "2    1493838   965693  -982236  1174000   951763   677000  1068835  1504110   \n",
       "3    1481481    -2046 -1713026  1178000  1068186   738000  1210101  1779171   \n",
       "4    1563211   758167  -969300  1320000  1195078   839000  1339257  1908119   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "162   652174  4386747  1261845  1828000  3096442  1768000  3422819  6433770   \n",
       "163  1485714  4017258  1123510  1746000  2727661  1590000  3059261  5686695   \n",
       "164  2065698  2615783   222222  1810000  2372051  1483000  2650423  4370763   \n",
       "165  1885790  2958064   395123  1691000  2284112  1407000  2574722  4401001   \n",
       "166  -770925  5614599  2339640  2185000  3960474  2255000  4179538  7290656   \n",
       "\n",
       "         MSRm  \n",
       "0     5080174  \n",
       "1     1985065  \n",
       "2     1636492  \n",
       "3     1970149  \n",
       "4     2131007  \n",
       "..        ...  \n",
       "162  11466633  \n",
       "163   9070438  \n",
       "164   5977733  \n",
       "165   6037665  \n",
       "166  15262347  \n",
       "\n",
       "[167 rows x 171 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qty of 0 values dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathway  D:\\cdu\\data\\zonal_stats\\output\\20230219\\ml_reg_dir\\data_set\\20230219_092646\\no0_values\n",
      "D:\\cdu\\data\\zonal_stats\\output\\20230219\\ml_reg_dir\\data_set\\20230219_092646\\no0_values\n"
     ]
    }
   ],
   "source": [
    "model_data = df_ml\n",
    "model_data_name = \"all_values\"\n",
    "\n",
    "\n",
    "# ## Filter out all taregt == 0 values\n",
    "model_data = df_ml[df_ml['target']>0]\n",
    "model_data_name = \"no0_values\"\n",
    "\n",
    "# # ## Filter out all taregt == 0 values\n",
    "# model_data = df_ml[(df_ml['target']>0) & (df_ml['target']!=9)]\n",
    "# model_data_name = \"no0or9_values\"\n",
    "\n",
    "\n",
    "# ## Select a randon number of 0 values\n",
    "# n = 3\n",
    "# agb_0 = df_ml[df_ml['target']==0.0].sample(n)\n",
    "# model_data = pd.concat([df_ml[df_ml['target']>0.0], agb_0])\n",
    "# model_data_name = f\"s{n}_0_values\"\n",
    "\n",
    "\n",
    "model_outputs = os.path.join(export_ml_rf_reg_dir, f\"{model_data_name}\")\n",
    "mk_dir_fn(model_outputs)\n",
    "\n",
    "print(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathway  D:\\cdu\\data\\zonal_stats\\output\\20230219\\ml_reg_dir\\no0_values\n"
     ]
    }
   ],
   "source": [
    "ml_data_path = os.path.join(ml_rf_reg_dir, model_data_name)\n",
    "mk_dir_fn(ml_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D:\\cdu\\data\\zonal_stats\\output\\20230213\\ml_rf_reg_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\biomass_zonal\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>b1_fpca2_0509_min</th>\n",
       "      <th>b1_fpca2_0509_max</th>\n",
       "      <th>b1_fpca2_0509_mean</th>\n",
       "      <th>b1_fpca2_0509_med</th>\n",
       "      <th>b1_fpca2_0509_std</th>\n",
       "      <th>b1_h99a_01122_min</th>\n",
       "      <th>b1_h99a_01122_max</th>\n",
       "      <th>b1_h99a_01122_mean</th>\n",
       "      <th>b1_h99a_01122_med</th>\n",
       "      <th>...</th>\n",
       "      <th>NDGIm</th>\n",
       "      <th>RIm</th>\n",
       "      <th>NBRm</th>\n",
       "      <th>NDIIm</th>\n",
       "      <th>GDVIm</th>\n",
       "      <th>MSAVIm</th>\n",
       "      <th>DVIm</th>\n",
       "      <th>SAVIm</th>\n",
       "      <th>NDVIm</th>\n",
       "      <th>MSRm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1894.20</td>\n",
       "      <td>1.79</td>\n",
       "      <td>5.83</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.22</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-1452928</td>\n",
       "      <td>1452928</td>\n",
       "      <td>400174</td>\n",
       "      <td>-1264158</td>\n",
       "      <td>1238000</td>\n",
       "      <td>1250407</td>\n",
       "      <td>846000</td>\n",
       "      <td>1420098</td>\n",
       "      <td>2149390</td>\n",
       "      <td>2440148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1536.15</td>\n",
       "      <td>6.80</td>\n",
       "      <td>17.20</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.44</td>\n",
       "      <td>12.23</td>\n",
       "      <td>9.75</td>\n",
       "      <td>9.73</td>\n",
       "      <td>...</td>\n",
       "      <td>-2148760</td>\n",
       "      <td>2148760</td>\n",
       "      <td>-267789</td>\n",
       "      <td>-1724138</td>\n",
       "      <td>1148000</td>\n",
       "      <td>1156438</td>\n",
       "      <td>732000</td>\n",
       "      <td>1358238</td>\n",
       "      <td>2373541</td>\n",
       "      <td>2737539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1164.24</td>\n",
       "      <td>6.80</td>\n",
       "      <td>17.20</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.44</td>\n",
       "      <td>12.23</td>\n",
       "      <td>9.75</td>\n",
       "      <td>9.73</td>\n",
       "      <td>...</td>\n",
       "      <td>-2327297</td>\n",
       "      <td>2327297</td>\n",
       "      <td>176162</td>\n",
       "      <td>-1318945</td>\n",
       "      <td>1571000</td>\n",
       "      <td>1235708</td>\n",
       "      <td>877000</td>\n",
       "      <td>1377054</td>\n",
       "      <td>1926203</td>\n",
       "      <td>2153802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4736.01</td>\n",
       "      <td>6.80</td>\n",
       "      <td>17.20</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.44</td>\n",
       "      <td>12.23</td>\n",
       "      <td>9.75</td>\n",
       "      <td>9.73</td>\n",
       "      <td>...</td>\n",
       "      <td>-2063673</td>\n",
       "      <td>2063673</td>\n",
       "      <td>799162</td>\n",
       "      <td>-701031</td>\n",
       "      <td>1106000</td>\n",
       "      <td>1197360</td>\n",
       "      <td>743000</td>\n",
       "      <td>1417038</td>\n",
       "      <td>2593368</td>\n",
       "      <td>3039489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1549.09</td>\n",
       "      <td>6.80</td>\n",
       "      <td>17.20</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.44</td>\n",
       "      <td>12.23</td>\n",
       "      <td>9.75</td>\n",
       "      <td>9.73</td>\n",
       "      <td>...</td>\n",
       "      <td>-1639267</td>\n",
       "      <td>1639267</td>\n",
       "      <td>1618314</td>\n",
       "      <td>-88940</td>\n",
       "      <td>1673000</td>\n",
       "      <td>2020530</td>\n",
       "      <td>1324000</td>\n",
       "      <td>2256305</td>\n",
       "      <td>3482378</td>\n",
       "      <td>4382641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>20805.22</td>\n",
       "      <td>15.54</td>\n",
       "      <td>42.39</td>\n",
       "      <td>29.12</td>\n",
       "      <td>29.27</td>\n",
       "      <td>6.84</td>\n",
       "      <td>16.05</td>\n",
       "      <td>20.42</td>\n",
       "      <td>18.75</td>\n",
       "      <td>18.77</td>\n",
       "      <td>...</td>\n",
       "      <td>-652174</td>\n",
       "      <td>652174</td>\n",
       "      <td>4386747</td>\n",
       "      <td>1261845</td>\n",
       "      <td>1828000</td>\n",
       "      <td>3096442</td>\n",
       "      <td>1768000</td>\n",
       "      <td>3422819</td>\n",
       "      <td>6433770</td>\n",
       "      <td>11466633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>30472.45</td>\n",
       "      <td>27.61</td>\n",
       "      <td>38.92</td>\n",
       "      <td>34.75</td>\n",
       "      <td>34.33</td>\n",
       "      <td>3.24</td>\n",
       "      <td>17.31</td>\n",
       "      <td>21.59</td>\n",
       "      <td>19.37</td>\n",
       "      <td>19.22</td>\n",
       "      <td>...</td>\n",
       "      <td>-1485714</td>\n",
       "      <td>1485714</td>\n",
       "      <td>4017258</td>\n",
       "      <td>1123510</td>\n",
       "      <td>1746000</td>\n",
       "      <td>2727661</td>\n",
       "      <td>1590000</td>\n",
       "      <td>3059261</td>\n",
       "      <td>5686695</td>\n",
       "      <td>9070438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>24414.13</td>\n",
       "      <td>9.06</td>\n",
       "      <td>22.31</td>\n",
       "      <td>14.40</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.60</td>\n",
       "      <td>9.74</td>\n",
       "      <td>16.81</td>\n",
       "      <td>13.63</td>\n",
       "      <td>13.79</td>\n",
       "      <td>...</td>\n",
       "      <td>-2065698</td>\n",
       "      <td>2065698</td>\n",
       "      <td>2615783</td>\n",
       "      <td>222222</td>\n",
       "      <td>1810000</td>\n",
       "      <td>2372051</td>\n",
       "      <td>1483000</td>\n",
       "      <td>2650423</td>\n",
       "      <td>4370763</td>\n",
       "      <td>5977733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>17598.35</td>\n",
       "      <td>5.26</td>\n",
       "      <td>25.45</td>\n",
       "      <td>13.08</td>\n",
       "      <td>12.11</td>\n",
       "      <td>5.79</td>\n",
       "      <td>9.61</td>\n",
       "      <td>20.05</td>\n",
       "      <td>13.89</td>\n",
       "      <td>13.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-1885790</td>\n",
       "      <td>1885790</td>\n",
       "      <td>2958064</td>\n",
       "      <td>395123</td>\n",
       "      <td>1691000</td>\n",
       "      <td>2284112</td>\n",
       "      <td>1407000</td>\n",
       "      <td>2574722</td>\n",
       "      <td>4401001</td>\n",
       "      <td>6037665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>9995.51</td>\n",
       "      <td>19.30</td>\n",
       "      <td>40.08</td>\n",
       "      <td>30.47</td>\n",
       "      <td>32.06</td>\n",
       "      <td>6.23</td>\n",
       "      <td>12.00</td>\n",
       "      <td>18.40</td>\n",
       "      <td>16.60</td>\n",
       "      <td>17.50</td>\n",
       "      <td>...</td>\n",
       "      <td>770925</td>\n",
       "      <td>-770925</td>\n",
       "      <td>5614599</td>\n",
       "      <td>2339640</td>\n",
       "      <td>2185000</td>\n",
       "      <td>3960474</td>\n",
       "      <td>2255000</td>\n",
       "      <td>4179538</td>\n",
       "      <td>7290656</td>\n",
       "      <td>15262347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target  b1_fpca2_0509_min  b1_fpca2_0509_max  b1_fpca2_0509_mean  \\\n",
       "5    1894.20               1.79               5.83                2.86   \n",
       "8    1536.15               6.80              17.20               11.25   \n",
       "9    1164.24               6.80              17.20               11.25   \n",
       "10   4736.01               6.80              17.20               11.25   \n",
       "12   1549.09               6.80              17.20               11.25   \n",
       "..       ...                ...                ...                 ...   \n",
       "162 20805.22              15.54              42.39               29.12   \n",
       "163 30472.45              27.61              38.92               34.75   \n",
       "164 24414.13               9.06              22.31               14.40   \n",
       "165 17598.35               5.26              25.45               13.08   \n",
       "166  9995.51              19.30              40.08               30.47   \n",
       "\n",
       "     b1_fpca2_0509_med  b1_fpca2_0509_std  b1_h99a_01122_min  \\\n",
       "5                 2.48               1.22               3.80   \n",
       "8                11.00               2.80               7.44   \n",
       "9                11.00               2.80               7.44   \n",
       "10               11.00               2.80               7.44   \n",
       "12               11.00               2.80               7.44   \n",
       "..                 ...                ...                ...   \n",
       "162              29.27               6.84              16.05   \n",
       "163              34.33               3.24              17.31   \n",
       "164              14.21               3.60               9.74   \n",
       "165              12.11               5.79               9.61   \n",
       "166              32.06               6.23              12.00   \n",
       "\n",
       "     b1_h99a_01122_max  b1_h99a_01122_mean  b1_h99a_01122_med  ...    NDGIm  \\\n",
       "5                 5.20                4.29               4.27  ... -1452928   \n",
       "8                12.23                9.75               9.73  ... -2148760   \n",
       "9                12.23                9.75               9.73  ... -2327297   \n",
       "10               12.23                9.75               9.73  ... -2063673   \n",
       "12               12.23                9.75               9.73  ... -1639267   \n",
       "..                 ...                 ...                ...  ...      ...   \n",
       "162              20.42               18.75              18.77  ...  -652174   \n",
       "163              21.59               19.37              19.22  ... -1485714   \n",
       "164              16.81               13.63              13.79  ... -2065698   \n",
       "165              20.05               13.89              13.26  ... -1885790   \n",
       "166              18.40               16.60              17.50  ...   770925   \n",
       "\n",
       "         RIm     NBRm    NDIIm    GDVIm   MSAVIm     DVIm    SAVIm    NDVIm  \\\n",
       "5    1452928   400174 -1264158  1238000  1250407   846000  1420098  2149390   \n",
       "8    2148760  -267789 -1724138  1148000  1156438   732000  1358238  2373541   \n",
       "9    2327297   176162 -1318945  1571000  1235708   877000  1377054  1926203   \n",
       "10   2063673   799162  -701031  1106000  1197360   743000  1417038  2593368   \n",
       "12   1639267  1618314   -88940  1673000  2020530  1324000  2256305  3482378   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "162   652174  4386747  1261845  1828000  3096442  1768000  3422819  6433770   \n",
       "163  1485714  4017258  1123510  1746000  2727661  1590000  3059261  5686695   \n",
       "164  2065698  2615783   222222  1810000  2372051  1483000  2650423  4370763   \n",
       "165  1885790  2958064   395123  1691000  2284112  1407000  2574722  4401001   \n",
       "166  -770925  5614599  2339640  2185000  3960474  2255000  4179538  7290656   \n",
       "\n",
       "         MSRm  \n",
       "5     2440148  \n",
       "8     2737539  \n",
       "9     2153802  \n",
       "10    3039489  \n",
       "12    4382641  \n",
       "..        ...  \n",
       "162  11466633  \n",
       "163   9070438  \n",
       "164   5977733  \n",
       "165   6037665  \n",
       "166  15262347  \n",
       "\n",
       "[110 rows x 171 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define if you are using all variabes or selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklean.model\n",
    "# randomly split data into train and test datasets, the user needs to define the variables \n",
    "xdata1 = model_data.iloc[:, 1:].astype('float32')\n",
    "ydata1 = model_data[[\"target\"]].astype('int')\n",
    "ydata2 = ydata1.values\n",
    "ydata = ydata2.ravel()\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(xdata1, ydata, train_size=0.70) #, stratify=ydata)  \n",
    "         \n",
    "#y_test.value_counts()\n",
    "# print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify the data split into train and test datasets.\n",
    "# The stratify parameter will ensure that the train and test split has the same class \n",
    "# distribution ratio as the original dataset.\n",
    "\n",
    "# xdata = model_data.iloc[:, 1:].astype('float32')\n",
    "# ydata = model_data[[\"target\"]].astype('int')\n",
    "\n",
    "# # Split the data into a training set and a test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(xdata, ydata, train_size=0.70) #, stratify=ydata)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stratify parameter will ensure that the train and test split has the same class distribution ratio as the original dataset. It is crucial in the case of imbalanced datasets. Otherwise, it might happen that the training data only consists of the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "# X_text = pd.DataFrame(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_plot(X_train, y_train, model, str_model, x_limit, y_limit, x_off, y_off):\n",
    "    #str_model = \"Linear_regression\"\n",
    "\n",
    "#     model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    r2 = model.score(X_train, y_train)\n",
    "    mse = np.mean((y_train - model.predict(X_train))**2)\n",
    "    print(f\"R2: {r2}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "\n",
    "\n",
    "    plt.scatter(model.predict(X_train), y_train)  \n",
    "    # data for the 1 for 1 line\n",
    "    x = [x_limit,y_limit]\n",
    "    y = [x_limit, y_limit]\n",
    "\n",
    "    #sets the limits of the axis\n",
    "    plt.xlim(x_limit, y_limit)\n",
    "    plt.ylim(x_limit, y_limit)\n",
    "\n",
    "    plt.ylabel('Observed target')\n",
    "\n",
    "    plt.xlabel('Predicted target')\n",
    "\n",
    "    # 1 for 1 line\n",
    "    #adding text inside the plot\n",
    "    plt.text((x_limit + x_off), (y_limit - y_off), f'$R^2 = {round(r2, 4)}$', fontsize = 12)\n",
    "#    plt.text((x_limit + x_off), (y_limit - (y_off*2)), f'$MSE = {round(mse, 4)}$', fontsize = 12)\n",
    "#     plt.text((x_limit + x_off), (y_limit - (y_off*2)), f'$MSE = {120}$', fontsize = 12)\n",
    "    plt.text((x_limit + x_off), (y_limit - (y_off*3)), f'$n = {len(y_train)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "    plt.plot(x, y, color = 'r')\n",
    "\n",
    "    plot_out = os.path.join(model_outputs, f'{str_model}_train_plot.jpg')\n",
    "    plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "    print(f\"plot saved to: {plot_out}\")\n",
    "    plt.show()\n",
    "    \n",
    "    return str_model, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.0595724406836996\n",
      "MSE: 51322151.18494445\n",
      "plot saved to: D:\\cdu\\data\\zonal_stats\\output\\20230219\\ml_reg_dir\\data_set\\20230219_092646\\no0_values\\Linear_regression_train_plot.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "str_model, model = train_model_plot(X_train, y_train, LinearRegression(),\n",
    "                                    \"Linear_regression\", 0, 40000, 1000, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_plot(model, X_test, y_test, str_model, x_limit, y_limit, x_off, y_off):\n",
    "\n",
    "    # call the model\n",
    "    y_test_predict = model.predict(X_test)\n",
    "\n",
    "\n",
    "    r2 = model.score(X_test, y_test)\n",
    "    mse = np.mean((y_test - model.predict(X_test))** 2)\n",
    "    rmse = np.sqrt(np.mean((y_test_predict - y_test) ** 2))\n",
    "    bias = np.mean(y_test) - np.mean(y_test_predict)\n",
    "    print('Predicted data r2 =', r2)\n",
    "    print('MSE =', mse)\n",
    "#     print('RMSE =', format(rmse, '.3f'))\n",
    "#     print('bias =' , format(bias, '.3f'))\n",
    "#     print('n =' , len(y_test))\n",
    "\n",
    "\n",
    "    # r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "    # mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "    # rmse = round(np.sqrt(np.mean((y2_predict - y_2) ** 2)), 2)\n",
    "    # bias = round(np.mean(y_2) - np.mean(y2_predict), 2)\n",
    "\n",
    "    plt.scatter(y_test_predict, y_test) #, s=10, c='b', marker='o')\n",
    "    # data for the 1 for 1 line\n",
    "    x = [x_limit,y_limit]\n",
    "    y = [x_limit, y_limit]\n",
    "\n",
    "    #sets the limits of the axis\n",
    "    plt.xlim(x_limit, y_limit)\n",
    "    plt.ylim(x_limit, y_limit)\n",
    "    plt.ylabel('Observed')\n",
    "    plt.xlabel('Predicted')\n",
    "    # 1 for 1 line\n",
    "\n",
    "    #adding text inside the plot\n",
    "#     plt.text((x_limit + x_off), (y_limit - y_off), f'$R^2 = {round(r2, 4)}$', fontsize = 12)\n",
    "#     plt.text((x_limit + x_off), (y_limit - (y_off*2)), f'$MSE = {round(mse, 4)}$', fontsize = 12)\n",
    "#     plt.text((x_limit + x_off), (y_limit - (y_off*3)), f'$RMSE = {round(rmse, 4)}$', fontsize = 12)\n",
    "#     plt.text((x_limit + x_off), (y_limit - (y_off*4)), f'$Bias = {round(bias, 4)}$', fontsize = 12)\n",
    "#     plt.text((x_limit + x_off), (y_limit - (y_off*5)), f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "    plt.plot(x, y, color = 'r')\n",
    "    plot_out = os.path.join(model_outputs, f'{str_model}_test_plot.jpg')\n",
    "    plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted data r2 = -2.595191545405894\n",
      "MSE = 281346817.702363\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-ada2ed579995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstr_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "str_model, model = test_model_plot(model.fit(X_train, y_train), X_test, y_test, str_model, 0, 40000, 1000, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model, model = train_model_plot(X_train, y_train, SGDRegressor(), \"SGD_regressor\", 0, 40000, 1000, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model, model = test_model_plot(model.fit(X_train, y_train), X_test, y_test, str_model, 0, 40000, 1000, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = \"Linear_regression\"\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "# y_pred = model_lr.predict(X_test)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# for regression we use R2 score and MAE(mean absolute error)\n",
    "# all other steps will be same as classification as shown above\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# r2 = r2_score(X_train, y_train)\n",
    "# mse = mean_absolute_error(X_train, y_train)\n",
    "\n",
    "r2 = round(model_lr.score(X_train, y_train), 2)\n",
    "mse = round(np.mean((y_train - model_lr.predict(X_train))**2), 2)\n",
    "\n",
    "\n",
    "print(f\"R2: {r2}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "\n",
    "\n",
    "plt.scatter(model_lr.predict(X_train), y_train)  \n",
    "# data for the 1 for 1 line\n",
    "x = [0,35000]\n",
    "y = [0,35000]\n",
    "\n",
    "# #sets the limits of the axis\n",
    "# plt.xlim(-1,35000)\n",
    "# plt.ylim(-1,35000)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(-13000, 33000, f'$R^2 = {round(r2, 4)}$', fontsize = 12)\n",
    "plt.text(-13000, 30000, f'$MSE = {round(mse, 4)}$', fontsize = 12)\n",
    "plt.text(-13000, 27000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_train_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the model\n",
    "y_test_predict = model_lr.predict(X_test)\n",
    "\n",
    "\n",
    "r2 = model_lr.score(X_test, y_test)\n",
    "mse = np.mean((y_test - model_lr.predict(X_test))** 2)\n",
    "rmse = np.sqrt(np.mean((y_test_predict - y_test) ** 2))\n",
    "bias = np.mean(y_test) - np.mean(y_test_predict)\n",
    "print('Predicted data r2 =', r2)\n",
    "print('MSE =', mse)\n",
    "print('RMSE =', format(rmse, '.3f'))\n",
    "#print('explained_var =',format(explained_variance_score(y_test, y_test_predict),  '.3f'))\n",
    "print('bias =' , format(bias, '.3f'))\n",
    "print('n =' , len(y_test))\n",
    "\n",
    "\n",
    "# r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "# mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "# rmse = round(np.sqrt(np.mean((y2_predict - y_2) ** 2)), 2)\n",
    "# bias = round(np.mean(y_2) - np.mean(y2_predict), 2)\n",
    "\n",
    "plt.scatter(y_test_predict, y_test ,s=10, c='b', marker='o')\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,40000]\n",
    "y = [-1,40000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,40000)\n",
    "plt.ylim(-1, 40000)\n",
    "plt.ylabel('Observed mean AGB')\n",
    "plt.xlabel('Predicted mean AGB')\n",
    "# 1 for 1 line\n",
    "\n",
    "#adding text inside the plot\n",
    "plt.text(300, 37000, f'$R^2 = {round(r2, 4)}$', fontsize = 12)\n",
    "plt.text(300, 34000, f'$MSE = {round(mse, 4)}$', fontsize = 12)\n",
    "plt.text(300, 31000, f'$RMSE = {round(rmse, 4)}$', fontsize = 12)\n",
    "plt.text(300, 28000, f'$Bias = {round(bias, 4)}$', fontsize = 12)\n",
    "plt.text(300, 25000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_test_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.statology.org/sklearn-linear-regression-summary/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "# #add constant to predictor variables\n",
    "# x = sm.add_constant(X_train)\n",
    "\n",
    "# #fit linear regression model\n",
    "# model = sm.OLS(x, y_train).fit()\n",
    "# #model_lr.fit(X_train, y_train)\n",
    "\n",
    "# #view model summary\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = \"SGD_regressor\"\n",
    "\n",
    "model_sgd = SGDRegressor()\n",
    "model_sgd.fit(X_train, y_train)\n",
    "# y_pred = model_sgd.predict(X_test)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# for regression we use R2 score and MAE(mean absolute error)\n",
    "# all other steps will be same as classification as shown above\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# r2 = r2_score(X_train, y_train)\n",
    "# mse = mean_absolute_error(X_train, y_train)\n",
    "\n",
    "r2 = round(model_sgd.score(X_train, y_train), 2)\n",
    "mse = round(np.mean((y_train - model_sgd.predict(X_train))**2), 2)\n",
    "\n",
    "\n",
    "print(f\"R2: {r2}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "\n",
    "\n",
    "plt.scatter(model_sgd.predict(X_train), y_train)  \n",
    "# data for the 1 for 1 line\n",
    "x = [0,35000]\n",
    "y = [0,35000]\n",
    "\n",
    "# #sets the limits of the axis\n",
    "# plt.xlim(-1,35000)\n",
    "# plt.ylim(-1,35000)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(-5, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(-5, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(-5, 27000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_train_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the model\n",
    "y_test_predict = model_sgd.predict(X_test)\n",
    "\n",
    "\n",
    "r2 = model_sgd.score(X_test, y_test)\n",
    "mse = np.mean((y_test - model_sgd.predict(X_test))** 2)\n",
    "rmse = np.sqrt(np.mean((y_test_predict - y_test) ** 2))\n",
    "bias = np.mean(y_test) - np.mean(y_test_predict)\n",
    "print('Predicted data r2 =', r2)\n",
    "print('MSE =', mse)\n",
    "print('RMSE =', format(rmse, '.3f'))\n",
    "#print('explained_var =',format(explained_variance_score(y_test, y_test_predict),  '.3f'))\n",
    "print('bias =' , format(bias, '.3f'))\n",
    "print('n =' , len(y_test))\n",
    "\n",
    "\n",
    "# r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "# mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "# rmse = round(np.sqrt(np.mean((y2_predict - y_2) ** 2)), 2)\n",
    "# bias = round(np.mean(y_2) - np.mean(y2_predict), 2)\n",
    "\n",
    "plt.scatter(y_test_predict, y_test ,s=10, c='b', marker='o')\n",
    "# data for the 1 for 1 line\n",
    "# x = [-1,40000]\n",
    "# y = [-1,40000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "# plt.xlim(-1,40000)\n",
    "# plt.ylim(-1, 40000)\n",
    "plt.ylabel('Observed mean AGB')\n",
    "plt.xlabel('Predicted mean AGB')\n",
    "# 1 for 1 line\n",
    "\n",
    "#adding text inside the plot\n",
    "plt.text(300, 37000, f'$R^2 = {round(r2, 4)}$', fontsize = 12)\n",
    "plt.text(300, 34000, f'$MSE = {round(mse, 4)}$', fontsize = 12)\n",
    "plt.text(300, 31000, f'$RMSE = {round(rmse, 4)}$', fontsize = 12)\n",
    "plt.text(300, 28000, f'$Bias = {round(bias, 4)}$', fontsize = 12)\n",
    "plt.text(300, 25000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_test_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = \"kernel_ridge\"\n",
    "\n",
    "model_kr = KernelRidge()\n",
    "model_kr.fit(X_train, y_train)\n",
    "# y_pred = model_sgd.predict(X_test)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# for regression we use R2 score and MAE(mean absolute error)\n",
    "# all other steps will be same as classification as shown above\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# r2 = r2_score(X_train, y_train)\n",
    "# mse = mean_absolute_error(X_train, y_train)\n",
    "\n",
    "r2 = round(model_sgd.score(X_train, y_train), 2)\n",
    "mse = round(np.mean((y_train - model_sgd.predict(X_train))**2), 2)\n",
    "\n",
    "\n",
    "print(f\"R2: {r2}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "\n",
    "\n",
    "plt.scatter(model_sgd.predict(X_train), y_train)  \n",
    "# data for the 1 for 1 line\n",
    "x = [0,35000]\n",
    "y = [0,35000]\n",
    "\n",
    "# #sets the limits of the axis\n",
    "# plt.xlim(-1,35000)\n",
    "# plt.ylim(-1,35000)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(-5, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(-5, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(-5, 27000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_train_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the model\n",
    "y_test_predict = model_sgd.predict(X_test)\n",
    "\n",
    "\n",
    "r2 = model_sgd.score(X_test, y_test)\n",
    "mse = np.mean((y_test - model_sgd.predict(X_test))** 2)\n",
    "rmse = np.sqrt(np.mean((y_test_predict - y_test) ** 2))\n",
    "bias = np.mean(y_test) - np.mean(y_test_predict)\n",
    "print('Predicted data r2 =', r2)\n",
    "print('MSE =', mse)\n",
    "print('RMSE =', format(rmse, '.3f'))\n",
    "#print('explained_var =',format(explained_variance_score(y_test, y_test_predict),  '.3f'))\n",
    "print('bias =' , format(bias, '.3f'))\n",
    "print('n =' , len(y_test))\n",
    "\n",
    "\n",
    "# r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "# mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "# rmse = round(np.sqrt(np.mean((y2_predict - y_2) ** 2)), 2)\n",
    "# bias = round(np.mean(y_2) - np.mean(y2_predict), 2)\n",
    "\n",
    "plt.scatter(y_test_predict, y_test ,s=10, c='b', marker='o')\n",
    "# data for the 1 for 1 line\n",
    "# x = [-1,40000]\n",
    "# y = [-1,40000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "# plt.xlim(-1,40000)\n",
    "# plt.ylim(-1, 40000)\n",
    "plt.ylabel('Observed mean AGB')\n",
    "plt.xlabel('Predicted mean AGB')\n",
    "# 1 for 1 line\n",
    "\n",
    "#adding text inside the plot\n",
    "plt.text(300, 37000, f'$R^2 = {round(r2, 4)}$', fontsize = 12)\n",
    "plt.text(300, 34000, f'$MSE = {round(mse, 4)}$', fontsize = 12)\n",
    "plt.text(300, 31000, f'$RMSE = {round(rmse, 4)}$', fontsize = 12)\n",
    "plt.text(300, 28000, f'$Bias = {round(bias, 4)}$', fontsize = 12)\n",
    "plt.text(300, 25000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_test_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = \"kr\"\n",
    "\n",
    "model_kr = KernelRidge()\n",
    "model_kr.fit(X_train, y_train)\n",
    "y_pred = model_kr.predict(X_test)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# for regression we use R2 score and MAE(mean absolute error)\n",
    "# all other steps will be same as classification as shown above\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "mse = mean_absolute_error(y_test,y_pred)\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "plt.scatter(model_kr.predict(X_train), y_train,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [-100,35000]\n",
    "y = [-100,35000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-100,35000)\n",
    "plt.ylim(-100,35000)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(100, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(100, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(100, 27000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = \"en\"\n",
    "\n",
    "model_en = ElasticNet()\n",
    "model_en.fit(X_train, y_train)\n",
    "y_pred = model_en.predict(X_test)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# for regression we use R2 score and MAE(mean absolute error)\n",
    "# all other steps will be same as classification as shown above\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "mse = mean_absolute_error(y_test,y_pred)\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "plt.scatter(model_en.predict(X_train), y_train,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [-100,35000]\n",
    "y = [-100,35000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-100,35000)\n",
    "plt.ylim(-100,35000)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(100, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(100, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(100, 27000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = \"br\"\n",
    "\n",
    "model_br = BayesianRidge()\n",
    "model_br.fit(X_train, y_train)\n",
    "y_pred = model_br.predict(X_test)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# for regression we use R2 score and MAE(mean absolute error)\n",
    "# all other steps will be same as classification as shown above\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "mse = mean_absolute_error(y_test,y_pred)\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "plt.scatter(model_br.predict(X_train), y_train,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [-100,35000]\n",
    "y = [-100,35000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-100,35000)\n",
    "plt.ylim(-100,35000)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(100, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(100, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(100, 27000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = \"gbr\"\n",
    "\n",
    "model_gbr = GradientBoostingRegressor()\n",
    "model_gbr.fit(X_train, y_train)\n",
    "y_pred = model_gbr.predict(X_test)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# for regression we use R2 score and MAE(mean absolute error)\n",
    "# all other steps will be same as classification as shown above\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "mse = mean_absolute_error(y_test,y_pred)\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "plt.scatter(model_gbr.predict(X_train), y_train,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [-100,35000]\n",
    "y = [-100,35000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-100,35000)\n",
    "plt.ylim(-100,35000)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(100, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(100, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(100, 27000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = \"svr\"\n",
    "\n",
    "model_svr = GradientBoostingRegressor()\n",
    "model_svr.fit(X_train, y_train)\n",
    "y_pred = model_svr.predict(X_test)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# for regression we use R2 score and MAE(mean absolute error)\n",
    "# all other steps will be same as classification as shown above\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "mse = mean_absolute_error(y_test,y_pred)\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "plt.scatter(model_svr.predict(X_train), y_train,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [-100,35000]\n",
    "y = [-100,35000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-100,35000)\n",
    "plt.ylim(-100,35000)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(100, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(100, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(100, 27000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_predict = rfrLCHM.predict(X_2)\n",
    "\n",
    "print('Predicted data r2 =', rfrLCHM.score(X_2, y_2))\n",
    "print('MSE =', format(np.mean((y_2 - rfrLCHM.predict(X_2))** 2), '.3f'))\n",
    "print('RMSE =', format(np.sqrt(np.mean((y2_predict - y_2) ** 2)), '.3f'))\n",
    "#print 'explained_var =',format(explained_variance_score(y_2, y2_predict),  '.3f') \n",
    "print('bias =' , format(np.mean(y_2) - np.mean(y2_predict), '.3f'))\n",
    "print('n =' , len(y_2))\n",
    "\n",
    "\n",
    "r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "rmse = round(np.sqrt(np.mean((y2_predict - y_2) ** 2)), 2)\n",
    "bias = round(np.mean(y_2) - np.mean(y2_predict), 2)\n",
    "\n",
    "plt.scatter(y2_predict, y_2 ,s=10, c='b', marker='o')\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,40000]\n",
    "y = [-1,40000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,40000)\n",
    "plt.ylim(-1, 40000)\n",
    "plt.ylabel('Observed mean AGB')\n",
    "plt.xlabel('Predicted mean AGB')\n",
    "# 1 for 1 line\n",
    "\n",
    "#adding text inside the plot\n",
    "plt.text(300, 37000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(300, 35000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(300, 33000, f'$RMSE = {mse}$', fontsize = 12)\n",
    "plt.text(300, 31000, f'$Bias = {bias}$', fontsize = 12)\n",
    "plt.text(300, 29000, f'$n = {len(y_1)}$', fontsize = 12)\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_test_data.jpg')\n",
    "fig.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgdr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model = \"kr\"\n",
    "\n",
    "model_kr = SGDRegressor()\n",
    "model_kr.fit(X_train, y_train)\n",
    "y_pred = model_kr.predict(X_test)\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# for regression we use R2 score and MAE(mean absolute error)\n",
    "# all other steps will be same as classification as shown above\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "mse = mean_absolute_error(y_test,y_pred)\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(mean_absolute_error(y_test,y_pred))\n",
    "\n",
    "plt.scatter(model_kr.predict(X_train), y_train,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [0,35000]\n",
    "y = [0,35000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,35000)\n",
    "plt.ylim(-1,35000)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(100, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(100, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(100, 27000, f'$n = {len(y_test)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(class_weight='balanced', max_depth=10)\n",
    "model .fit(X_train_res, y_train_res.target.ravel())\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(class_weight='balanced', random_state=1,max_depth=5, \\\n",
    "                              n_estimators =10, max_features=1)\n",
    "model .fit(X_train_res, y_train_res.target.ravel())\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(3)\n",
    "model .fit(X_train_res, y_train_res.target.ravel())\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(learning_rate=0.01)\n",
    "model .fit(X_train_res, y_train_res.target.ravel())\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, input_dim=26, activation='relu'),\n",
    "    keras.layers.Dense(16, activation = \"relu\"),\n",
    "    keras.layers.Dropout(0,3),\n",
    "    keras.layers.Dense(8, activation=\"relu\"),\n",
    "    keras.layers.Dense(4, activation = \"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_enc = pd.get_dummies(y_train_res)\n",
    "y_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "enc_df = pd.DataFrame(enc.fit_transform(y_train_res[['target']]).toarray())\n",
    "# merge with main df bridge_df on key values\n",
    "y_train_res = y_train_res.join(enc_df)\n",
    "y_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df = pd.DataFrame(enc.fit_transform(y_test_res[['target']]).toarray())\n",
    "# merge with main df bridge_df on key values\n",
    "y_test_res = y_test_res.join(enc_df)\n",
    "y_test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res.drop(\"target\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_res, y_train_enc, epochs=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.educba.com/keras-sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.keras.Input(shape=(3,))\n",
    "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, the first layer can receive an `input_shape` argument:\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
    "# Afterwards, we do automatic shape inference:\n",
    "model.add(tf.keras.layers.Dense(4))\n",
    "\n",
    "# This is identical to the following:\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(16,)))\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "\n",
    "# Note that you can also omit the `input_shape` argument.\n",
    "# In that case the model doesn't have any weights until the first call\n",
    "# to a training/evaluation method (since it isn't yet built):\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "model.add(tf.keras.layers.Dense(4))\n",
    "# model.weights not created yet\n",
    "\n",
    "# Whereas if you specify the input shape, the model gets built\n",
    "# continuously as you are adding layers:\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
    "model.add(tf.keras.layers.Dense(4))\n",
    "len(model.weights)\n",
    "# Returns \"4\"\n",
    "\n",
    "# When using the delayed-build pattern (no input shape specified), you can\n",
    "# choose to manually build your model by calling\n",
    "# `build(batch_input_shape)`:\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "model.add(tf.keras.layers.Dense(4))\n",
    "model.build((None, 16))\n",
    "len(model.weights)\n",
    "# Returns \"4\"\n",
    "\n",
    "# Note that when using the delayed-build pattern (no input shape specified),\n",
    "# the model gets built the first time you call `fit`, `eval`, or `predict`,\n",
    "# or the first time you call the model on some input data.\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(8))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "# This builds the model for the first time:\n",
    "model.fit(x, y, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((X_train_res, y_train_enc))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((X_test_res, y_test_enc))\n",
    "\n",
    "history = model.fit(X_train_res, y_train_enc, epochs=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainMixed, trainVocals,epochs=10, validation_data=(testMixed, testVocals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((trainMixed, trainVocals))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((testMixed, testVocals))\n",
    "\n",
    "model.fit(train_data, epochs=10, validation_data=valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model_svc,\n",
    "        X_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = iris.target_names\n",
    "\n",
    "# # Split the data into a training set and a test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "classifier = svm.SVC(kernel=\"linear\", C=0.01).fit(X_train, y_train)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = iris.target_names\n",
    "\n",
    "# # Split the data into a training set and a test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "classifier = svm.SVC(kernel=\"linear\", C=0.01).fit(X_train, y_train)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X_test,\n",
    "        y_test,\n",
    "#         display_labels=class_names,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterise the Random Forest Regressor alogorthim\n",
    "\n",
    "for details see: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 300\n",
    "rs = 1\n",
    "maxd = 4\n",
    "\n",
    "rng = np.random.RandomState(rs)\n",
    "rfrModel_1 = abr(dtr(max_depth=maxd), n_estimators=n_est, random_state=rng)\n",
    "print(rfrModel_1)\n",
    "mdl = \"abr\"\n",
    "str_model = f\"rf_{abr}_{model_data_name}_n_est_{n_est}_rs_{rs}_maxd_{maxd}_{date_time_str}\"\n",
    "print(str_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 100\n",
    "lr=0.1\n",
    "rs = 1\n",
    "maxd = 4\n",
    "loss = 'squared_error'\n",
    "\n",
    "rfrModel_1 = gbr(n_estimators=n_est, learning_rate=lr, max_depth=maxd, random_state=1, loss=loss)\n",
    "print(rfrModel_1)\n",
    "mdl = \"gbr\"\n",
    "str_model = f\"rf_{mdl}_{model_data_name}_n_est_{n_est}_lr{lr}_{loss}_rs_{rs}_maxd_{maxd}_{date_time_str}\"\n",
    "print(str_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfrModel_1 = etr(n_estimators=100, bootstrap=True, oob_score=True,  max_features='log2', min_samples_split=1,n_jobs=-1) \n",
    "# rfrModel_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rfrModel_1 = rfr(n_estimators=100, oob_score=True,  max_depth=None, max_features='log2', min_samples_split=1.0,n_jobs=-1) \n",
    "# rfrModel_1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfrModel_1 = rfr(n_estimators=100, oob_score=True) #,  max_depth=None, max_features='log2', min_samples_split=1.0,n_jobs=-1) \n",
    "# rfrModel_1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(X_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit random forest regressor model and compute variable importance score \n",
    "\n",
    "may need to restrict the number of variables for the bar graph to be legible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfrLCHM = rfrModel_1.fit(X_1, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rfrModel_1.feature_importances_\n",
    "\n",
    "### TRY THIS\n",
    "# use \"feature importance\" scores to see what the top 10 important features are\n",
    "fi = enumerate(rfrModel_1.feature_importances_)\n",
    "cols = xdata1.columns\n",
    "fiResult = [(value,cols[i]) for (i,value) in fi]\n",
    "#fiResult = [(value,cols[i]) for (i,value) in fi if value > 0.001]\n",
    "## Change the value 0.04 which we picked empirically to give us 10 variables\n",
    "## try running this code after changing the value up and down so you get more or less variables\n",
    "## do you see how this might be useful in refining the model?\n",
    "## Here is the code in case you mess up the line above\n",
    "## [(value,cols[i]) for (i,value) in fi if value > 0.04]\n",
    "#print fiResult\n",
    "r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "# print(r2)\n",
    "# print('Fitted model r2 =' ,  format(rfrLCHM.score(X_1, y_1), '.2f'))\n",
    "# print('Fitted model mse =', format(np.mean((y_1 - rfrLCHM.predict(X_1))**2), '.2f'))\n",
    "# print('n =', len(y_1))\n",
    "plt.scatter(rfrLCHM.predict(X_1), y_1,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [0,35000]\n",
    "y = [0,35000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "#plt.xlim(-1,35)\n",
    "#plt.ylim(-1,35)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(100, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(100, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(100, 27000, f'$n = {len(y_1)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiResult = np.array(fiResult)\n",
    "score = (fiResult[:,0])\n",
    "band = fiResult[:,1]\n",
    "a = fiResult[np.argsort(fiResult[:, 1])]\n",
    "\n",
    "df_band = pd.DataFrame(dict(band=band,n=score))\n",
    "df_band['n'].astype('float')\n",
    "dfsort = df_band.sort_values(['n'], ascending=[False])\n",
    "print(dfsort)\n",
    " \n",
    "## my complicated way to get the bar plot to sort in ascending order and display the assocated band names in the y axis\n",
    "dfsort2 = df_band.sort_values(['n'], ascending=[True])\n",
    "b = dfsort2[['band']]\n",
    "c = b.values.tolist()\n",
    "# convert the list of band names in the correct order to a string\n",
    "e = str(c)\n",
    "# strips all the rubbish from the string\n",
    "f = e.replace('[','').replace(']','').replace(\"'\",'').replace(\",\",' ')\n",
    "# convert the cleaned up string back into a list to plot the band names in the bar graph\n",
    "g = f.split()\n",
    " \n",
    "ind = np.arange(len(df_band))\n",
    "width = 0.4\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(ind, dfsort2.n, width, color='blue')\n",
    "ax.set(yticks=ind + width, yticklabels= g, ylim=[2*width - 1, len(df_band)])\n",
    "ax.set_xlabel('Performance')\n",
    "ax.set_ylabel('Ranked variables')\n",
    "plt.xticks(rotation='vertical')\n",
    "ax.set_title('Variable Importance Rank')\n",
    "\n",
    "plt.show()\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_feature_importance_plot.jpg')\n",
    "fig.savefig(plot_out,dpi=600)# save out your figure to a pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsort['n'].astype('float')\n",
    "dfsort.info()\n",
    "dfsort['n'] = dfsort['n'].astype('float')\n",
    "dfsort.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bf_selection = 0.01\n",
    "df_var = dfsort[dfsort['n'] > num_bf_selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_var = df_var.band.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_var.insert(0, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_model_data = df_ml[column_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = select_model_data.corr()\n",
    "df_corr.to_csv(os.path.join(model_outputs, f'{str_model}_feature_imp_n_{num_bf_selection}_.csv'), index=False)\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_imp_list = dfsort.band.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_imp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run same model and same peramiters with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into train and test datasets, the user needs to define the variables \n",
    "xdata1 = select_model_data.iloc[:, 1:].astype('float32')\n",
    "ydata1 = select_model_data[[value_x]].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata = ydata2.ravel()\n",
    "\n",
    "X_1, X_2, y_1, y_2 = train_test_split(xdata1, ydata, train_size=0.70)  \n",
    "         \n",
    "print(X_1.shape, y_1.shape)\n",
    "print(X_2.shape, y_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mdl == \"abr\":\n",
    "    \n",
    "    rng = np.random.RandomState(rs)\n",
    "    rfrModel_1 = abr(dtr(max_depth=maxd), n_estimators=n_est, random_state=rng)\n",
    "    str_model = f\"rf_abr_{model_data_name}_slc_feat_n_est_{n_est}_rs_{rs}_maxd_{maxd}_{date_time_str}\"\n",
    "    print(str_model)\n",
    "\n",
    "\n",
    "elif mdl== gbr:\n",
    "    rfrModel_1 = gbr(n_estimators=n_est, learning_rate=lr, max_depth=maxd, random_state=1, loss=loss)\n",
    "    str_model = f\"rf_gbr_{model_data_name}_slc_feat_n_est_{n_est}_lr{lr}_{loss}_rs_{rs}_maxd_{maxd}_{date_time_str}\"\n",
    "    print(str_model)\n",
    "else:\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(X_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit random forest regressor model and compute variable importance score \n",
    "\n",
    "may need to restrict the number of variables for the bar graph to be legible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfrLCHM = rfrModel_1.fit(X_1, y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### good info on the feature importance score - http://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rfrModel_1.feature_importances_\n",
    "\n",
    "### TRY THIS\n",
    "# use \"feature importance\" scores to see what the top 10 important features are\n",
    "fi = enumerate(rfrModel_1.feature_importances_)\n",
    "cols = xdata1.columns\n",
    "fiResult = [(value,cols[i]) for (i,value) in fi]\n",
    "#fiResult = [(value,cols[i]) for (i,value) in fi if value > 0.001]\n",
    "## Change the value 0.04 which we picked empirically to give us 10 variables\n",
    "## try running this code after changing the value up and down so you get more or less variables\n",
    "## do you see how this might be useful in refining the model?\n",
    "## Here is the code in case you mess up the line above\n",
    "## [(value,cols[i]) for (i,value) in fi if value > 0.04]\n",
    "#print fiResult\n",
    "r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "# print(r2)\n",
    "# print('Fitted model r2 =' ,  format(rfrLCHM.score(X_1, y_1), '.2f'))\n",
    "# print('Fitted model mse =', format(np.mean((y_1 - rfrLCHM.predict(X_1))**2), '.2f'))\n",
    "# print('n =', len(y_1))\n",
    "plt.scatter(rfrLCHM.predict(X_1), y_1,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [0,35000]\n",
    "y = [0,35000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "#plt.xlim(-1,35)\n",
    "#plt.ylim(-1,35)\n",
    "\n",
    "plt.ylabel('Observed target')\n",
    "\n",
    "plt.xlabel('Predicted target')\n",
    "\n",
    "# 1 for 1 line\n",
    "#adding text inside the plot\n",
    "plt.text(100, 33000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(100, 30000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(100, 27000, f'$n = {len(y_1)}$', fontsize = 12)\n",
    "\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_select_feat_plot.jpg')\n",
    "plt.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "print(f\"plot saved to: {plot_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiResult = np.array(fiResult)\n",
    "score = (fiResult[:,0])\n",
    "band = fiResult[:,1]\n",
    "a = fiResult[np.argsort(fiResult[:, 1])]\n",
    "\n",
    "df_band = pd.DataFrame(dict(band=band,n=score))\n",
    "df_band['n'].astype('float')\n",
    "dfsort = df_band.sort_values(['n'], ascending=[False])\n",
    "print(dfsort)\n",
    " \n",
    "## my complicated way to get the bar plot to sort in ascending order and display the assocated band names in the y axis\n",
    "dfsort2 = df_band.sort_values(['n'], ascending=[True])\n",
    "b = dfsort2[['band']]\n",
    "c = b.values.tolist()\n",
    "# convert the list of band names in the correct order to a string\n",
    "e = str(c)\n",
    "# strips all the rubbish from the string\n",
    "f = e.replace('[','').replace(']','').replace(\"'\",'').replace(\",\",' ')\n",
    "# convert the cleaned up string back into a list to plot the band names in the bar graph\n",
    "g = f.split()\n",
    " \n",
    "ind = np.arange(len(df_band))\n",
    "width = 0.4\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(ind, dfsort2.n, width, color='blue')\n",
    "ax.set(yticks=ind + width, yticklabels= g, ylim=[2*width - 1, len(df_band)])\n",
    "ax.set_xlabel('Performance')\n",
    "ax.set_ylabel('Ranked variables')\n",
    "plt.xticks(rotation='vertical')\n",
    "ax.set_title('Variable Importance Rank')\n",
    "\n",
    "plt.show()\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_select_features_feature_importance_plot.jpg')\n",
    "fig.savefig(plot_out,dpi=600)# save out your figure to a pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the selected model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(y2_predict, y_2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_predict = rfrLCHM.predict(X_2)\n",
    "\n",
    "print('Predicted data r2 =', rfrLCHM.score(X_2, y_2))\n",
    "print('MSE =', format(np.mean((y_2 - rfrLCHM.predict(X_2))** 2), '.3f'))\n",
    "print('RMSE =', format(np.sqrt(np.mean((y2_predict - y_2) ** 2)), '.3f'))\n",
    "#print 'explained_var =',format(explained_variance_score(y_2, y2_predict),  '.3f') \n",
    "print('bias =' , format(np.mean(y_2) - np.mean(y2_predict), '.3f'))\n",
    "print('n =' , len(y_2))\n",
    "\n",
    "\n",
    "r2 = round(rfrLCHM.score(X_1, y_1), 2)\n",
    "mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "rmse = round(np.sqrt(np.mean((y2_predict - y_2) ** 2)), 2)\n",
    "bias = round(np.mean(y_2) - np.mean(y2_predict), 2)\n",
    "\n",
    "plt.scatter(y2_predict, y_2 ,s=10, c='b', marker='o')\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,40000]\n",
    "y = [-1,40000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,40000)\n",
    "plt.ylim(-1, 40000)\n",
    "plt.ylabel('Observed mean AGB')\n",
    "plt.xlabel('Predicted mean AGB')\n",
    "# 1 for 1 line\n",
    "\n",
    "#adding text inside the plot\n",
    "plt.text(300, 37000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(300, 35000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(300, 33000, f'$RMSE = {mse}$', fontsize = 12)\n",
    "plt.text(300, 31000, f'$Bias = {bias}$', fontsize = 12)\n",
    "plt.text(300, 29000, f'$n = {len(y_1)}$', fontsize = 12)\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_test_data.jpg')\n",
    "fig.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = y2_predict\n",
    "y = y_2\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(x, y, c=z, s=0.8, edgecolor='')\n",
    "\n",
    "# # data for the 1 for 1 line\n",
    "# a = [-1,25]\n",
    "# b = [-1,25]\n",
    "\n",
    "# #sets the limits of the axis\n",
    "# plt.xlim(-1,25)\n",
    "# plt.ylim(-1,25)\n",
    "# plt.ylabel('Observed mean CHM')\n",
    "# plt.xlabel('Predicted mean CHM')\n",
    "# # 1 for 1 line\n",
    "# ax.plot(a, b, color = 'black')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP - do you realy want to save this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remember to change the cPickle file name !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save current fitted model and apply to unseen validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#rfrL8CHM = rfr()\n",
    "#rfrL8CHM.fit(X_1, y_1)\n",
    "\n",
    "pkl_out = os.path.join(model_outputs, f'rf_model_{str_model}')\n",
    "\n",
    "\n",
    "with open(pkl_out, 'wb') as f:\n",
    "    pickle.dump(rfrLCHM, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in unseen data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in your validation dataset which has never been seen by rfr model - NOTE in this example I am just reading the same data used to train the model\n",
    "new_data = select_model_data\n",
    "# df = pd.read_csv(csv_file, header=0)\n",
    "# df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = new_data.columns.tolist()\n",
    "c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df[(df['comp'] == 'l57')]\n",
    "df1 = new_data[(new_data['target'] > 0.01)]\n",
    "df1.dropna(inplace=True)\n",
    "print (df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[column_var].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata2 = df1[column_var].astype('float32')\n",
    "xdata2.drop(\"target\", axis=1, inplace=True)\n",
    "\n",
    "ydata1 = df1[['target']].astype('float32')\n",
    "\n",
    "ydata2 = ydata1.values\n",
    "\n",
    "ydata = ydata2.ravel()\n",
    "\n",
    "print(len(ydata1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_out, 'rb') as f:\n",
    "        rf = pickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print('Predicted data r2 =', rf.score(xdata2, ydata))\n",
    "print('MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f'))\n",
    "print('RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f'))\n",
    "print('explained_var =',format(explained_variance_score(ydata, predicted),  '.3f'))\n",
    "print('bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f'))\n",
    "print('n =' , len(ydata))\n",
    "\n",
    "r2 = round(rf.score(xdata2, ydata), 2)\n",
    "mse = round(np.mean((ydata - rf.predict(xdata2))** 2), 2)\n",
    "rmse = round(np.sqrt(np.mean((predicted - ydata) ** 2)), 2)\n",
    "exp_var = round(explained_variance_score(ydata, predicted), 2)\n",
    "bias = round(np.mean(ydata) - np.mean(predicted), 2)\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=8, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,40000]\n",
    "y = [-1,40000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 40000)\n",
    "plt.ylim(-1, 40000)\n",
    "\n",
    "#adding text inside the plot\n",
    "plt.text(300, 37000, f'$R^2 = {r2}$', fontsize = 12)\n",
    "plt.text(300, 35000, f'$MSE = {mse}$', fontsize = 12)\n",
    "plt.text(300, 33000, f'$RMSE = {mse}$', fontsize = 12)\n",
    "plt.text(300, 31000, f'$Bias = {bias}$', fontsize = 12)\n",
    "plt.text(300, 29000, f'$Var = {exp_var}$', fontsize = 12)\n",
    "plt.text(300, 27000, f'$n = {len(y_1)}$', fontsize = 12)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "\n",
    "plot_out = os.path.join(model_outputs, f'{str_model}_unseen_data.jpg')\n",
    "\n",
    "fig.savefig(plot_out,dpi=600)# save out your figure to a pdf \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
