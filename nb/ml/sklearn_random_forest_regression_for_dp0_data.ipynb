{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Random Forest Regression for dp0 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load modules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following conditions apply:\n",
    "\n",
    " - env = biomass_zonal\n",
    " - data merged_slats_field_agb_dp1_start.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import ExtraTreesRegressor as etr\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.ensemble import AdaBoostRegressor as abr\n",
    "from sklearn.tree import DecisionTreeRegressor as dtr\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import plotting and stats modules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import scipy\n",
    "import scipy.stats as sc\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# stats module\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import figure, show\n",
    "#%matplotlib inline\n",
    "\n",
    "# Bokeh Libraries\n",
    "# from bokeh.plotting import figure, show\n",
    "# from bokeh.io import output_file\n",
    "from bokeh.models import ColumnDataSource, NumeralTickFormatter, HoverTool\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "#sklearn.model_selection.cross_validate\n",
    "# from sklearn import cross_validation\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.cross_validation import KFold\n",
    "import pickle5 as Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_file = r\"F:\\cdu\\data\\zonal_stats\\output\\merged_slats_field_nt_mosaic_clean_start_all_values.csv\"\n",
    "#csv_file = r\"E:\\cdu\\data\\zonal_stats\\output\\merged_slats_field_agb_dp1_start.csv\"\n",
    "csv_file = r\"D:\\cdu\\data\\zonal_stats\\output\\merged_slats_field_agb_dp0_tile.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set output file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ = r\"D:\\cdu\\data\\zonal_stats\\output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(180, 65)\n",
=======
      "(165, 65)\n",
>>>>>>> 3ae4cfd9954c5bf41c130f26f7a8782665ba0c8e
      "['uid_x', 'site', 'date', 'lon_gda94', 'lat_gda94', 'bio_l_kg1ha', 'bio_t_kg1ha', 'bio_b_kg1ha', 'bio_w_kg1ha', 'bio_br_kg1ha', 'bio_s_kg1ha', 'bio_r_kg1ha', 'bio_agb_kg1ha', 'c_l_kg1ha', 'c_t_kg1ha', 'c_b_kg1ha', 'c_w_kg1ha', 'c_br_kg1ha', 'c_s_kg1ha', 'c_r_kg1ha', 'c_agb_kg1ha', 'basal_dt', 'uid_y', 'image', 'year', 'month', 'day', 'b1_dp0_min', 'b1_dp0_max', 'b1_dp0_mean', 'b1_dp0_count', 'b1_dp0_std', 'b1_dp0_med', 'b1_dp0_p25', 'b1_dp0_p50', 'b1_dp0_p75', 'b1_dp0_p95', 'b1_dp0_p99', 'b1_dp0_range', 'b2_dp0_min', 'b2_dp0_max', 'b2_dp0_mean', 'b2_dp0_count', 'b2_dp0_std', 'b2_dp0_med', 'b2_dp0_p25', 'b2_dp0_p50', 'b2_dp0_p75', 'b2_dp0_p95', 'b2_dp0_p99', 'b2_dp0_range', 'b3_dp0_min', 'b3_dp0_max', 'b3_dp0_mean', 'b3_dp0_count', 'b3_dp0_med', 'b3_dp0_p25', 'b3_dp0_p50', 'b3_dp0_p75', 'b3_dp0_p95', 'b3_dp0_p99', 'b3_dp0_range', 'b3_dp0_std', 'im_date', 'image_dt']\n"
     ]
    }
   ],
   "source": [
    "# read as dataframe and copy\n",
    "df1 = pd.read_csv(csv_file, header=0) # the first row is read in as the header for you columns\n",
    "print(df1.shape) # prints out the number of rows and columns in your csv file \n",
    "print(list(df1))\n",
    "df1.shape\n",
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 165 entries, 0 to 164\n",
      "Data columns (total 65 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   uid_x          165 non-null    int64  \n",
      " 1   site           165 non-null    object \n",
      " 2   date           165 non-null    int64  \n",
      " 3   lon_gda94      165 non-null    float64\n",
      " 4   lat_gda94      165 non-null    float64\n",
      " 5   bio_l_kg1ha    165 non-null    float64\n",
      " 6   bio_t_kg1ha    165 non-null    float64\n",
      " 7   bio_b_kg1ha    165 non-null    float64\n",
      " 8   bio_w_kg1ha    165 non-null    float64\n",
      " 9   bio_br_kg1ha   165 non-null    float64\n",
      " 10  bio_s_kg1ha    165 non-null    float64\n",
      " 11  bio_r_kg1ha    165 non-null    float64\n",
      " 12  bio_agb_kg1ha  165 non-null    float64\n",
      " 13  c_l_kg1ha      165 non-null    float64\n",
      " 14  c_t_kg1ha      165 non-null    float64\n",
      " 15  c_b_kg1ha      165 non-null    float64\n",
      " 16  c_w_kg1ha      165 non-null    float64\n",
      " 17  c_br_kg1ha     165 non-null    float64\n",
      " 18  c_s_kg1ha      165 non-null    float64\n",
      " 19  c_r_kg1ha      165 non-null    float64\n",
      " 20  c_agb_kg1ha    165 non-null    float64\n",
      " 21  basal_dt       165 non-null    object \n",
      " 22  uid_y          158 non-null    float64\n",
      " 23  image          158 non-null    object \n",
      " 24  year           158 non-null    float64\n",
      " 25  month          158 non-null    float64\n",
      " 26  day            158 non-null    float64\n",
      " 27  b1_dp0_min     158 non-null    float64\n",
      " 28  b1_dp0_max     158 non-null    float64\n",
      " 29  b1_dp0_mean    158 non-null    float64\n",
      " 30  b1_dp0_count   158 non-null    float64\n",
      " 31  b1_dp0_std     158 non-null    float64\n",
      " 32  b1_dp0_med     158 non-null    float64\n",
      " 33  b1_dp0_p25     158 non-null    float64\n",
      " 34  b1_dp0_p50     158 non-null    float64\n",
      " 35  b1_dp0_p75     158 non-null    float64\n",
      " 36  b1_dp0_p95     158 non-null    float64\n",
      " 37  b1_dp0_p99     158 non-null    float64\n",
      " 38  b1_dp0_range   158 non-null    float64\n",
      " 39  b2_dp0_min     135 non-null    float64\n",
      " 40  b2_dp0_max     158 non-null    float64\n",
      " 41  b2_dp0_mean    158 non-null    float64\n",
      " 42  b2_dp0_count   158 non-null    float64\n",
      " 43  b2_dp0_std     158 non-null    float64\n",
      " 44  b2_dp0_med     158 non-null    float64\n",
      " 45  b2_dp0_p25     158 non-null    float64\n",
      " 46  b2_dp0_p50     158 non-null    float64\n",
      " 47  b2_dp0_p75     158 non-null    float64\n",
      " 48  b2_dp0_p95     158 non-null    float64\n",
      " 49  b2_dp0_p99     158 non-null    float64\n",
      " 50  b2_dp0_range   158 non-null    float64\n",
      " 51  b3_dp0_min     158 non-null    float64\n",
      " 52  b3_dp0_max     158 non-null    float64\n",
      " 53  b3_dp0_mean    158 non-null    float64\n",
      " 54  b3_dp0_count   158 non-null    float64\n",
      " 55  b3_dp0_med     158 non-null    float64\n",
      " 56  b3_dp0_p25     158 non-null    float64\n",
      " 57  b3_dp0_p50     158 non-null    float64\n",
      " 58  b3_dp0_p75     158 non-null    float64\n",
      " 59  b3_dp0_p95     158 non-null    float64\n",
      " 60  b3_dp0_p99     158 non-null    float64\n",
      " 61  b3_dp0_range   158 non-null    float64\n",
      " 62  b3_dp0_std     158 non-null    float64\n",
      " 63  im_date        158 non-null    float64\n",
      " 64  image_dt       158 non-null    object \n",
      "dtypes: float64(59), int64(2), object(4)\n",
      "memory usage: 83.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill null values in Min 02 to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum values in FC data that has a mean value (i.e. not masked) must have a 0 minimum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(subset = ['b1_dp0_mean'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 172 entries, 0 to 179\n",
      "Data columns (total 35 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   site           172 non-null    object \n",
      " 1   bio_agb_kg1ha  172 non-null    float64\n",
      " 2   b1_dp0_min     172 non-null    float64\n",
      " 3   b1_dp0_max     172 non-null    float64\n",
      " 4   b1_dp0_mean    172 non-null    float64\n",
      " 5   b1_dp0_std     172 non-null    float64\n",
      " 6   b1_dp0_med     172 non-null    float64\n",
      " 7   b1_dp0_p25     172 non-null    float64\n",
      " 8   b1_dp0_p50     172 non-null    float64\n",
      " 9   b1_dp0_p75     172 non-null    float64\n",
      " 10  b1_dp0_p95     172 non-null    float64\n",
      " 11  b1_dp0_p99     172 non-null    float64\n",
      " 12  b2_dp0_min     172 non-null    float64\n",
      " 13  b2_dp0_max     172 non-null    float64\n",
      " 14  b2_dp0_mean    172 non-null    float64\n",
      " 15  b2_dp0_std     172 non-null    float64\n",
      " 16  b2_dp0_med     172 non-null    float64\n",
      " 17  b2_dp0_p25     172 non-null    float64\n",
      " 18  b2_dp0_p50     172 non-null    float64\n",
      " 19  b2_dp0_p75     172 non-null    float64\n",
      " 20  b2_dp0_p95     172 non-null    float64\n",
      " 21  b2_dp0_p99     172 non-null    float64\n",
      " 22  b2_dp0_range   172 non-null    float64\n",
      " 23  b3_dp0_min     172 non-null    float64\n",
      " 24  b3_dp0_max     172 non-null    float64\n",
      " 25  b3_dp0_mean    172 non-null    float64\n",
      " 26  b3_dp0_count   172 non-null    float64\n",
      " 27  b3_dp0_med     172 non-null    float64\n",
      " 28  b3_dp0_p25     172 non-null    float64\n",
      " 29  b3_dp0_p50     172 non-null    float64\n",
      " 30  b3_dp0_p75     172 non-null    float64\n",
      " 31  b3_dp0_p95     172 non-null    float64\n",
      " 32  b3_dp0_p99     172 non-null    float64\n",
      " 33  b3_dp0_range   172 non-null    float64\n",
      " 34  b3_dp0_std     172 non-null    float64\n",
      "dtypes: float64(34), object(1)\n",
      "memory usage: 48.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.b2_dp0_min.fillna(0).inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[[\"b2_dp0_min\"]] = df2[[\"b2_dp0_min\"]].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 172 entries, 0 to 179\n",
      "Data columns (total 35 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   site           172 non-null    object \n",
      " 1   bio_agb_kg1ha  172 non-null    float64\n",
      " 2   b1_dp0_min     172 non-null    float64\n",
      " 3   b1_dp0_max     172 non-null    float64\n",
      " 4   b1_dp0_mean    172 non-null    float64\n",
      " 5   b1_dp0_std     172 non-null    float64\n",
      " 6   b1_dp0_med     172 non-null    float64\n",
      " 7   b1_dp0_p25     172 non-null    float64\n",
      " 8   b1_dp0_p50     172 non-null    float64\n",
      " 9   b1_dp0_p75     172 non-null    float64\n",
      " 10  b1_dp0_p95     172 non-null    float64\n",
      " 11  b1_dp0_p99     172 non-null    float64\n",
      " 12  b2_dp0_min     172 non-null    float64\n",
      " 13  b2_dp0_max     172 non-null    float64\n",
      " 14  b2_dp0_mean    172 non-null    float64\n",
      " 15  b2_dp0_std     172 non-null    float64\n",
      " 16  b2_dp0_med     172 non-null    float64\n",
      " 17  b2_dp0_p25     172 non-null    float64\n",
      " 18  b2_dp0_p50     172 non-null    float64\n",
      " 19  b2_dp0_p75     172 non-null    float64\n",
      " 20  b2_dp0_p95     172 non-null    float64\n",
      " 21  b2_dp0_p99     172 non-null    float64\n",
      " 22  b2_dp0_range   172 non-null    float64\n",
      " 23  b3_dp0_min     172 non-null    float64\n",
      " 24  b3_dp0_max     172 non-null    float64\n",
      " 25  b3_dp0_mean    172 non-null    float64\n",
      " 26  b3_dp0_count   172 non-null    float64\n",
      " 27  b3_dp0_med     172 non-null    float64\n",
      " 28  b3_dp0_p25     172 non-null    float64\n",
      " 29  b3_dp0_p50     172 non-null    float64\n",
      " 30  b3_dp0_p75     172 non-null    float64\n",
      " 31  b3_dp0_p95     172 non-null    float64\n",
      " 32  b3_dp0_p99     172 non-null    float64\n",
      " 33  b3_dp0_range   172 non-null    float64\n",
      " 34  b3_dp0_std     172 non-null    float64\n",
      "dtypes: float64(34), object(1)\n",
      "memory usage: 48.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_x = 'b2_dp0_mean'\n",
    "value_y = 'bio_agb_kg1ha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 35)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output to file\n",
    "output_file(os.path.join(output_,'all_sites_{0}_{1}.html'.format(value_x, value_y)),\n",
    "            title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")))\n",
    "\n",
    "\n",
    "#Specify the selection tools to be made available\n",
    "select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'zoom_in', 'zoom_out', 'wheel_zoom', 'reset']\n",
    "\n",
    "# Format the tooltip\n",
    "tooltips = [\n",
    "            ('Site', '@site'),\n",
    "            ('Date', '@date'),\n",
    "            ('AGB', '@bio_agb_kg1ha'),\n",
    "#             ('Three-Point Percentage', '@pct3PM{00.0%}')   \n",
    "           ]\n",
    "\n",
    "# Create the figure\n",
    "fig = figure(plot_height=400,\n",
    "             plot_width=1500,\n",
    "             y_axis_label= value_y.replace(\"_\", \" \"), \n",
    "             x_axis_label= value_x.replace(\"_\", \" \"),\n",
    "             title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")),\n",
    "             toolbar_location='below',\n",
    "             tools=select_tools)\n",
    "\n",
    "# # Format the y-axis tick label\n",
    "fig.yaxis[0].formatter = NumeralTickFormatter(format='0')\n",
    "\n",
    "# Add square representing each site\n",
    "fig.square(x= value_x,\n",
    "           y= value_y,\n",
    "           source=df2.round(4),\n",
    "           size=5,\n",
    "           color='royalblue',\n",
    "           selection_color='deepskyblue',\n",
    "           nonselection_color='lightgray',\n",
    "           nonselection_alpha=0.3)\n",
    "\n",
    "# Add the HoverTool to the figure\n",
    "fig.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "# Visualize\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop AGB numbers which are high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site        b2_dp0_mean  bio_agb_kg1ha\n",
       "NTAMGD0004  31.25        12934706.40      1\n",
       "NTAMGD0002  37.33        12934706.40      1\n",
       "NTAGFU0023  42.19        12934706.40      1\n",
       "NTAGFU0018  26.08        12934706.40      1\n",
       "NTAGFU0017  49.81        12934706.40      1\n",
       "NTAGFU0008  11.44        12934706.40      1\n",
       "NTAGFU0007  16.78        12934706.40      1\n",
       "NTAGFU0006  34.67        12934706.40      1\n",
       "NTAGFU0004  29.75        12934706.40      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the 7 tern sites that apear to be outliers\n",
    "df3 =df2[df2['bio_agb_kg1ha'] <= 100000]\n",
    "df3.to_csv(os.path.join(output_, \"dp1_agb_lt_100000.csv\"))\n",
    "drop_sites =df2[df2['bio_agb_kg1ha'] > 100000]\n",
    "drop_sites.value_counts(['site', 'b2_dp0_mean', 'bio_agb_kg1ha'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163, 35)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output to file\n",
    "output_file(os.path.join(output_, 'TERN7_removed_sites_{0}_{1}.html'.format(value_x, value_y)),\n",
    "            title='Seven TERN sites removed - relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")))\n",
    "\n",
    "\n",
    "#Specify the selection tools to be made available\n",
    "select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'zoom_in', 'zoom_out', 'wheel_zoom', 'reset']\n",
    "\n",
    "# Format the tooltip\n",
    "tooltips = [\n",
    "            ('Site', '@site'),\n",
    "            ('Date', '@date'),\n",
    "            ('AGB', '@bio_agb_kg1ha'),\n",
    "#             ('Three-Point Percentage', '@pct3PM{00.0%}')   \n",
    "           ]\n",
    "\n",
    "# Create the figure\n",
    "fig = figure(plot_height=400,\n",
    "             plot_width=1500,\n",
    "             y_axis_label= value_y.replace(\"_\", \" \"), \n",
    "             x_axis_label= value_x.replace(\"_\", \" \"),\n",
    "             title='Seven TERN sites removed - relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")),\n",
    "             toolbar_location='below',\n",
    "             tools=select_tools)\n",
    "\n",
    "# # Format the y-axis tick label\n",
    "fig.yaxis[0].formatter = NumeralTickFormatter(format='0')\n",
    "\n",
    "# Add square representing each site\n",
    "fig.square(x= value_x,\n",
    "           y= value_y,\n",
    "           source=df3,\n",
    "           size=5,\n",
    "           color='royalblue',\n",
    "           selection_color='deepskyblue',\n",
    "           nonselection_color='lightgray',\n",
    "           nonselection_alpha=0.3)\n",
    "\n",
    "# Add the HoverTool to the figure\n",
    "fig.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "# Visualize\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the TERN sites for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the TERN sites due to \n",
    "df4=df3[df3.site.apply(lambda x: len(str(x))<=9)]\n",
    "df4.to_csv(os.path.join(output_, \"dp1_agb_NTH_only_lt_100000.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid_x</th>\n",
       "      <th>site</th>\n",
       "      <th>date</th>\n",
       "      <th>lon_gda94</th>\n",
       "      <th>lat_gda94</th>\n",
       "      <th>bio_l_kg1ha</th>\n",
       "      <th>bio_t_kg1ha</th>\n",
       "      <th>bio_b_kg1ha</th>\n",
       "      <th>bio_w_kg1ha</th>\n",
       "      <th>bio_br_kg1ha</th>\n",
       "      <th>...</th>\n",
       "      <th>b3_dp0_med</th>\n",
       "      <th>b3_dp0_p25</th>\n",
       "      <th>b3_dp0_p50</th>\n",
       "      <th>b3_dp0_p75</th>\n",
       "      <th>b3_dp0_p95</th>\n",
       "      <th>b3_dp0_p99</th>\n",
       "      <th>b3_dp0_range</th>\n",
       "      <th>b3_dp0_std</th>\n",
       "      <th>im_date</th>\n",
       "      <th>image_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>64</td>\n",
       "      <td>wh02</td>\n",
       "      <td>20120724</td>\n",
       "      <td>130.68</td>\n",
       "      <td>-18.23</td>\n",
       "      <td>8.12</td>\n",
       "      <td>8.83</td>\n",
       "      <td>34.49</td>\n",
       "      <td>112.20</td>\n",
       "      <td>85.08</td>\n",
       "      <td>...</td>\n",
       "      <td>38.50</td>\n",
       "      <td>36.00</td>\n",
       "      <td>38.50</td>\n",
       "      <td>42.75</td>\n",
       "      <td>50.15</td>\n",
       "      <td>53.23</td>\n",
       "      <td>24.00</td>\n",
       "      <td>6.08</td>\n",
       "      <td>2012722.00</td>\n",
       "      <td>2012-07-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>74</td>\n",
       "      <td>wh12</td>\n",
       "      <td>20120726</td>\n",
       "      <td>130.91</td>\n",
       "      <td>-17.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>61.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>61.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>71.60</td>\n",
       "      <td>73.52</td>\n",
       "      <td>25.00</td>\n",
       "      <td>7.92</td>\n",
       "      <td>2012722.00</td>\n",
       "      <td>2012-07-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19</td>\n",
       "      <td>nt003</td>\n",
       "      <td>20120523</td>\n",
       "      <td>131.18</td>\n",
       "      <td>-13.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>24.00</td>\n",
       "      <td>22.75</td>\n",
       "      <td>24.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2012519.00</td>\n",
       "      <td>2012-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>90</td>\n",
       "      <td>vrd28</td>\n",
       "      <td>20120731</td>\n",
       "      <td>131.17</td>\n",
       "      <td>-16.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>86.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>88.60</td>\n",
       "      <td>88.92</td>\n",
       "      <td>11.00</td>\n",
       "      <td>3.09</td>\n",
       "      <td>201287.00</td>\n",
       "      <td>2012-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>61</td>\n",
       "      <td>lto04</td>\n",
       "      <td>20130528</td>\n",
       "      <td>130.78</td>\n",
       "      <td>-13.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>78.50</td>\n",
       "      <td>76.75</td>\n",
       "      <td>78.50</td>\n",
       "      <td>80.25</td>\n",
       "      <td>83.45</td>\n",
       "      <td>83.89</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2013630.00</td>\n",
       "      <td>2013-06-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid_x   site      date  lon_gda94  lat_gda94  bio_l_kg1ha  bio_t_kg1ha  \\\n",
       "89      64   wh02  20120724     130.68     -18.23         8.12         8.83   \n",
       "99      74   wh12  20120726     130.91     -17.48         0.00         0.00   \n",
       "29      19  nt003  20120523     131.18     -13.85         0.00         0.00   \n",
       "115     90  vrd28  20120731     131.17     -16.55         0.00         0.00   \n",
       "148     61  lto04  20130528     130.78     -13.17         0.00         0.00   \n",
       "\n",
       "     bio_b_kg1ha  bio_w_kg1ha  bio_br_kg1ha  ...  b3_dp0_med  b3_dp0_p25  \\\n",
       "89         34.49       112.20         85.08  ...       38.50       36.00   \n",
       "99          0.00         0.00          0.00  ...       61.00       53.00   \n",
       "29          0.00         0.00          0.00  ...       24.00       22.75   \n",
       "115         0.00         0.00          0.00  ...       86.00       85.00   \n",
       "148         0.00         0.00          0.00  ...       78.50       76.75   \n",
       "\n",
       "     b3_dp0_p50  b3_dp0_p75  b3_dp0_p95  b3_dp0_p99  b3_dp0_range  b3_dp0_std  \\\n",
       "89        38.50       42.75       50.15       53.23         24.00        6.08   \n",
       "99        61.00       64.00       71.60       73.52         25.00        7.92   \n",
       "29        24.00       25.00       25.00       25.00          6.00        1.71   \n",
       "115       86.00       86.00       88.60       88.92         11.00        3.09   \n",
       "148       78.50       80.25       83.45       83.89          9.00        2.79   \n",
       "\n",
       "       im_date    image_dt  \n",
       "89  2012722.00  2012-07-22  \n",
       "99  2012722.00  2012-07-22  \n",
       "29  2012519.00  2012-05-19  \n",
       "115  201287.00  2012-08-07  \n",
       "148 2013630.00  2013-06-30  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 65)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output to file\n",
    "output_file(os.path.join(output_, 'ntg_sites_agb_{0}_{1}.html'.format(value_x, value_y)),\n",
    "            title='NTG sites only - relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")))\n",
    "\n",
    "#Specify the selection tools to be made available\n",
    "select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'zoom_in', 'zoom_out', 'wheel_zoom', 'reset']\n",
    "\n",
    "# Format the tooltip\n",
    "tooltips = [\n",
    "            ('Site', '@site'),\n",
    "            ('Date', '@date'),\n",
    "            ('AGB', '@bio_agb_kg1ha'),\n",
    "#             ('Three-Point Percentage', '@pct3PM{00.0%}')   \n",
    "           ]\n",
    "\n",
    "# Create the figure\n",
    "fig = figure(plot_height=400,\n",
    "             plot_width=1500,\n",
    "             y_axis_label= value_y.replace(\"_\", \" \"), \n",
    "             x_axis_label= value_x.replace(\"_\", \" \"),\n",
    "             title='NTG sites only - relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")),\n",
    "             toolbar_location='below',\n",
    "             tools=select_tools)\n",
    "\n",
    "# # Format the y-axis tick label\n",
    "fig.yaxis[0].formatter = NumeralTickFormatter(format='0')\n",
    "\n",
    "# Add square representing each site\n",
    "fig.square(x= value_x,\n",
    "           y= value_y,\n",
    "           source=df4,\n",
    "           size=5,\n",
    "           color='royalblue',\n",
    "           selection_color='deepskyblue',\n",
    "           nonselection_color='lightgray',\n",
    "           nonselection_alpha=0.3)\n",
    "\n",
    "# Add the HoverTool to the figure\n",
    "fig.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "# Visualize\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which data set to run the models from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\biomass_zonal\\lib\\site-packages\\pandas\\core\\frame.py:4167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# drop some of the unwanted values\n",
    "df_ml.drop(['uid_x', 'date', 'lon_gda94', 'lat_gda94', 'bio_l_kg1ha', 'bio_t_kg1ha', 'bio_b_kg1ha', 'bio_w_kg1ha', 'bio_br_kg1ha', 'bio_s_kg1ha', 'bio_r_kg1ha', 'c_l_kg1ha', 'c_t_kg1ha', 'c_b_kg1ha', 'c_w_kg1ha', 'c_br_kg1ha', 'c_s_kg1ha', 'c_r_kg1ha', 'c_agb_kg1ha'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['site', 'bio_agb_kg1ha', 'basal_dt', 'uid_y', 'image', 'year', 'month', 'day', 'b1_dp0_min', 'b1_dp0_max', 'b1_dp0_mean', 'b1_dp0_count', 'b1_dp0_std', 'b1_dp0_med', 'b1_dp0_p25', 'b1_dp0_p50', 'b1_dp0_p75', 'b1_dp0_p95', 'b1_dp0_p99', 'b1_dp0_range', 'b2_dp0_min', 'b2_dp0_max', 'b2_dp0_mean', 'b2_dp0_count', 'b2_dp0_std', 'b2_dp0_med', 'b2_dp0_p25', 'b2_dp0_p50', 'b2_dp0_p75', 'b2_dp0_p95', 'b2_dp0_p99', 'b2_dp0_range', 'b3_dp0_min', 'b3_dp0_max', 'b3_dp0_mean', 'b3_dp0_count', 'b3_dp0_med', 'b3_dp0_p25', 'b3_dp0_p50', 'b3_dp0_p75', 'b3_dp0_p95', 'b3_dp0_p99', 'b3_dp0_range', 'b3_dp0_std', 'im_date', 'image_dt']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\biomass_zonal\\lib\\site-packages\\pandas\\core\\frame.py:4167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "#dp0\n",
    "df_ml.drop(['basal_dt', 'uid_y', 'image', 'year', 'month', 'day', 'im_date', 'image_dt', 'b1_dp0_count', 'b1_dp0_range', 'b2_dp0_count', ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['site', 'bio_agb_kg1ha', 'b1_dp0_min', 'b1_dp0_max', 'b1_dp0_mean', 'b1_dp0_std', 'b1_dp0_med', 'b1_dp0_p25', 'b1_dp0_p50', 'b1_dp0_p75', 'b1_dp0_p95', 'b1_dp0_p99', 'b2_dp0_min', 'b2_dp0_max', 'b2_dp0_mean', 'b2_dp0_std', 'b2_dp0_med', 'b2_dp0_p25', 'b2_dp0_p50', 'b2_dp0_p75', 'b2_dp0_p95', 'b2_dp0_p99', 'b2_dp0_range', 'b3_dp0_min', 'b3_dp0_max', 'b3_dp0_mean', 'b3_dp0_count', 'b3_dp0_med', 'b3_dp0_p25', 'b3_dp0_p50', 'b3_dp0_p75', 'b3_dp0_p95', 'b3_dp0_p99', 'b3_dp0_range', 'b3_dp0_std']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 35)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce level of 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to the number of field sites with no basal collected data is stratified\n",
    "no0_df = df_ml[df_ml['bio_agb_kg1ha']>0.0]\n",
    "agb_0 = df_ml[df_ml['bio_agb_kg1ha']==0.0].sample(3)\n",
    "some0_df = pd.concat([no0_df, agb_0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the dataset to run the models from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 35)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_ml\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 117 entries, 0 to 179\n",
      "Data columns (total 35 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   site           117 non-null    object \n",
      " 1   bio_agb_kg1ha  117 non-null    float64\n",
      " 2   b1_dp0_min     115 non-null    float64\n",
      " 3   b1_dp0_max     115 non-null    float64\n",
      " 4   b1_dp0_mean    115 non-null    float64\n",
      " 5   b1_dp0_std     115 non-null    float64\n",
      " 6   b1_dp0_med     115 non-null    float64\n",
      " 7   b1_dp0_p25     115 non-null    float64\n",
      " 8   b1_dp0_p50     115 non-null    float64\n",
      " 9   b1_dp0_p75     115 non-null    float64\n",
      " 10  b1_dp0_p95     115 non-null    float64\n",
      " 11  b1_dp0_p99     115 non-null    float64\n",
      " 12  b2_dp0_min     85 non-null     float64\n",
      " 13  b2_dp0_max     115 non-null    float64\n",
      " 14  b2_dp0_mean    115 non-null    float64\n",
      " 15  b2_dp0_std     115 non-null    float64\n",
      " 16  b2_dp0_med     115 non-null    float64\n",
      " 17  b2_dp0_p25     115 non-null    float64\n",
      " 18  b2_dp0_p50     115 non-null    float64\n",
      " 19  b2_dp0_p75     115 non-null    float64\n",
      " 20  b2_dp0_p95     115 non-null    float64\n",
      " 21  b2_dp0_p99     115 non-null    float64\n",
      " 22  b2_dp0_range   115 non-null    float64\n",
      " 23  b3_dp0_min     115 non-null    float64\n",
      " 24  b3_dp0_max     115 non-null    float64\n",
      " 25  b3_dp0_mean    115 non-null    float64\n",
      " 26  b3_dp0_count   115 non-null    float64\n",
      " 27  b3_dp0_med     115 non-null    float64\n",
      " 28  b3_dp0_p25     115 non-null    float64\n",
      " 29  b3_dp0_p50     115 non-null    float64\n",
      " 30  b3_dp0_p75     115 non-null    float64\n",
      " 31  b3_dp0_p95     115 non-null    float64\n",
      " 32  b3_dp0_p99     115 non-null    float64\n",
      " 33  b3_dp0_range   115 non-null    float64\n",
      " 34  b3_dp0_std     115 non-null    float64\n",
      "dtypes: float64(34), object(1)\n",
      "memory usage: 32.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[df['bio_agb_kg1ha']==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 35)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = col_list[4]\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "\n",
    "\n",
    "bio_list = df['bio_agb_kg1ha'].tolist()\n",
    "print(bio_list)\n",
    "print('-'*50)\n",
    "site_list = df['site'].tolist()\n",
    "print(site_list)\n",
    "print('-'*50)\n",
    "var_list = df[variable].tolist()\n",
    "print(var_list)\n",
    "print('-'*50)\n",
    "bio_max = max(bio_list)*1.4\n",
    "print(bio_max)\n",
    "print('-'*50)\n",
    "var_max = max(var_list)*1.4\n",
    "print(var_max)\n",
    "print('-'*50)\n",
    "dict_=dict(\n",
    "    agb= bio_list,\n",
    "    var = var_list,\n",
    "    names=site_list)\n",
    "\n",
    "print(dict_)\n",
    "dict_[variable] = dict_.pop('var')\n",
    "dict_\n",
    "print(dict_)\n",
    "\n",
    "print(type(variable))\n",
    "source = ColumnDataSource(data=dict_)\n",
    "\n",
    "#dictionary[new_key] = dictionary.pop(old_key)\n",
    "\n",
    "p = figure(x_range=(var_max, bio_max))\n",
    "p.scatter(x='agb', y=variable, size=8, source=source)\n",
    "p.xaxis.axis_label = 'AGB'\n",
    "p.yaxis.axis_label = variable\n",
    "\n",
    "labels = LabelSet(x='agb', y=variable, text='names', level='glyph',\n",
    "                  x_offset=5, y_offset=5, source=source, render_mode='canvas')\n",
    "\n",
    "\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df.columns[1:]:\n",
    "    print(i)\n",
    "    value_x = 'bio_agb_kg1ha'\n",
    "    value_y = str(i)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    # left plot\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.regplot(df[value_x], df[value_y], line_kws={\"color\":\"red\"})\n",
    "    plt.xlabel(value_x)\n",
    "    plt.ylabel(value_y)\n",
    "    plt.title(\"Regression {0} and {1}\".format(value_x, value_y))\n",
    "    \n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df[value_x], df[value_y])\n",
    "\n",
    "    print(\"slope: \", slope)\n",
    "    print(\"intersept: \", intercept)\n",
    "    print(\"r2: \", r_value)\n",
    "    print(\"P_value: \", p_value)\n",
    "    print(\"std error: \", std_err)\n",
    "\n",
    "    # right plot\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.regplot(df[value_x], df[value_y], lowess=True, line_kws={\"color\":\"green\"})\n",
    "    plt.xlabel(value_x)\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.title(\"Residual Error {0} and {1}\".format(value_x, value_y))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#     slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df[value_x], df[value_y])\n",
    "\n",
    "#     print(\"slope: \", slope)\n",
    "#     print(\"intersept: \", intercept)\n",
    "#     print(\"r2: \", r_value)\n",
    "#     print(\"P_value: \", p_value)\n",
    "#     print(\"std error: \", std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_x = 'bio_agb_kg1ha'\n",
    "value_y = 'b2_dbi_mean'\n",
    "sns.regplot(x= value_x, y=value_y, data=df)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df[value_x], df[value_y])\n",
    "\n",
    "print(\"slope: \", slope)\n",
    "print(\"intersept: \", intercept)\n",
    "print(\"r2: \", r_value)\n",
    "print(\"P_value: \", p_value)\n",
    "print(\"std error: \", std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_x = 'bio_agb_kg1ha'\n",
    "value_y = 'b3_dbi_mean'\n",
    "sns.scatterplot(x= value_x, y=value_y, data=df)\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df[value_x], df[value_y])\n",
    "\n",
    "print(\"slope: \", slope)\n",
    "print(\"intersept: \", intercept)\n",
    "print(\"r2: \", r_value)\n",
    "print(\"P_value: \", p_value)\n",
    "print(\"std error: \", std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into train and test datasets, the user needs to define the variables \n",
    "\n",
    "# Two example of how you can call the predictor variables \n",
    "\n",
    "#xdata1 = df4[df4.columns[12:]].astype('float32')\n",
    "\n",
    "#xdata1 = df[['psB2a', 'psB3a', 'psB4a', 'psB5a', 'psB6a', 'ratio32a', 'ratio42a', 'ratio43a', 'ratio52a', 'ratio53a', 'ratio54a', 'ratio62a', 'ratio63a', 'ratio64a', 'ratio65a', 'GSAVIa', 'GNDVIa', 'CVIa', 'NDGIa', 'RIa', 'NBRa', 'NDIIa', 'GDVIa', 'MSAVIa', 'DVIa', 'SAVIa', 'NDVIa', 'MSRa', 'psB2d', 'psB3d', 'psB4d', 'psB5d', 'psB6d', 'ratio32d', 'ratio42d', 'ratio43d', 'ratio52d', 'ratio53d', 'ratio54d', 'ratio62d', 'ratio63d', 'ratio64d', 'ratio65d', 'GSAVId', 'GNDVId', 'CVId', 'NDGId', 'RId', 'NBRd', 'NDIId', 'GDVId', 'MSAVId', 'DVId', 'SAVId', 'NDVId', 'MSRd']].astype('float32')\n",
    "#xdata1 = df[['psB1a', 'psB2a', 'psB3a', 'psB4a', 'psB5a', 'psB6a', 'ratio32fa', 'ratio42fa', 'ratio43fa', 'ratio52fa', 'ratio53fa', 'ratio54fa', 'ratio62fa', 'ratio63fa', 'ratio64fa', 'ratio65fa', 'ratio32a', 'ratio42a', 'ratio43a', 'ratio52a', 'ratio53a', 'ratio54a', 'ratio62a', 'ratio63a', 'ratio64a', 'ratio65a', 'GSAVIfa', 'GSAVIa', 'GNDVIfa', 'GNDVIa', 'CVIfa', 'CVIa', 'NDGIfa', 'NDGIa', 'RIfa', 'RIa', 'NBRfa', 'NBRa', 'NDIIfa', 'NDIIa', 'GDVIfa', 'GDVIa', 'MSAVIfa', 'MSAVIa', 'DVIfa', 'DVIa', 'SAVIfa', 'SAVIa', 'NDVIfa', 'NDVIa', 'MSRfa', 'MSRa']]\n",
    "xdata1 = df.iloc[:, 1:].astype('float32')\n",
    "ydata1 = df[['bio_agb_kg1ha']].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata = ydata2.ravel()\n",
    "\n",
    "X_1, X_2, y_1, y_2 = train_test_split(xdata1, ydata, train_size=0.80)  \n",
    "         \n",
    "print(X_1.shape, y_1.shape)\n",
    "print(X_2.shape, y_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot up Histograms of Lidar meanCHM for train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(y_1)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(y_2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterise the Random Forest Regressor alogorthim\n",
    "\n",
    "for details see: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "rfrModel_1 = abr(dtr(max_depth=4), n_estimators=300, random_state=rng)\n",
    "rfrModel_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfrModel_1 = gbr(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0, loss='ls')\n",
    "rfrModel_1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfrModel_1 = etr(n_estimators=100, bootstrap=True, oob_score=True,  max_features='log2', min_samples_split=1,n_jobs=-1) \n",
    "rfrModel_1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfrModel_1 = rfr(n_estimators=100, oob_score=True,  max_depth=None, max_features='log2', min_samples_split=1.0,n_jobs=-1) \n",
    "rfrModel_1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfrModel_1 = rfr(n_estimators=100, oob_score=True) #,  max_depth=None, max_features='log2', min_samples_split=1.0,n_jobs=-1) \n",
    "rfrModel_1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan_to_num(X_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit random forest regressor model and compute variable importance score \n",
    "\n",
    "may need to restrict the number of variables for the bar graph to be legible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfrLCHM = rfrModel_1.fit(X_1, y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### good info on the feature importance score - http://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rfrModel_1.feature_importances_\n",
    "\n",
    "### TRY THIS\n",
    "# use \"feature importance\" scores to see what the top 10 important features are\n",
    "fi = enumerate(rfrModel_1.feature_importances_)\n",
    "cols = xdata1.columns\n",
    "fiResult = [(value,cols[i]) for (i,value) in fi]\n",
    "#fiResult = [(value,cols[i]) for (i,value) in fi if value > 0.001]\n",
    "## Change the value 0.04 which we picked empirically to give us 10 variables\n",
    "## try running this code after changing the value up and down so you get more or less variables\n",
    "## do you see how this might be useful in refining the model?\n",
    "## Here is the code in case you mess up the line above\n",
    "## [(value,cols[i]) for (i,value) in fi if value > 0.04]\n",
    "#print fiResult\n",
    "\n",
    "print('Fitted model r2 =' ,  format(rfrLCHM.score(X_1, y_1), '.2f'))\n",
    "print('Fitted model mse =', format(np.mean((y_1 - rfrLCHM.predict(X_1))**2), '.2f'))\n",
    "print('n =', len(y_1))\n",
    "plt.scatter(rfrLCHM.predict(X_1), y_1,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [0,100]\n",
    "y = [0,100]\n",
    "\n",
    "#sets the limits of the axis\n",
    "#plt.xlim(-1,35)\n",
    "#plt.ylim(-1,35)\n",
    "\n",
    "plt.ylabel('Observed AGB')\n",
    "\n",
    "plt.xlabel('Predicted AGB')\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiResult = np.array(fiResult)\n",
    "score = (fiResult[:,0])\n",
    "band = fiResult[:,1]\n",
    "a = fiResult[np.argsort(fiResult[:, 1])]\n",
    "\n",
    "df = pd.DataFrame(dict(band=band,n=score))\n",
    "#print(df)\n",
    "df['n'].astype('float')\n",
    "#df.convert_objects(convert_numeric=True).dtypes()\n",
    "#ind = np.arange(len(df))\n",
    "dfsort = df.sort_values(['n'], ascending=[False])\n",
    "print(dfsort)\n",
    " \n",
    "## my complicated way to get the bar plot to sort in ascending order and display the assocated band names in the y axis\n",
    " \n",
    "dfsort2 = df.sort_values(['n'], ascending=[True])\n",
    "b = dfsort2[['band']]\n",
    "c = b.values.tolist()\n",
    "# convert the list of band names in the correct order to a string\n",
    "e = str(c)\n",
    "# strips all the rubbish from the string\n",
    "f = e.replace('[','').replace(']','').replace(\"'\",'').replace(\",\",' ')\n",
    "# convert the cleaned up string back into a list to plot the band names in the bar graph\n",
    "g = f.split()\n",
    " \n",
    "ind = np.arange(len(df))\n",
    "width = 0.4\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(ind, dfsort2.n, width, color='blue')\n",
    "ax.set(yticks=ind + width, yticklabels= g, ylim=[2*width - 1, len(df)])\n",
    "plt.show()\n",
    "fig.savefig('Band_Importance_Score.pdf',dpi=600)# save out your figure to a pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the selected model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y2_predict, y_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_predict = rfrLCHM.predict(X_2)\n",
    "\n",
    "print('Predicted data r2 =', rfrLCHM.score(X_2, y_2))\n",
    "print('MSE =', format(np.mean((y_2 - rfrLCHM.predict(X_2))** 2), '.3f'))\n",
    "print('RMSE =', format(np.sqrt(np.mean((y2_predict - y_2) ** 2)), '.3f'))\n",
    "#print 'explained_var =',format(explained_variance_score(y_2, y2_predict),  '.3f') \n",
    "print('bias =' , format(np.mean(y_2) - np.mean(y2_predict), '.3f'))\n",
    "print('n =' , len(y_2))\n",
    "\n",
    "plt.scatter(y2_predict, y_2 ,s=10, c='b', marker='o')\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30000]\n",
    "y = [-1,30000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30000)\n",
    "plt.ylim(-1, 30000)\n",
    "plt.ylabel('Observed mean AGB')\n",
    "plt.xlabel('Predicted mean AGB')\n",
    "# 1 for 1 line\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = y2_predict\n",
    "y = y_2\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=0.8, edgecolor='')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "a = [-1,25]\n",
    "b = [-1,25]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,25)\n",
    "plt.ylim(-1,25)\n",
    "plt.ylabel('Observed mean CHM')\n",
    "plt.xlabel('Predicted mean CHM')\n",
    "# 1 for 1 line\n",
    "ax.plot(a, b, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP - do you realy want to save this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remember to change the cPickle file name !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save current fitted model and apply to unseen validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle\n",
    "\n",
    "#rfrL8CHM = rfr()\n",
    "#rfrL8CHM.fit(X_1, y_1)\n",
    "\n",
    "with open('rfr_modelName_nt100_n17', 'wb') as f:\n",
    "    cPickle.dump(rfrLCHM, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in your validation dataset which has never been seen by rfr model - NOTE in this example I am just reading the same data used to train the model\n",
    "\n",
    "df = pd.read_csv('combined_val_data_l5_l7_l8.csv', header=0)\n",
    "print df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df[(df['comp'] == 'l57')]\n",
    "df1 = df[(df['chm'] >= 4)]\n",
    "\n",
    "print (df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata2 = df1[['dem', 'ratio42', 'psB5', 'CVI', 'ratio43', 'psB2', 'ratio54', 'SAVI', 'ratio53', 'ratio52', 'psB3', 'GSAVI', 'ratio65', 'ratio63', 'ratio62', 'psB4', 'ratio32']].astype('float32')\n",
    "\n",
    "ydata1 = df1[['chm']].astype('float32')\n",
    "\n",
    "ydata2 = ydata1.values\n",
    "\n",
    "ydata = ydata2.ravel()\n",
    "\n",
    "print len(ydata1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfr_modelName_mKath', 'rb') as f:\n",
    "        rf = cPickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print 'Predicted data r2 =', rf.score(xdata2, ydata)\n",
    "print 'MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f')\n",
    "print 'RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f')\n",
    "print 'explained_var =',format(explained_variance_score(ydata, predicted),  '.3f') \n",
    "print 'bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f')\n",
    "print 'n =' , len(ydata)\n",
    "\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=0.002, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30]\n",
    "y = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 30)\n",
    "plt.ylim(-1, 30)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "fig.savefig('predicted_Observed_Validation_78.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = predicted\n",
    "y = ydata\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=0.5, edgecolor='')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "a = [-1,30]\n",
    "b = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30)\n",
    "plt.ylim(-1,30)\n",
    "plt.ylabel('Observed mean CHM')\n",
    "plt.xlabel('Predicted mean CHM')\n",
    "# 1 for 1 line\n",
    "ax.plot(a, b, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfr_modelName_mKath', 'rb') as f:\n",
    "        rf = cPickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print 'Predicted data r2 =', rf.score(xdata2, ydata)\n",
    "print 'MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f')\n",
    "print 'RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f')\n",
    "print 'explained_var =',format(explained_variance_score(ydata, predicted),  '.3f') \n",
    "print 'bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f')\n",
    "print 'n =' , len(ydata)\n",
    "\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=0.002, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30]\n",
    "y = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 30)\n",
    "plt.ylim(-1, 30)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "fig.savefig('predicted_Observed_Validation_l57.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = predicted\n",
    "y = ydata\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=0.5, edgecolor='')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "a = [-1,30]\n",
    "b = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30)\n",
    "plt.ylim(-1,30)\n",
    "plt.ylabel('Observed mean CHM')\n",
    "plt.xlabel('Predicted mean CHM')\n",
    "# 1 for 1 line\n",
    "ax.plot(a, b, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfr_modelNamel57', 'rb') as f:\n",
    "        rf = cPickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print 'Predicted data r2 =', rf.score(xdata2, ydata)\n",
    "print 'MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f')\n",
    "print 'RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f')\n",
    "print 'explained_var =',format(explained_variance_score(ydata, predicted),  '.3f') \n",
    "print 'bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f')\n",
    "print 'n =' , len(ydata)\n",
    "\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=0.002, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30]\n",
    "y = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 30)\n",
    "plt.ylim(-1, 30)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "fig.savefig('predicted_Observed_Validation.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = predicted\n",
    "y = ydata\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=0.5, edgecolor='')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "a = [-1,30]\n",
    "b = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30)\n",
    "plt.ylim(-1,30)\n",
    "plt.ylabel('Observed mean CHM')\n",
    "plt.xlabel('Predicted mean CHM')\n",
    "# 1 for 1 line\n",
    "ax.plot(a, b, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfr_modelNamel57', 'rb') as f:\n",
    "        rf = cPickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print 'Predicted data r2 =', rf.score(xdata2, ydata)\n",
    "print 'MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f')\n",
    "print 'RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f')\n",
    "print 'explained_var =',format(explained_variance_score(ydata, predicted),  '.3f') \n",
    "print 'bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f')\n",
    "print 'n =' , len(ydata)\n",
    "\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=0.002, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30]\n",
    "y = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 30)\n",
    "plt.ylim(-1, 30)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "fig.savefig('predicted_Observed_Validationgtr4m.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = predicted\n",
    "y = ydata\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=0.5, edgecolor='')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "a = [-1,30]\n",
    "b = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30)\n",
    "plt.ylim(-1,30)\n",
    "plt.ylabel('Observed mean CHM')\n",
    "plt.xlabel('Predicted mean CHM')\n",
    "# 1 for 1 line\n",
    "ax.plot(a, b, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfr_modelNamel78', 'rb') as f:\n",
    "        rf = cPickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print 'Predicted data r2 =', rf.score(xdata2, ydata)\n",
    "print 'MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f')\n",
    "print 'RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f')\n",
    "print 'explained_var =',format(explained_variance_score(ydata, predicted),  '.3f') \n",
    "print 'bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f')\n",
    "print 'n =' , len(ydata)\n",
    "\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=0.002, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30]\n",
    "y = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 30)\n",
    "plt.ylim(-1, 30)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "fig.savefig('predicted_Observed_Validation.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
