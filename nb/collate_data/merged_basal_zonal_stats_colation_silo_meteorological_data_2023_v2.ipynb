{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged meteorological AGB zonal stats colation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook looks for zonal stats subdirectories and the zonal stats csv outputs within them and concatenates all files into one data frame which is exported as a csv to the output directory.\n",
    "\n",
    "The following conditions apply:\n",
    "\n",
    " - run after Seasonal Biomass Zonal Pipeline.\n",
    " - env = base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "from calendar import monthrange\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # processing date\n",
    "# date = \"20230104\"\n",
    "# # date of data exports\n",
    "# field_date = \"20230103\"\n",
    "# # out_date\n",
    "# out_date = \"20230109\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing date\n",
    "date = \"20230407\"\n",
    "# date of data exports\n",
    "field_date = \"20230407\"\n",
    "# out_date\n",
    "out_date = \"20230407\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basal = r\"F:\\cdu\\data\\output\\{0}\\slats_tern_biomass.csv\".format(field_date)\n",
    "basal_df = pd.read_csv(basal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = r\"F:\\cdu\\data\\zonal_stats\\meterological\\gr_meteorological_20230104_0840\"\n",
    "output_dir = r\"F:\\cdu\\data\\zonal_stats\\output\\{0}\".format(out_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_seasonal_date(date_):\n",
    "    \"\"\" extract the end dates of the seasonal image zonal stats.\"\"\"\n",
    "    \n",
    "    year = date_[:4]\n",
    "    month = date_[4:]\n",
    "    \n",
    "    start_date = str(year) + str(month) + \"01\"\n",
    "    \n",
    "    return start_date\n",
    "    \n",
    "\n",
    "def end_seasonal_date(date_):\n",
    "    \n",
    "    \"\"\" extract the start dates of the seasonal image zonal stats.\"\"\"\n",
    "    #print(\"date: \", date_)\n",
    "    year = str(date_[:4])\n",
    "    month = str(date_[4:])\n",
    "    #print(\"month: \", month)\n",
    "    \n",
    "    month_, day_range = monthrange(int(year), int(month))\n",
    "    end_date = str(year) + str(month) + str(day_range)\n",
    "    #print(end_date)\n",
    "    return end_date\n",
    "\n",
    "\n",
    "def im_date_season(df):\n",
    "    \"\"\"Collate start date of image into im_date column\"\"\"\n",
    "    \n",
    "    st_date_list = []\n",
    "    e_date_list = []\n",
    "    for i in df.im_name:\n",
    "        #print(i)\n",
    "        list_name = i.split(\"_\")\n",
    "        date = list_name[-2]\n",
    "        st_date = date[1:7]\n",
    "        start_date = start_seasonal_date(st_date)\n",
    "        st_date_list.append(start_date)\n",
    "        \n",
    "        e_date = date[7:] \n",
    "        end_date = end_seasonal_date(e_date)\n",
    "        e_date_list.append(end_date)\n",
    "        \n",
    "    df[\"im_s_date\"] = st_date_list\n",
    "    df[\"im_e_date\"] = e_date_list\n",
    "    \n",
    "    return df\n",
    "        \n",
    "    \n",
    "def im_date_annual(df):\n",
    "    \"\"\"Collate start date of image into im_date column\"\"\"\n",
    "    \n",
    "    st_date_list = []\n",
    "    e_date_list = []\n",
    "    for i in df.im_name:\n",
    "        #print(i)\n",
    "        list_name = i.split(\"_\")\n",
    "        date = list_name[-2]\n",
    "        st_date = str(date) + \"01\"\n",
    "        start_date = start_seasonal_date(st_date)\n",
    "        st_date_list.append(start_date)\n",
    "        \n",
    "        e_date = str(date) + \"12\"\n",
    "        end_date = end_seasonal_date(e_date)\n",
    "        e_date_list.append(end_date)\n",
    "        \n",
    "    df[\"im_s_date\"] = st_date_list\n",
    "    df[\"im_e_date\"] = e_date_list\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "def convert_to_datetime(df, col_nm_s, col_nm_d):\n",
    "    \n",
    "    date_list = []\n",
    "    for i in df[col_nm_s]:\n",
    "        #print(i)\n",
    "        datetime_object = datetime.strptime(str(i), '%Y%m%d')\n",
    "        date_list.append(datetime_object)\n",
    "        print(datetime_object)\n",
    "        #df[col_nm_d] =  pd.to_datetime(df[col_nm_s], format='%Y%m%d.%f')\n",
    "        #date_time = now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    df[col_nm_d] = date_list\n",
    "    return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basal_df = convert_to_datetime(basal_df, \"date\", \"basal_dt\")\n",
    "basal_df.sort_values(by='basal_dt', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basal_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_dir_fn(output_dir, pos):\n",
    "    temp_dir = os.path.join(output_dir, \"{0}_temp\".format(pos))\n",
    "    \n",
    "    if not os.path.isdir(temp_dir):\n",
    "        os.mkdir(temp_dir)\n",
    "    \n",
    "    return temp_dir\n",
    "\n",
    "def out_file_fn(temp_dir, pos, sub_dir, df__):\n",
    "    out_file = os.path.join(temp_dir, \"{0}_{1}_zonal_stats.csv\".format(pos, sub_dir))\n",
    "    df__.to_csv(os.path.join(temp_dir, out_file), index=False)\n",
    "    print(\"output: \", out_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a list of subdirectories from the qld meterological zonal stats\n",
    "sub_list = next(os.walk(dir_))[1]\n",
    "sub_list\n",
    "\n",
    "\n",
    "working_sub_list = sub_list[19:20]\n",
    "zonal_list = []\n",
    "sub_dir_list = []\n",
    "for sub_dir in working_sub_list:\n",
    "    file_list = []\n",
    "    #print(sub_dir)\n",
    "    sub_dir_path = os.path.join(dir_, sub_dir)\n",
    "    sub_dir_df_list = []\n",
    "    for file_ in glob(os.path.join(sub_dir_path, \"*.csv\")):\n",
    "        if \"zonal_stats\" in file_:\n",
    "            sub_dir_list.append(file_)\n",
    "            print(file_)\n",
    "\n",
    "            df = pd.read_csv(file_)\n",
    "            df = convert_to_datetime(df, \"im_date\", \"image_dt\")\n",
    "            df.sort_values(by='image_dt', inplace=True)\n",
    "            print(df.columns)\n",
    "            sub_dir_df_list.append(df)\n",
    "    df1 = pd.concat(sub_dir_df_list)\n",
    "    \n",
    "    # sort values\n",
    "    df1.sort_values(by=\"im_date\", inplace=True)\n",
    "    \n",
    "    # drop null values on minimum column\n",
    "    df_columns = df1.columns.tolist()\n",
    "    min_column = [columns for columns in df_columns if \"min\" in columns]\n",
    "    print(\"Min column: \", min_column)\n",
    "    df1.dropna(subset = min_column, inplace=True)\n",
    "    \n",
    "\n",
    "    #merge data with basal datset based on the nearest date to the field data colection\n",
    "    n_df = pd.merge_asof(basal_df, df1, left_on=\"basal_dt\", right_on= \"image_dt\", by=\"site\", direction=\"nearest\")\n",
    "    f_df = pd.merge_asof(basal_df, df1, left_on=\"basal_dt\", right_on= \"image_dt\", by=\"site\", direction=\"forward\")\n",
    "    b_df = pd.merge_asof(basal_df, df1, left_on=\"basal_dt\", right_on= \"image_dt\", by=\"site\", direction=\"backward\")\n",
    "        \n",
    "    # create temp dirs    \n",
    "    n_temp_dir = temp_dir_fn(output_dir, \"near\")\n",
    "    f_temp_dir = temp_dir_fn(output_dir, \"for\")\n",
    "    b_temp_dir = temp_dir_fn(output_dir, \"back\")\n",
    "    \n",
    "    # export csv\n",
    "    out_file_fn(n_temp_dir, \"near\", sub_dir, n_df)\n",
    "    out_file_fn(f_temp_dir, \"for\", sub_dir, f_df)\n",
    "    out_file_fn(b_temp_dir, \"back\", sub_dir, b_df)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob_fn(temp_dir):\n",
    "    csv_list = []\n",
    "    for f in glob(os.path.join(temp_dir, \"*.csv\")):\n",
    "        \n",
    "        df__ = pd.read_csv(f)\n",
    "        csv_list.append(df__)\n",
    "    final_df = pd.concat(csv_list, axis=1)\n",
    "    \n",
    "\n",
    "    return final_df\n",
    "        \n",
    "def export_fn(output_dir, pos, dff):\n",
    "    out = os.path.join(output_dir, \"{0}_met_zonal_stats.csv\".format(pos))\n",
    "    dff.to_csv((out), index=False)\n",
    "    print(\"output to: \", out)\n",
    "    \n",
    "    \n",
    "def drop_cols_fn(df):\n",
    "    df1 = df.copy()\n",
    "    df_columns = df.columns.tolist()\n",
    "#     print(df_columns)\n",
    "#     print(\"-\"*100)\n",
    "\n",
    "    drop_list = [columns for columns in df_columns if \"mean\" not in columns]\n",
    "\n",
    "#     print(len(drop_list))\n",
    "#     drop_list.remove(\"site\")\n",
    "#     drop_list.remove(\"bio_agb_kg1ha\")\n",
    "#     print(\"length of drop: \", len(drop_list))\n",
    "#     print(\"mean column: \", mean_column)\n",
    "#     test = mean_column\n",
    "#     print(\"test: \", test)\n",
    "    df.drop(drop_list, axis = 1, inplace=True)\n",
    "    \n",
    "    var_ = df1.iloc[:, [1, 12]]\n",
    "    df_out = pd.concat([var_, df], axis=1)\n",
    "    \n",
    "    return df_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_temp_dir = r\"F:\\cdu\\data\\zonal_stats\\output\\20230104\\near_temp\"\n",
    "f_temp_dir = r\"F:\\cdu\\data\\zonal_stats\\output\\20230104\\for_temp\"\n",
    "b_temp_dir = r\"F:\\cdu\\data\\zonal_stats\\output\\20230104\\back_temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output to:  F:\\cdu\\data\\zonal_stats\\output\\20230109\\near_met_zonal_stats.csv\n",
      "output to:  F:\\cdu\\data\\zonal_stats\\output\\20230109\\cleaned_near_met_zonal_stats.csv\n",
      "output to:  F:\\cdu\\data\\zonal_stats\\output\\20230109\\for_met_zonal_stats.csv\n",
      "output to:  F:\\cdu\\data\\zonal_stats\\output\\20230109\\cleaned_for_met_zonal_stats.csv\n",
      "output to:  F:\\cdu\\data\\zonal_stats\\output\\20230109\\back_met_zonal_stats.csv\n",
      "output to:  F:\\cdu\\data\\zonal_stats\\output\\20230109\\cleaned_back_met_zonal_stats.csv\n"
     ]
    }
   ],
   "source": [
    "n_final_df = glob_fn(n_temp_dir)\n",
    "export_fn(output_dir, \"near\", n_final_df)\n",
    "df1 = drop_cols_fn(n_final_df)\n",
    "export_fn(output_dir, \"cleaned_near\", df1)\n",
    "\n",
    "f_final_df = glob_fn(f_temp_dir)\n",
    "export_fn(output_dir, \"for\", f_final_df)\n",
    "df1 = drop_cols_fn(f_final_df)\n",
    "export_fn(output_dir, \"cleaned_for\", df1)\n",
    "\n",
    "b_final_df = glob_fn(b_temp_dir)\n",
    "export_fn(output_dir, \"back\", b_final_df)\n",
    "df1 = drop_cols_fn(b_final_df)\n",
    "export_fn(output_dir, \"cleaned_back\", df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
