{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess model performance - collate data using script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C:\\Users\\robot\\code\\ml\\landsat\\collate_validation_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!conda info"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display, Markdown\n",
    "%matplotlib inline\n",
    "\n",
    "# Disable scientific notation for pandas display\n",
    "pd.set_option('display.float_format', lambda x: '%.10f' % x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Directory path to search through\n",
    "directory_ = r'H:\\biomass'\n",
    "model_run = \"test_train_all04_05\"\n",
    "model_run = \"model_all01_02_03_04_05_06_v2\"\n",
    "\n",
    "\n",
    "directory_path = os.path.join(directory_, f\"model_{model_run}\")\n",
    "\n",
    "combined_df = pd.read_csv(os.path.join(directory_path, \"total_metrics.csv\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Directory path to search through\n",
    "# directory_ = r'H:\\biomass'\n",
    "# model_run = \"test_train_mlp\"\n",
    "# model_run = \"test_train_all04_05\"\n",
    "# \n",
    "# directory_path = os.path.join(directory_, f\"{model_run}\")\n",
    "# \n",
    "# combined_df = pd.read_csv(os.path.join(directory_path, \"total_metrics.csv\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into groups based on status"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "retrain_df = combined_df[combined_df[\"status\"]==\"retrain\"]\n",
    "retest_df = combined_df[combined_df[\"status\"]==\"retest\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "retest_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Validation and Train together"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_merged = pd.merge(retrain_df, retest_df, on=['mdl', 'model', 'sel_num', 'fac', 'var', 'file', 'stats', 'data', 'stdev'], how='outer')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Rename columns containing \"_x\" to \"validation\" and \"_y\" to \"train\"\n",
    "df_merged.columns = df_merged.columns.str.replace('_x', '_retrain').str.replace('_y', '_retest')\n",
    "df_merged"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_best_model(df, model_run, model, var, data, std, display_limit):\n",
    "    #df = df.sort_values(by=['rmse_retest', 'r2_retest', 'rmse_retrain', 'r2_retrain'], ascending=[True, False, True, False])\n",
    "    df = df.sort_values(by=['rmse_retest'], ascending=[True])\n",
    "\n",
    "    # Generate the Windows path\n",
    "    df[\"file_path\"] = (\n",
    "        f\"H:/biomass/model_{model_run}/AGB/\" +\n",
    "        df['var'].astype(str) + \"/\" +\n",
    "        df['mdl'].astype(str) + \"/\" +\n",
    "        df['stats'].astype(str) + \"/std\" +\n",
    "        #df['stdev'].astype(str) + \"/\" +\n",
    "        df['stdev'].astype(int).astype(str) + \"/\" + \n",
    "        df['data'].astype(str) + \"/\" +\n",
    "        df['fac'].astype(str) + \"/sel_num_\" +\n",
    "        df['sel_num'].astype(str).str[:2]\n",
    "    )\n",
    "\n",
    "    # Loop through each row in the DataFrame and print out the relevant information\n",
    "    for i, row in enumerate(df.itertuples(index=False)):\n",
    "\n",
    "        # Limit the number of displayed image sets to prevent memory overload\n",
    "        if i >= display_limit:\n",
    "            print(\"Display limit reached. Adjust the display limit to see more images.\")\n",
    "            break  # Stop after showing the defined number of image sets\n",
    "\n",
    "        # Extract validation and test (retest) metrics from the row\n",
    "        test_metrics = {\n",
    "            'R² (retest)': getattr(row, 'r2_retest', np.nan),\n",
    "            'MSE (retest)': getattr(row, 'mse_retest', np.nan),\n",
    "            'RMSE (retest)': getattr(row, 'rmse_retest', np.nan),\n",
    "            'MAE (retest)': getattr(row, 'mae_retest', np.nan),\n",
    "            'MAPE (retest)': getattr(row, 'mape_retest', np.nan),\n",
    "            'Bias (retest)': getattr(row, 'bias_retest', np.nan),\n",
    "            'N (retest)': getattr(row, 'n_retest', np.nan)\n",
    "        }\n",
    "\n",
    "        retrain_metrics = {\n",
    "            'R² (retrain)': getattr(row, 'r2_retrain', np.nan),\n",
    "            'MSE (retrain)': getattr(row, 'mse_retrain', np.nan),\n",
    "            'RMSE (retrain)': getattr(row, 'rmse_retrain', np.nan),\n",
    "            'MAE (retrain)': getattr(row, 'mae_retrain', np.nan),\n",
    "            'MAPE (retrain)': getattr(row, 'mape_retrain', np.nan),\n",
    "            'Bias (retrain)': getattr(row, 'bias_retrain', np.nan),\n",
    "            'N (retrain)': getattr(row, 'n_retrain', np.nan)\n",
    "        }\n",
    "\n",
    "        # Generate and display images (retest and validation as before)\n",
    "        path = row.file_path\n",
    "        print(f\"Path: {path}\")\n",
    "\n",
    "        # Log the path being used to ensure the correct images are selected\n",
    "        #print(f\"Looking for image files in: {path}\")\n",
    "\n",
    "        # Split the path after \"AGB\" and keep the rest of the path\n",
    "        base, after_agb = path.split(\"AGB\", 1)\n",
    "\n",
    "        # Replace forward slashes with underscores in the part after \"AGB\"\n",
    "        after_agb_modified = after_agb.replace(\"/\", \"_\")\n",
    "        df.at[i, \"apply_mdl\"] = after_agb_modified[1:]  # Update the DataFrame\n",
    "        print(f\"If using - create directory: {after_agb_modified[1:]}\")\n",
    "\n",
    "        # Locate the directory and find files ending with retest.JPG and validation.JPG\n",
    "        search_path = os.path.join(path, \"*.JPG\")  # Search for all JPG files in the directory\n",
    "\n",
    "        # Get all JPG files\n",
    "        jpg_files = glob.glob(search_path)\n",
    "\n",
    "        # Filter for files ending with retest.JPG and validation.JPG\n",
    "        retest_files = [file for file in jpg_files if file.endswith(\"retest.JPG\")]\n",
    "        retrain_files = [file for file in jpg_files if file.endswith(\"retrain.JPG\")]\n",
    "\n",
    "        # Log file paths to check which files are being imported\n",
    "        if retest_files:\n",
    "            print(f\" - Retest Image found: {retest_files[0]}\")\n",
    "            #print(retest_files)\n",
    "        else:\n",
    "            print(\"No Retest Image found.\")\n",
    "            print(\"ERROR --\"*50)\n",
    "\n",
    "        if retrain_files:\n",
    "            print(f\" - retrain Image found: {retrain_files[0]}\")\n",
    "            #print(retrain_files)\n",
    "        else:\n",
    "            print(\"No retrain Image found.\")\n",
    "            print(\"ERROR --\"*50)\n",
    "\n",
    "        # **NEW** Search for files ending with retrain_distribution.JPG two sub-directories above the original path\n",
    "        distribution_dir = os.path.abspath(os.path.join(path, \"../..\"))  # Two directories above\n",
    "        distribution_search_path = os.path.join(distribution_dir, \"*retrain_distribution.JPG\")\n",
    "\n",
    "        # Check if the retrain_distribution.JPG exists\n",
    "        distribution_files = glob.glob(distribution_search_path)  # Search for the file\n",
    "\n",
    "        #print(\"distribution_files: \", distribution_files)\n",
    "        if len(distribution_files) > 0:\n",
    "            #print(f\"retrain Distribution Plot found at: {distribution_files[0]}\")\n",
    "            fig, ax = plt.subplots(figsize=(10, 8), dpi=150)  # Increase size and DPI for better quality\n",
    "            retrain_distribution_img = mpimg.imread(distribution_files[0])\n",
    "            ax.imshow(retrain_distribution_img)\n",
    "            ax.set_title('retrain Distribution Plot', fontsize=16)  # Increased font size\n",
    "            ax.axis('off')  # Turn off axis display\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Plot the found JPG files (retest and retrain) side by side\n",
    "        if retest_files or retrain_files:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 6), dpi=150)  # Larger figure and higher DPI\n",
    "\n",
    "            # Load and display the retest image (if available)\n",
    "            if retest_files:\n",
    "                retest_img = mpimg.imread(retest_files[0])\n",
    "                axes[0].imshow(retest_img)\n",
    "                axes[0].set_title('Retest Image', fontsize=16)  # Increased font size\n",
    "                axes[0].axis('off')  # Turn off axis display\n",
    "            else:\n",
    "                axes[0].axis('off')  # Leave the subplot blank if no image is available\n",
    "\n",
    "            # Load and display the retrain image (if available)\n",
    "            if retrain_files:\n",
    "                retrain_img = mpimg.imread(retrain_files[0])\n",
    "                axes[1].imshow(retrain_img)\n",
    "                axes[1].set_title('retrain Image', fontsize=16)  # Increased font size\n",
    "                axes[1].axis('off')  # Turn off axis display\n",
    "            else:\n",
    "                axes[1].axis('off')  # Leave the subplot blank if no image is available\n",
    "\n",
    "            # Adjust layout and show the images\n",
    "            plt.tight_layout(pad=2.0)  # Add padding between images\n",
    "            plt.show()\n",
    "\n",
    "            # Clear the figure from memory after displaying it\n",
    "            plt.close()\n",
    "            print(\"-\" * 100)\n",
    "            # Print the test and retrain metrics for comparison\n",
    "            print(f\"Test Metrics vs retrain Metrics for row {i}:\")\n",
    "            # for metric in test_metrics:\n",
    "            #     print(f\"{metric}: {test_metrics[metric]}\"  |  {retrain_metric_name}: {retrain_metrics.get(retrain_metric_name, 'N/A')}\")\n",
    "\n",
    "            print(\"=\"*100)\n",
    "        # Print the relevant features\n",
    "        print(f\"Features Used: {row.features_retest}\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "    print(\"exported to: \", r\"C:\\Users\\robot\\code\\pipelines\\apply_biomass\\{0}_{1}_{2}_{3}_{4}_overall_best.csv\".format(\n",
    "        model_run, model, var, data, std))\n",
    "    # Save the updated DataFrame to a CSV file\n",
    "    df.to_csv(r\"C:\\Users\\robot\\code\\pipelines\\apply_biomass\\{0}_{1}_{2}_{3}_{4}_overall_best.csv\".format(\n",
    "        model_run, model, var, data, std))\n",
    "    \n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_best_model(df, model_run, model, var, data, std, display_limit):\n",
    "    # Sort the DataFrame\n",
    "    df = df.sort_values(by=['rmse_retest'], ascending=[True])\n",
    "\n",
    "    # Generate the Windows path\n",
    "    df[\"file_path\"] = (\n",
    "        f\"H:/biomass/model_{model_run}/AGB/\" +\n",
    "        df['var'].astype(str) + \"/\" +\n",
    "        df['mdl'].astype(str) + \"/\" +\n",
    "        df['stats'].astype(str) + \"/std\" +\n",
    "        df['stdev'].astype(int).astype(str) + \"/\" + \n",
    "        df['data'].astype(str) + \"/\" +\n",
    "        df['fac'].astype(str) + \"/sel_num_\" +\n",
    "        df['sel_num'].astype(str).str[:2]\n",
    "    )\n",
    "\n",
    "    # Loop through each row in the DataFrame and print out the relevant information\n",
    "    for i, row in enumerate(df.itertuples(index=False)):\n",
    "\n",
    "        # Limit the number of displayed image sets to prevent memory overload\n",
    "        if i >= display_limit:\n",
    "            print(\"Display limit reached. Adjust the display limit to see more images.\")\n",
    "            break\n",
    "\n",
    "        # Extract validation and test (retest) metrics from the row\n",
    "        test_metrics = {\n",
    "            'R² (retest)': getattr(row, 'r2_retest', np.nan),\n",
    "            'MSE (retest)': getattr(row, 'mse_retest', np.nan),\n",
    "            'RMSE (retest)': getattr(row, 'rmse_retest', np.nan),\n",
    "            'MAE (retest)': getattr(row, 'mae_retest', np.nan),\n",
    "            'MAPE (retest)': getattr(row, 'mape_retest', np.nan),\n",
    "            'Bias (retest)': getattr(row, 'bias_retest', np.nan),\n",
    "            'N (retest)': getattr(row, 'n_retest', np.nan)\n",
    "        }\n",
    "\n",
    "        retrain_metrics = {\n",
    "            'R² (retrain)': getattr(row, 'r2_retrain', np.nan),\n",
    "            'MSE (retrain)': getattr(row, 'mse_retrain', np.nan),\n",
    "            'RMSE (retrain)': getattr(row, 'rmse_retrain', np.nan),\n",
    "            'MAE (retrain)': getattr(row, 'mae_retrain', np.nan),\n",
    "            'MAPE (retrain)': getattr(row, 'mape_retrain', np.nan),\n",
    "            'Bias (retrain)': getattr(row, 'bias_retrain', np.nan),\n",
    "            'N (retrain)': getattr(row, 'n_retrain', np.nan)\n",
    "        }\n",
    "\n",
    "        # Generate and display images (retest and validation as before)\n",
    "        path = row.file_path\n",
    "        print(f\"Path: {path}\")\n",
    "        \n",
    "        # Split the path after \"AGB\" and keep the rest of the path\n",
    "        base, after_agb = path.split(\"AGB\", 1)\n",
    "\n",
    "        # Replace forward slashes with underscores in the part after \"AGB\"\n",
    "        after_agb_modified = after_agb.replace(\"/\", \"_\")\n",
    "        df.at[i, \"apply_mdl\"] = after_agb_modified[1:]  # Update the DataFrame\n",
    "        print(f\"If using - create directory: {after_agb_modified[1:]}\")\n",
    "\n",
    "        # Locate the directory and find files ending with retest.JPG and validation.JPG\n",
    "        search_path = os.path.join(path, \"*.JPG\")  # Search for all JPG files in the directory\n",
    "        jpg_files = glob.glob(search_path)\n",
    "\n",
    "        # Filter for files ending with retest.JPG and validation.JPG\n",
    "        retest_files = [file for file in jpg_files if file.endswith(\"retest.JPG\")]\n",
    "        retrain_files = [file for file in jpg_files if file.endswith(\"retrain.JPG\")]\n",
    "\n",
    "        # Log file paths to check which files are being imported\n",
    "        if retest_files:\n",
    "            print(f\" - Retest Image found: {retest_files[0]}\")\n",
    "        else:\n",
    "            print(\"No Retest Image found.\")\n",
    "            print(\"ERROR --\" * 50)\n",
    "\n",
    "        if retrain_files:\n",
    "            print(f\" - retrain Image found: {retrain_files[0]}\")\n",
    "        else:\n",
    "            print(\"No retrain Image found.\")\n",
    "            print(\"ERROR --\" * 50)\n",
    "\n",
    "        # **NEW** Search for files ending with retrain_distribution.JPG two sub-directories above the original path\n",
    "        distribution_dir = os.path.abspath(os.path.join(path, \"../..\"))  # Two directories above\n",
    "        distribution_search_path = os.path.join(distribution_dir, \"*retrain_distribution.JPG\")\n",
    "\n",
    "        # Check if the retrain_distribution.JPG exists\n",
    "        distribution_files = glob.glob(distribution_search_path)  # Search for the file\n",
    "\n",
    "        if len(distribution_files) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(10, 8), dpi=150)  # Increase size and DPI for better quality\n",
    "            retrain_distribution_img = mpimg.imread(distribution_files[0])\n",
    "            ax.imshow(retrain_distribution_img)\n",
    "            ax.set_title('retrain Distribution Plot', fontsize=16)  # Increased font size\n",
    "            ax.axis('off')  # Turn off axis display\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Plot the found JPG files (retest and retrain) side by side\n",
    "        if retest_files or retrain_files:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 6), dpi=150)  # Larger figure and higher DPI\n",
    "\n",
    "            # Load and display the retest image (if available)\n",
    "            if retest_files:\n",
    "                retest_img = mpimg.imread(retest_files[0])\n",
    "                axes[0].imshow(retest_img)\n",
    "                axes[0].set_title('Retest Image', fontsize=16)  # Increased font size\n",
    "                axes[0].axis('off')  # Turn off axis display\n",
    "            else:\n",
    "                axes[0].axis('off')  # Leave the subplot blank if no image is available\n",
    "\n",
    "            # Load and display the retrain image (if available)\n",
    "            if retrain_files:\n",
    "                retrain_img = mpimg.imread(retrain_files[0])\n",
    "                axes[1].imshow(retrain_img)\n",
    "                axes[1].set_title('retrain Image', fontsize=16)  # Increased font size\n",
    "                axes[1].axis('off')  # Turn off axis display\n",
    "            else:\n",
    "                axes[1].axis('off')  # Leave the subplot blank if no image is available\n",
    "\n",
    "            # Adjust layout and show the images\n",
    "            plt.tight_layout(pad=2.0)  # Add padding between images\n",
    "            plt.show()\n",
    "\n",
    "            # Clear the figure from memory after displaying it\n",
    "            plt.close()\n",
    "            print(\"-\" * 100)\n",
    "\n",
    "        from IPython.display import display\n",
    "        import pandas as pd\n",
    "        \n",
    "        # Assuming test_metrics and retrain_metrics are dictionaries with metric names as keys\n",
    "        metrics_table = pd.DataFrame({\n",
    "            'Metric': list(test_metrics.keys()),\n",
    "            'Retest': list(test_metrics.values()),\n",
    "            'Retrain': [retrain_metrics[metric.replace('(retest)', '(retrain)')] for metric in test_metrics.keys()]\n",
    "        })\n",
    "        \n",
    "        # Display the table\n",
    "        display(metrics_table)\n",
    "\n",
    "        #print(metrics_table.to_string(index=False))\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        # Print the relevant features\n",
    "        print(f\"Features Used: {row.features_retest}\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "    print(\"exported to: \", r\"C:\\Users\\robot\\code\\pipelines\\apply_biomass\\{0}_{1}_{2}_{3}_{4}_overall_best.csv\".format(\n",
    "        model_run, model, var, data, std))\n",
    "    # Save the updated DataFrame to a CSV file\n",
    "    \n",
    "    return df, model_run, model, var, data, std"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Adjust filtering condition for R² if necessary\n",
    "df_low_rmse = df_merged[(df_merged['rmse_retest'] <= 7000.0) & (df_merged['r2_retest'] >= 0.6)] #\\\n",
    "   #                     & (df_merged['rmse_test'] <= 12000.0) & (df_merged['r2_test'] >= 0.6)]  # Adjusted to 0.5 assuming typical R² values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#'rmse_retest', 'r2_retest', 'rmse_retrain', 'r2_retrain'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(list(df_low_rmse))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(len(df_low_rmse))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_low_rmse",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Make a copy of the DataFrame\n",
    "df_low_rmse_run = df_low_rmse.copy()\n",
    "mdl_list = sorted(df_low_rmse_run.mdl.unique())\n",
    "var_list = sorted(df_low_rmse_run[\"var\"].unique())\n",
    "data_list = sorted(df_low_rmse_run[\"data\"].unique())\n",
    "std_list = sorted(df_low_rmse_run[\"stdev\"].unique())\n",
    "#mdl = \"GBR\"\n",
    "mdl_sel_df = df_low_rmse_run[df_low_rmse_run[\"var\"]=='all05_rs30']\n",
    "#mdl_sel_df = df_low_rmse_run[(df_low_rmse_run[\"var\"]=='all01_rs30') & (df_low_rmse_run[\"mdl\"]=='KNN')]\n",
    "#mdl_sel_df = df_low_rmse_run[(df_low_rmse_run[\"var\"]=='all01_rs0')&(df_low_rmse_run[\"data\"]=='all0')&(df_low_rmse_run[\"mdl\"]=='RFR')]\n",
    "#mdl_sel_df = df[(df[\"mdl\"]==mdl) & (df[\"data\"]!=\"all_data\") & ((df[\"var\"]==\"ann02_rs0\") | (df[\"var\"]==\"ann02_rs47\")) ]\n",
    "#df = mdl_sel_df.copy()\n",
    "#mdl_sel_df = df[df[\"mdl\"]==mdl]\n",
    "#dl_sel_df = df_low_rmse_run[df_low_rmse_run[\"data\"]!= \"all0\"]\n",
    "#mdl_sel_df = df_low_rmse_run\n",
    "#mdl_sel_df.shape\n",
    "print(\"mdl_list: \", mdl_list)\n",
    "print(var_list)\n",
    "print(data_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false
   },
   "source": "best_df, model_run, model, var, data, std = plot_best_model(mdl_sel_df, model_run, \"top\", \"top\", \"top\", \"top\", 5)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_df.to_csv(r\"C:\\Users\\robot\\code\\pipelines\\apply_biomass\\{0}_{1}_{2}_{3}_{4}_rs30_all05_overall_best.csv\".format(model_run, model, var, data, std))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_df",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "best_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Find the model with the lowest RMSE\n",
    "best_perform_model = best_df.loc[best_df['rmse_retest'].idxmin()]\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = best_df.describe()\n",
    "\n",
    "# Output results\n",
    "print(\"Summary Statistics:\")\n",
    "print(summary_stats)\n",
    "print(\"\\nModel with the Lowest RMSE:\")\n",
    "print(best_perform_model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Normalise metrics\n",
    "best_df['RMSE_norm'] = best_df['rmse_retest'] / best_df['rmse_retest'].max()  # Lower is better\n",
    "best_df['MAE_norm'] = best_df['mae_retest'] / best_df['mae_retest'].max()    # Lower is better\n",
    "best_df['R2_norm'] = 1 - ((best_df['r2_retest'].max() - best_df['r2_retest']) / (best_df['r2_retest'].max() - best_df['r2_retest'].min()))  # Higher is better\n",
    "\n",
    "# Assign weights to each metric (optional)\n",
    "weights = {'rmse_retest': 0.8, 'mae_retest': 0.1, 'r2_retest': 0.1}\n",
    "\n",
    "# Calculate combined score\n",
    "best_df['Score'] = (\n",
    "    best_df['RMSE_norm'] * weights['rmse_retest'] +\n",
    "    best_df['MAE_norm'] * weights['mae_retest'] +\n",
    "    best_df['R2_norm'] * weights['r2_retest']\n",
    ")\n",
    "\n",
    "# Rank models based on the score\n",
    "best_df['Rank'] = best_df['Score'].rank(ascending=True)\n",
    "\n",
    "# Sort by rank\n",
    "df_rank = best_df.sort_values(by='Rank')\n",
    "\n",
    "# Output results\n",
    "df_rank[['mdl', 'rmse_retest', 'mae_retest', 'r2_retest', 'Score', 'Rank', 'file_path', 'model', 'features_retest']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Group by 'mdl' and get the best rank (minimum score) per model\n",
    "best_rank_per_model = df_rank.groupby('mdl', as_index=False).first()\n",
    "\n",
    "# Sort the models by Rank for clear display\n",
    "best_rank_per_model = best_rank_per_model.sort_values(by='Rank')\n",
    "\n",
    "# Output the results\n",
    "print(\"Best Rank for Each Model:\")\n",
    "best_rank_per_model[['mdl', 'rmse_retest', 'mae_retest', 'r2_retest', 'Score', 'Rank', 'file_path', 'model', 'features_retest']]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Group by 'mdl' and find the row with the minimum 'rmse_retest' for each model\n",
    "lowest_rmse_df = best_df.loc[best_df.groupby('mdl')['rmse_retest'].idxmin()]\n",
    "# Reset index for cleaner presentation\n",
    "lowest_rmse_df = lowest_rmse_df.reset_index(drop=True)\n",
    "\n",
    "# Display the table with the lowest RMSE per model\n",
    "print(\"Table of Lowest RMSE for Each Model:\")\n",
    "lowest_rmse_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_rank_per_model.to_csv(r\"C:\\Users\\robot\\code\\pipelines\\apply_biomass\\{0}_{1}_{2}_{3}_{4}_AGB_best_model_results_rs30_all05.csv\".format(model_run, model, var, data, std))\n",
    "#best_rank_per_model.to_csv(r\"H:\\biomass\\model_test_train_all01_02_03_04_05_06_final\\AGB_best_model_results_rs30_all05.csv\", index=False)\n",
    "print(r\"C:\\Users\\robot\\code\\pipelines\\apply_biomass\\{0}_{1}_{2}_{3}_{4}_AGB_best_model_results_rs30_all05.csv\".format(model_run, model, var, data, std))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "grouped_df = best_df.groupby(['mdl'])[['rmse_retest', 'r2_retest', 'mae_retest']].agg(['mean', 'std']).reset_index()\n",
    "grouped_df\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "best_df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
