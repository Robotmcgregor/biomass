{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable corrolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following conditions apply:\n",
    "\n",
    " - env = biomass_zonal\n",
    " - data merged_slats_field_agb_dp1_start.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import ExtraTreesRegressor as etr\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.ensemble import AdaBoostRegressor as abr\n",
    "from sklearn.tree import DecisionTreeRegressor as dtr\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "# import plotting and stats modules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import scipy\n",
    "import scipy.stats as sc\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from random import randint \n",
    "\n",
    "# stats module\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import figure, show, save\n",
    "#%matplotlib inline\n",
    "\n",
    "# Bokeh Libraries\n",
    "# from bokeh.plotting import figure, show\n",
    "# from bokeh.io import output_file\n",
    "from bokeh.models import ColumnDataSource, NumeralTickFormatter, HoverTool\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "#sklearn.model_selection.cross_validate\n",
    "# from sklearn import cross_validation\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.cross_validation import KFold\n",
    "import pickle as Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import plotting and stats modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import scipy\n",
    "import scipy.stats as sc\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# stats module\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Set option to display floating-point numbers without scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import figure, show, save\n",
    "#%matplotlib inline\n",
    "\n",
    "# Bokeh Libraries\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_file\n",
    "from bokeh.models import ColumnDataSource, NumeralTickFormatter, HoverTool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = \"D\"\n",
    "date = \"20240511\"\n",
    "mdl = \"rfr\"\n",
    "#mdl = \"gbr\"\n",
    "#mdl = \"abr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_file = r\"F:\\cdu\\data\\zonal_stats\\output\\merged_slats_field_nt_mosaic_clean_start_all_values.csv\"\n",
    "#csv_file = r\"E:\\cdu\\data\\zonal_stats\\output\\merged_slats_field_agb_dp1_start.csv\"\n",
    "#csv_file = r\"{0}:\\cdu\\data\\zonal_stats\\output\\{1}\\dja_dbi_dim_dis_dka_stc_h99a2_fpca2_dry_indicies_clean.csv\".format(drive, date)\n",
    "csv_file = r\"{0}:\\cdu\\data\\latest_biomass_data\\20240402\\dp1_dbi_si_dry_mask_density_near_met_si_fire.csv\".format(drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = r\"C:\\Users\\robot\\projects\\cdu\\biomass\\dp1_dbi_si_dry_mask_density_near_met_si_fire.csv\"\n",
    "#csv_file = r\"C:\\Users\\robot\\projects\\cdu\\biomass\\dp1_dbi_si_annual_mask_density_near_met_si_fire.csv\"\n",
    "# csv_file = r\"C:\\Users\\robot\\projects\\cdu\\biomass\\dp1_dbi_si_annual_density_near_met_si_fire.csv\"\n",
    "# csv_file = r\"C:\\Users\\robot\\projects\\cdu\\biomass\\dp0_dbg_si_single_dry_density_near_met_si_fire.csv\"\n",
    "# csv_file = r\"C:\\Users\\robot\\projects\\cdu\\biomass\\dp0_dbg_si_single_annual_density_near_met_si_fire.csv\"\n",
    "# csv_file = r\"C:\\Users\\robot\\projects\\cdu\\biomass\\dp0_dbg_si_mask_single_dry_density_near_met_si_fire.csv\"\n",
    "# csv_file = r\"C:\\Users\\robot\\projects\\cdu\\biomass\\dp0_dbg_si_mask_single_annual_density_near_met_si_fire.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set output file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = r\"{0}:\\cdu\\data\\zonal_stats\\output\\{1}\".format(drive, date)\n",
    "output_ = os.path.join(output, \"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(output):\n",
    "    os.mkdir(output)\n",
    "if not os.path.isdir(output_):\n",
    "    os.mkdir(output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 297)\n",
      "['uid', 'site_clean', 'date', 'lon_gda94', 'lat_gda94', 'bio_l_kg1ha', 'bio_t_kg1ha', 'bio_b_kg1ha', 'bio_w_kg1ha', 'bio_br_kg1ha', 'bio_s_kg1ha', 'bio_r_kg1ha', 'bio_agb_kg1ha', 'c_l_kg1ha', 'c_t_kg1ha', 'c_b_kg1ha', 'c_w_kg1ha', 'c_br_kg1ha', 'c_s_kg1ha', 'c_r_kg1ha', 'c_agb_kg1ha', 'geometry', 'basal_dt', 'im_date', 'band', 'fire_count', 'fire_min', 'fire_max', 'fire_mean', 'fire_sum', 'fire_std', 'fire_med', 'fire_major', 'fire_minor', 'jan', 'feb', 'mar', 'april', 'may', 'june', 'july', 'aug', 'sep', 'oct', 'nov', 'dec', 's_date', 'e_date', 'image_s_dt', 'image_e_dt', 'area_ha', 'jan_per', 'feb_per', 'mar_per', 'april_per', 'may_per', 'june_per', 'july_per', 'aug_per', 'sep_per', 'oct_per', 'nov_per', 'dec_per', 'burnt_enco', 'burnt_cat', 'fire_sn_ord', 'fire_sn_cat', 'fire_f', 'fire_tot', 'since_fire', 'fire_gap', 'fire_pois1_2', 'fire_pois1_5', 'fire_pois1_10', 'year', 'tot_an_emsi_avg', 'tot_an_emsi_avg_R', 'tot_an_emsi_avg_si', 'emsi_dt', 'tot_an_drsi_avg', 'tot_an_drsi_avg_R', 'tot_an_drsi_avg_si', 'drsi_dt', 'tot_avg_emse_djf', 'tot_avg_emse_mam', 'tot_avg_emse_jja', 'tot_avg_emse_son', 'tot_avg_emse_dry', 'tot_avg_emse_wet', 'tot_avg_emse_annual', 'emse_dt', 'tot_avg_drse_djf', 'tot_avg_drse_mam', 'tot_avg_drse_jja', 'tot_avg_drse_son', 'tot_avg_drse_dry', 'tot_avg_drse_wet', 'tot_avg_drse_annual', 'drse_dt', 'rain_d_mean', 'et_ma_mean', 'tmax_mean', 'tmin_mean', 'rh_tmax_mean', 'rh_tmin_mean', 'b1_wfp_dry_min', 'b1_wfp_dry_max', 'b1_wfp_dry_mean', 'b1_wfp_dry_std', 'b1_wfp_dry_med', 'b1_wfp_dry_p25', 'b1_wfp_dry_p50', 'b1_wfp_dry_p75', 'b1_wfp_dry_p95', 'b1_wfp_dry_p99', 'b1_wdc_dry_major', 'b1_wdc_dry_minor', 'b1_n17_dry_major', 'b1_n17_dry_minor', 'b1_hsd_min', 'b1_hsd_max', 'b1_hsd_mean', 'b1_hsd_std', 'b1_hsd_med', 'b1_hsd_p25', 'b1_hsd_p50', 'b1_hsd_p75', 'b1_hsd_p95', 'b1_hsd_p99', 'b1_hmc_min', 'b1_hmc_max', 'b1_hmc_mean', 'b1_hmc_std', 'b1_hmc_med', 'b1_hmc_p25', 'b1_hmc_p50', 'b1_hmc_p75', 'b1_hmc_p95', 'b1_hmc_p99', 'b1_hcv_min', 'b1_hcv_max', 'b1_hcv_mean', 'b1_hcv_std', 'b1_hcv_med', 'b1_hcv_p25', 'b1_hcv_p50', 'b1_hcv_p75', 'b1_hcv_p95', 'b1_hcv_p99', 'b1_h99_min', 'b1_h99_max', 'b1_h99_mean', 'b1_h99_std', 'b1_h99_med', 'b1_h99_p25', 'b1_h99_p50', 'b1_h99_p75', 'b1_h99_p95', 'b1_h99_p99', 'b1_fdc_dry_major', 'b1_fdc_dry_minor', 'b1_ccw_dry_min', 'b1_ccw_dry_max', 'b1_ccw_dry_mean', 'b1_ccw_dry_std', 'b1_ccw_dry_med', 'b1_ccw_dry_p25', 'b1_ccw_dry_p50', 'b1_ccw_dry_p75', 'b1_ccw_dry_p95', 'b1_ccw_dry_p99', 'b1_dbifm_dry_min', 'b1_dbifm_dry_max', 'b1_dbifm_dry_mean', 'b1_dbifm_dry_std', 'b1_dbifm_dry_med', 'b1_dbifm_dry_p25', 'b1_dbifm_dry_p50', 'b1_dbifm_dry_p75', 'b1_dbifm_dry_p95', 'b1_dbifm_dry_p99', 'b1_dp1fm_dry_min', 'b1_dp1fm_dry_max', 'b1_dp1fm_dry_mean', 'b1_dp1fm_dry_std', 'b1_dp1fm_dry_med', 'b1_dp1fm_dry_p25', 'b1_dp1fm_dry_p50', 'b1_dp1fm_dry_p75', 'b1_dp1fm_dry_p95', 'b1_dp1fm_dry_p99', 'b2_dp1fm_dry_min', 'b2_dp1fm_dry_max', 'b2_dp1fm_dry_mean', 'b2_dp1fm_dry_std', 'b2_dp1fm_dry_med', 'b2_dp1fm_dry_p25', 'b2_dp1fm_dry_p50', 'b2_dp1fm_dry_p75', 'b2_dp1fm_dry_p95', 'b2_dp1fm_dry_p99', 'b3_dp1fm_dry_min', 'b3_dp1fm_dry_max', 'b3_dp1fm_dry_mean', 'b3_dp1fm_dry_std', 'b3_dp1fm_dry_med', 'b3_dp1fm_dry_p25', 'b3_dp1fm_dry_p50', 'b3_dp1fm_dry_p75', 'b3_dp1fm_dry_p95', 'b3_dp1fm_dry_p99', 'b1_dbifm_dry_std.1', 'b1_dbifm_dry_med.1', 'b1_dbifm_dry_p25.1', 'b1_dbifm_dry_p50.1', 'b1_dbifm_dry_p75.1', 'b1_dbifm_dry_p95.1', 'b1_dbifm_dry_p99.1', 'b2_dbifm_dry_min', 'b2_dbifm_dry_max', 'b2_dbifm_dry_mean', 'b2_dbifm_dry_std', 'b2_dbifm_dry_med', 'b2_dbifm_dry_p25', 'b2_dbifm_dry_p50', 'b2_dbifm_dry_p75', 'b2_dbifm_dry_p95', 'b2_dbifm_dry_p99', 'b3_dbifm_dry_min', 'b3_dbifm_dry_max', 'b3_dbifm_dry_mean', 'b3_dbifm_dry_std', 'b3_dbifm_dry_med', 'b3_dbifm_dry_p25', 'b3_dbifm_dry_p50', 'b3_dbifm_dry_p75', 'b3_dbifm_dry_p95', 'b3_dbifm_dry_p99', 'b4_dbifm_dry_min', 'b4_dbifm_dry_max', 'b4_dbifm_dry_mean', 'b4_dbifm_dry_std', 'b4_dbifm_dry_med', 'b4_dbifm_dry_p25', 'b4_dbifm_dry_p50', 'b4_dbifm_dry_p75', 'b4_dbifm_dry_p95', 'b4_dbifm_dry_p99', 'b5_dbifm_dry_min', 'b5_dbifm_dry_max', 'b5_dbifm_dry_mean', 'b5_dbifm_dry_std', 'b5_dbifm_dry_med', 'b5_dbifm_dry_p25', 'b5_dbifm_dry_p50', 'b5_dbifm_dry_p75', 'b5_dbifm_dry_p95', 'b5_dbifm_dry_p99', 'b6_dbifm_dry_min', 'b6_dbifm_dry_max', 'b6_dbifm_dry_mean', 'b6_dbifm_dry_std', 'b6_dbifm_dry_med', 'b6_dbifm_dry_p25', 'b6_dbifm_dry_p50', 'b6_dbifm_dry_p75', 'b6_dbifm_dry_p95', 'b6_dbifm_dry_p99', 'dbifmdry_psB1a', 'dbifmdry_psB2a', 'dbifmdry_psB3a', 'dbifmdry_psB4a', 'dbifmdry_psB5a', 'dbifmdry_psB6a', 'dbifmdry_r32', 'dbifmdry_r42', 'dbifmdry_r43', 'dbifmdry_r52', 'dbifmdry_r53', 'dbifmdry_r54', 'dbifmdry_r62', 'dbifmdry_r63', 'dbifmdry_r64', 'dbifmdry_r65', 'dbifmdry_GSAVI', 'dbifmdry_GNDVI', 'dbifmdry_CVI', 'dbifmdry_NDGI', 'dbifmdry_RI', 'dbifmdry_NBR', 'dbifmdry_NDII', 'dbifmdry_GDVI', 'dbifmdry_MSAVI', 'dbifmdry_DVI', 'dbifmdry_SAVI', 'dbifmdry_NDVI', 'dbifmdry_MSR']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(188, 297)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read as dataframe and copy\n",
    "df1 = pd.read_csv(csv_file, header=0) # the first row is read in as the header for you columns\n",
    "print(df1.shape) # prints out the number of rows and columns in your csv file \n",
    "print(list(df1))\n",
    "df1.shape\n",
    "#df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values in each column\n",
    "columns_with_nulls = df1.columns[df1.isnull().any()]\n",
    "columns_with_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auv07.2012 missing b1_wfp_dry and b1_ccw_dry all variables filled with median\n",
    "# b2_dp1fm_dry_min - about 20 missing values convert to 1 or 0\n",
    "df1[\"b2_dbifm_dry_max\"] = df1[\"b2_dbifm_dry_max\"].fillna(1)\n",
    "filled_df = df1.fillna(df1.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values in each column\n",
    "columns_with_nulls = filled_df.columns[filled_df.isnull().any()]\n",
    "columns_with_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filled_df.rename(columns={'bio_agb_kg1ha': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #main only\n",
    "# var_ = \"main_only\"\n",
    "\n",
    "# df_columns = list(df.columns)\n",
    "# keep = ['site_clean', \"target\", \"mean\", \"major\"]\n",
    "# header = [ele for ele in df_columns for x in keep if x in ele]\n",
    "# df2 = df[header]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #main major and h99 \n",
    "# var_ = \"main_only\"\n",
    "\n",
    "# df_columns = list(df.columns)\n",
    "# keep = ['site_clean', \"target\", \"mean\", \"major\", \"h99\"]\n",
    "# header = [ele for ele in df_columns for x in keep if x in ele]\n",
    "# df2 = df[header]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['site_clean', \"target\",\n",
    "\n",
    "'b6_dbifm_dry_mean',\n",
    " 'b3_dbifm_dry_mean',\n",
    " 'b2_dbifm_dry_mean',\n",
    " 'dbifmdry_GNDVI',\n",
    " 'dbifmdry_MSR',\n",
    " 'b2_dp1fm_dry_mean',\n",
    " 'b3_dp1fm_dry_mean',\n",
    " 'dbifmdry_NBR',\n",
    " 'b5_dbifm_dry_mean',\n",
    " 'dbifmdry_NDVI',\n",
    " 'b1_hsd_mean',\n",
    " 'b1_h99_mean',\n",
    " 'b1_dbifm_dry_mean',\n",
    " 'rh_tmin_mean',\n",
    " 'dbifmdry_CVI',\n",
    " 'b1_ccw_dry_mean',\n",
    " 'b1_dp1fm_dry_mean',\n",
    " 'b1_wfp_dry_mean',\n",
    " 'dbifmdry_GDVI',\n",
    " 'dbifmdry_GSAVI']]\n",
    "\n",
    "var_ = \"20_ada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['site_clean', \"target\",\n",
    "\n",
    "'b6_dbifm_dry_mean',\n",
    " 'b3_dbifm_dry_mean',\n",
    " 'b2_dbifm_dry_mean',\n",
    " 'dbifmdry_GNDVI',\n",
    " 'dbifmdry_MSR',\n",
    " 'b2_dp1fm_dry_mean',\n",
    " 'b3_dp1fm_dry_mean',\n",
    " 'dbifmdry_NBR',\n",
    " 'b5_dbifm_dry_mean',\n",
    " 'dbifmdry_NDVI',\n",
    " 'b1_hsd_mean',\n",
    " 'b1_h99_mean',\n",
    " 'b1_dbifm_dry_mean',\n",
    " 'rh_tmin_mean',\n",
    " 'dbifmdry_CVI',\n",
    " 'b1_ccw_dry_mean',\n",
    " 'b1_dp1fm_dry_mean',\n",
    " 'b1_wfp_dry_mean',\n",
    " 'dbifmdry_GDVI',\n",
    " 'dbifmdry_GSAVI','fire_f', 'fire_tot', 'since_fire', 'fire_gap', 'fire_pois1_2', 'fire_pois1_5', 'fire_pois1_10']]\n",
    "var_ = \"20_ada_fire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =df[['site_clean', \n",
    " 'target', \n",
    " 'fire_count', \n",
    " 'fire_min', \n",
    " 'fire_max', \n",
    " 'fire_mean', \n",
    " 'fire_sum', \n",
    " 'fire_std', \n",
    " 'fire_med', \n",
    " 'fire_major', \n",
    " 'fire_minor', \n",
    " 'burnt_enco', \n",
    " 'fire_sn_ord', \n",
    " 'fire_f', \n",
    " 'fire_tot', \n",
    " 'since_fire', \n",
    " 'fire_gap', \n",
    " 'fire_pois1_2', \n",
    " 'fire_pois1_5', \n",
    " 'fire_pois1_10', \n",
    " 'tot_an_emsi_avg_si', \n",
    " 'tot_an_drsi_avg_si', \n",
    " 'tot_avg_emse_djf', \n",
    " 'tot_avg_emse_mam', \n",
    " 'tot_avg_emse_jja', \n",
    " 'tot_avg_emse_son', \n",
    " 'tot_avg_emse_dry', \n",
    " 'tot_avg_emse_wet', \n",
    " 'tot_avg_emse_annual', \n",
    " 'tot_avg_drse_djf', \n",
    " 'tot_avg_drse_mam', \n",
    " 'tot_avg_drse_jja', \n",
    " 'tot_avg_drse_son', \n",
    " 'tot_avg_drse_dry', \n",
    " 'tot_avg_drse_wet', \n",
    " 'tot_avg_drse_annual', \n",
    " 'b1_wfp_dry_mean', \n",
    " 'b1_wfp_dry_p50', \n",
    " 'b1_wfp_dry_p99', \n",
    " 'b1_wdc_dry_major', \n",
    " 'b1_n17_dry_major', \n",
    " 'b1_hsd_mean', \n",
    " 'b1_hsd_p50', \n",
    " 'b1_hsd_p99', \n",
    " 'b1_hmc_mean', \n",
    " 'b1_hmc_p50', \n",
    " 'b1_hmc_p99', \n",
    " 'b1_hcv_mean', \n",
    " 'b1_hcv_p50', \n",
    " 'b1_hcv_p99', \n",
    " 'b1_h99_mean', \n",
    " 'b1_h99_p50', \n",
    " 'b1_h99_p99', \n",
    " 'b1_fdc_dry_major', \n",
    " 'b1_ccw_dry_mean', \n",
    " 'b1_ccw_dry_p50', \n",
    " 'b1_ccw_dry_p99', \n",
    " 'b1_dbifm_dry_mean', \n",
    " 'b1_dp1fm_dry_mean', \n",
    " 'b1_dp1fm_dry_p50',\n",
    " 'b1_dp1fm_dry_p99', \n",
    " 'b2_dp1fm_dry_mean', \n",
    " 'b2_dp1fm_dry_p50', \n",
    " 'b2_dp1fm_dry_p95', \n",
    " 'b3_dp1fm_dry_mean', \n",
    " 'b3_dp1fm_dry_p50', \n",
    " 'b3_dp1fm_dry_p99',  \n",
    " 'b1_dbifm_dry_p50', \n",
    " 'b1_dbifm_dry_p99', \n",
    " 'b2_dbifm_dry_mean', \n",
    " 'b2_dbifm_dry_p50',  \n",
    " 'b2_dbifm_dry_p99', \n",
    " 'b3_dbifm_dry_mean', \n",
    " 'b3_dbifm_dry_p50',  \n",
    " 'b3_dbifm_dry_p99', \n",
    " 'b4_dbifm_dry_mean', \n",
    " 'b4_dbifm_dry_p50',  \n",
    " 'b4_dbifm_dry_p99', \n",
    " 'b5_dbifm_dry_mean', \n",
    " 'b5_dbifm_dry_p50', \n",
    " 'b5_dbifm_dry_p99', \n",
    " 'b6_dbifm_dry_mean', \n",
    " 'b6_dbifm_dry_p50',\n",
    " 'b6_dbifm_dry_p99',\n",
    " 'dbifmdry_r32',\n",
    " 'dbifmdry_r42', \n",
    " 'dbifmdry_r43', \n",
    " 'dbifmdry_r52', \n",
    " 'dbifmdry_r53', \n",
    " 'dbifmdry_r54', \n",
    " 'dbifmdry_r62', \n",
    " 'dbifmdry_r63', \n",
    " 'dbifmdry_r64', \n",
    " 'dbifmdry_r65', \n",
    " 'dbifmdry_GSAVI', \n",
    " 'dbifmdry_GNDVI', \n",
    " 'dbifmdry_CVI', \n",
    " 'dbifmdry_NDGI', \n",
    " 'dbifmdry_RI', \n",
    " 'dbifmdry_NBR',\n",
    " 'dbifmdry_NDII',\n",
    " 'dbifmdry_GDVI', \n",
    " 'dbifmdry_MSAVI', \n",
    " 'dbifmdry_DVI', \n",
    " 'dbifmdry_SAVI', \n",
    " 'dbifmdry_NDVI',\n",
    " 'dbifmdry_MSR',\n",
    "        ]]\n",
    "\n",
    "var_ = \"mm_si_f\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dp1_dbi_si_dry_mask_density_near_met_si_fire.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =df[['site_clean', \n",
    " 'target', \n",
    " 'fire_count', \n",
    " 'fire_min', \n",
    " 'fire_max', \n",
    " 'fire_mean', \n",
    " 'fire_sum', \n",
    " 'fire_std', \n",
    " 'fire_med', \n",
    " 'fire_major', \n",
    " 'fire_minor', \n",
    "#  'jan', \n",
    "#  'feb', \n",
    "#  'mar', \n",
    "#  'april', \n",
    "#  'may', \n",
    "#  'june', \n",
    "#  'july', \n",
    "#  'aug', \n",
    "#  'sep', \n",
    "#  'oct', \n",
    "#  'nov', \n",
    "#  'dec', \n",
    "#   'jan_per', \n",
    "#  'feb_per', \n",
    "#  'mar_per', \n",
    "#  'april_per', \n",
    "#  'may_per', \n",
    "#  'june_per', \n",
    "#  'july_per', \n",
    "#  'aug_per',\n",
    "#  'sep_per', \n",
    "#  'oct_per', \n",
    "#  'nov_per', \n",
    "#  'dec_per', \n",
    " 'burnt_enco', \n",
    "#  'burnt_cat', \n",
    " 'fire_sn_ord', \n",
    "#  'fire_sn_cat', \n",
    " 'fire_f', \n",
    " 'fire_tot', \n",
    " 'since_fire', \n",
    " 'fire_gap', \n",
    " 'fire_pois1_2', \n",
    " 'fire_pois1_5', \n",
    " 'fire_pois1_10', \n",
    "#  'tot_an_emsi_avg', \n",
    "#  'tot_an_emsi_avg_R', \n",
    " 'tot_an_emsi_avg_si', \n",
    "#  'emsi_dt', \n",
    "#  'tot_an_drsi_avg', \n",
    "#  'tot_an_drsi_avg_R', \n",
    " 'tot_an_drsi_avg_si', \n",
    "#  'drsi_dt', \n",
    " 'tot_avg_emse_djf', \n",
    " 'tot_avg_emse_mam', \n",
    " 'tot_avg_emse_jja', \n",
    " 'tot_avg_emse_son', \n",
    " 'tot_avg_emse_dry', \n",
    " 'tot_avg_emse_wet', \n",
    " 'tot_avg_emse_annual', \n",
    "#  'emse_dt', \n",
    " 'tot_avg_drse_djf', \n",
    " 'tot_avg_drse_mam', \n",
    " 'tot_avg_drse_jja', \n",
    " 'tot_avg_drse_son', \n",
    " 'tot_avg_drse_dry', \n",
    " 'tot_avg_drse_wet', \n",
    " 'tot_avg_drse_annual', \n",
    "#  'drse_dt', \n",
    "#  'rain_d_mean', \n",
    "#  'et_ma_mean', \n",
    "#  'tmax_mean', \n",
    "#  'tmin_mean', \n",
    "#  'rh_tmax_mean', \n",
    "#  'rh_tmin_mean', \n",
    "#  'b1_wfp_dry_min', \n",
    "#  'b1_wfp_dry_max', \n",
    " 'b1_wfp_dry_mean', \n",
    "#  'b1_wfp_dry_std', \n",
    "#  'b1_wfp_dry_med', \n",
    "#  'b1_wfp_dry_p25', \n",
    " 'b1_wfp_dry_p50', \n",
    "#  'b1_wfp_dry_p75', \n",
    "#  'b1_wfp_dry_p95', \n",
    " 'b1_wfp_dry_p99', \n",
    " 'b1_wdc_dry_major', \n",
    "#  'b1_wdc_dry_minor', \n",
    " 'b1_n17_dry_major', \n",
    "#  'b1_n17_dry_minor', \n",
    "#  'b1_hsd_min', \n",
    "#  'b1_hsd_max', \n",
    " 'b1_hsd_mean', \n",
    "#  'b1_hsd_std', \n",
    "#  'b1_hsd_med', \n",
    "#  'b1_hsd_p25', \n",
    " 'b1_hsd_p50', \n",
    "#  'b1_hsd_p75', \n",
    "#  'b1_hsd_p95', \n",
    " 'b1_hsd_p99', \n",
    "#  'b1_hmc_min', \n",
    "#  'b1_hmc_max', \n",
    " 'b1_hmc_mean', \n",
    "#  'b1_hmc_std', \n",
    "#  'b1_hmc_med', \n",
    "#  'b1_hmc_p25', \n",
    " 'b1_hmc_p50', \n",
    "#  'b1_hmc_p75', \n",
    "#  'b1_hmc_p95', \n",
    " 'b1_hmc_p99', \n",
    "#  'b1_hcv_min', \n",
    "#  'b1_hcv_max', \n",
    " 'b1_hcv_mean', \n",
    "#  'b1_hcv_std', \n",
    "#  'b1_hcv_med', \n",
    "#  'b1_hcv_p25', \n",
    " 'b1_hcv_p50', \n",
    "#  'b1_hcv_p75', \n",
    "#  'b1_hcv_p95', \n",
    " 'b1_hcv_p99', \n",
    "#  'hcv_dt', \n",
    "#  'b1_h99_min', \n",
    "#  'b1_h99_max', \n",
    " 'b1_h99_mean', \n",
    "#  'b1_h99_std', \n",
    "#  'b1_h99_med', \n",
    "#  'b1_h99_p25',\n",
    " 'b1_h99_p50', \n",
    "#  'b1_h99_p75', \n",
    "#  'b1_h99_p95', \n",
    " 'b1_h99_p99', \n",
    " 'b1_fdc_dry_major', \n",
    "#  'b1_fdc_dry_minor', \n",
    "#  'b1_ccw_dry_min', \n",
    "#  'b1_ccw_dry_max', \n",
    " 'b1_ccw_dry_mean', \n",
    "#  'b1_ccw_dry_std', \n",
    "#  'b1_ccw_dry_med', \n",
    "#  'b1_ccw_dry_p25', \n",
    " 'b1_ccw_dry_p50', \n",
    "#  'b1_ccw_dry_p75', \n",
    "#  'b1_ccw_dry_p95', \n",
    " 'b1_ccw_dry_p99', \n",
    "#  'b1_dbifm_dry_min', \n",
    "#  'b1_dbifm_dry_max', \n",
    " 'b1_dbifm_dry_mean', \n",
    "#  'b1_dp1fm_dry_min', \n",
    "#  'b1_dp1fm_dry_max', \n",
    " 'b1_dp1fm_dry_mean', \n",
    "#  'b1_dp1fm_dry_std',\n",
    "#  'b1_dp1fm_dry_med', \n",
    "#  'b1_dp1fm_dry_p25', \n",
    " 'b1_dp1fm_dry_p50',\n",
    "#  'b1_dp1fm_dry_p75',\n",
    "#  'b1_dp1fm_dry_p95', \n",
    " 'b1_dp1fm_dry_p99', \n",
    "#  'b2_dp1fm_dry_min', \n",
    "#  'b2_dp1fm_dry_max', \n",
    " 'b2_dp1fm_dry_mean', \n",
    "#  'b2_dp1fm_dry_std', \n",
    "#  'b2_dp1fm_dry_med', \n",
    "#  'b2_dp1fm_dry_p25', \n",
    " 'b2_dp1fm_dry_p50', \n",
    "#  'b2_dp1fm_dry_p75',\n",
    " 'b2_dp1fm_dry_p95', \n",
    "#  'b2_dp1fm_dry_p99', \n",
    "#  'b3_dp1fm_dry_min', \n",
    "#  'b3_dp1fm_dry_max', \n",
    " 'b3_dp1fm_dry_mean', \n",
    "#  'b3_dp1fm_dry_std',\n",
    "#  'b3_dp1fm_dry_med',\n",
    "#  'b3_dp1fm_dry_p25',\n",
    " 'b3_dp1fm_dry_p50', \n",
    "#  'b3_dp1fm_dry_p75', \n",
    "#  'b3_dp1fm_dry_p95',\n",
    " 'b3_dp1fm_dry_p99', \n",
    "#  'b1_dbifm_dry_std',\n",
    "#  'b1_dbifm_dry_med',\n",
    "#  'b1_dbifm_dry_p25', \n",
    " 'b1_dbifm_dry_p50', \n",
    "#  'b1_dbifm_dry_p75', \n",
    "#  'b1_dbifm_dry_p95', \n",
    " 'b1_dbifm_dry_p99', \n",
    "#  'b2_dbifm_dry_min', \n",
    "#  'b2_dbifm_dry_max', \n",
    " 'b2_dbifm_dry_mean', \n",
    "#  'b2_dbifm_dry_std', \n",
    "#  'b2_dbifm_dry_med', \n",
    "#  'b2_dbifm_dry_p25', \n",
    " 'b2_dbifm_dry_p50', \n",
    "#  'b2_dbifm_dry_p75', \n",
    "#  'b2_dbifm_dry_p95', \n",
    " 'b2_dbifm_dry_p99', \n",
    "#  'b3_dbifm_dry_min', \n",
    "#  'b3_dbifm_dry_max', \n",
    " 'b3_dbifm_dry_mean', \n",
    "#  'b3_dbifm_dry_std',\n",
    "#  'b3_dbifm_dry_med', \n",
    "#  'b3_dbifm_dry_p25', \n",
    " 'b3_dbifm_dry_p50', \n",
    "#  'b3_dbifm_dry_p75', \n",
    "#  'b3_dbifm_dry_p95', \n",
    " 'b3_dbifm_dry_p99', \n",
    "#  'b4_dbifm_dry_min', \n",
    "#  'b4_dbifm_dry_max', \n",
    " 'b4_dbifm_dry_mean', \n",
    "#  'b4_dbifm_dry_std', \n",
    "#  'b4_dbifm_dry_med', \n",
    "#  'b4_dbifm_dry_p25', \n",
    " 'b4_dbifm_dry_p50', \n",
    "#  'b4_dbifm_dry_p75', \n",
    "#  'b4_dbifm_dry_p95', \n",
    " 'b4_dbifm_dry_p99', \n",
    "#  'b5_dbifm_dry_min', \n",
    "#  'b5_dbifm_dry_max', \n",
    " 'b5_dbifm_dry_mean', \n",
    "#  'b5_dbifm_dry_std', \n",
    "#  'b5_dbifm_dry_med', \n",
    "#  'b5_dbifm_dry_p25',\n",
    " 'b5_dbifm_dry_p50', \n",
    "#  'b5_dbifm_dry_p75',\n",
    "#  'b5_dbifm_dry_p95', \n",
    " 'b5_dbifm_dry_p99', \n",
    "#  'b6_dbifm_dry_min', \n",
    "#  'b6_dbifm_dry_max', \n",
    " 'b6_dbifm_dry_mean', \n",
    "#  'b6_dbifm_dry_std',\n",
    "#  'b6_dbifm_dry_med', \n",
    "#  'b6_dbifm_dry_p25', \n",
    " 'b6_dbifm_dry_p50',\n",
    "#  'b6_dbifm_dry_p75', \n",
    "#  'b6_dbifm_dry_p95', \n",
    " 'b6_dbifm_dry_p99',\n",
    "\n",
    " 'dbifmdry_r32',\n",
    " 'dbifmdry_r42', \n",
    " 'dbifmdry_r43', \n",
    " 'dbifmdry_r52', \n",
    " 'dbifmdry_r53', \n",
    " 'dbifmdry_r54', \n",
    " 'dbifmdry_r62', \n",
    " 'dbifmdry_r63', \n",
    " 'dbifmdry_r64', \n",
    " 'dbifmdry_r65', \n",
    " 'dbifmdry_GSAVI', \n",
    " 'dbifmdry_GNDVI', \n",
    " 'dbifmdry_CVI', \n",
    " 'dbifmdry_NDGI', \n",
    " 'dbifmdry_RI', \n",
    " 'dbifmdry_NBR',\n",
    " 'dbifmdry_NDII',\n",
    " 'dbifmdry_GDVI', \n",
    " 'dbifmdry_MSAVI', \n",
    " 'dbifmdry_DVI', \n",
    " 'dbifmdry_SAVI', \n",
    " 'dbifmdry_NDVI',\n",
    " 'dbifmdry_MSR',\n",
    "        ]]\n",
    "\n",
    "var_ = \"mm_si_f\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main and Major Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #main and major only\n",
    "# var_ = \"mean_major\"\n",
    "\n",
    "# df_columns = list(df.columns)\n",
    "# keep = ['site_clean', \"target\", \"mean\", \"major\"]\n",
    "# header = [ele for ele in df_columns for x in keep if x in ele]\n",
    "# df2 = df[header]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #varibles no coorolation\n",
    "# df2 = df2.drop(['rain_d_mean','et_ma_mean','tmax_mean','tmin_mean','rh_tmax_mean','rh_tmin_mean'], axis=1)\n",
    "# df2.columns\n",
    "# var_ = \"mean_major_met_rem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main and veg indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_ = \"mm_met_rem\"\n",
    "\n",
    "# df_columns = list(df.columns)\n",
    "# keep = ['site_clean', \"target\", \"mean\", 'major', 'dbifmdry_GSAVI',\n",
    "#  'dbifmdry_GNDVI',\n",
    "#  'dbifmdry_CVI',\n",
    "#  #'dbifmdry_NDGI',\n",
    "#  'dbifmdry_RI',\n",
    "#  'dbifmdry_NBR',\n",
    "#  #'dbifmdry_NDII',\n",
    "#  'dbifmdry_GDVI',\n",
    "#  'dbifmdry_MSAVI',\n",
    "#  'dbifmdry_DVI',\n",
    "#  'dbifmdry_SAVI',\n",
    "#  'dbifmdry_NDVI',\n",
    "#  'dbifmdry_MSR']\n",
    "# header = [ele for ele in df_columns for x in keep if x in ele]\n",
    "# df2 = df[header]\n",
    "\n",
    "# del df2['fire_mean']\n",
    "# del df2['rh_tmin_mean']\n",
    "\n",
    "# #varibles no coorolation\n",
    "# df2 = df2.drop(['rain_d_mean','et_ma_mean','tmax_mean','tmin_mean','rh_tmax_mean'], axis=1)# ,'rh_tmin_mean'\n",
    "# print(list(df2.columns))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main, veg indicies and fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_ = \"mmf_met_rem\"\n",
    "\n",
    "# df_columns = list(df.columns)\n",
    "# keep = ['site_clean', \"target\", \"mean\", 'dbifmdry_GSAVI',\n",
    "#  'dbifmdry_GNDVI',\n",
    "#  'dbifmdry_CVI',\n",
    "#  'dbifmdry_NDGI',\n",
    "#  'dbifmdry_RI',\n",
    "#  'dbifmdry_NBR',\n",
    "#  'dbifmdry_NDII',\n",
    "#  'dbifmdry_GDVI',\n",
    "#  'dbifmdry_MSAVI',\n",
    "#  'dbifmdry_DVI',\n",
    "#  'dbifmdry_SAVI',\n",
    "#  'dbifmdry_NDVI',\n",
    "#  'dbifmdry_MSR',\n",
    "#        #'burnt', 'intens', 'fire_f', 'fire_tot', 'since_fire', 'fire_gap', \n",
    "# 'fire_pois1_2', 'fire_pois1_5', 'fire_pois1_10',\n",
    "#        ]\n",
    "# header = [ele for ele in df_columns for x in keep if x in ele]\n",
    "# df2 = df[header]\n",
    "\n",
    "# #varibles no coorolation\n",
    "# df2 = df2.drop(['rain_d_mean','et_ma_mean','tmax_mean','tmin_mean','rh_tmax_mean'], axis=1)# ,'rh_tmin_mean'\n",
    "# print(list(df2.columns))\n",
    "# #d_type = \"mmf_met_rem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all target == 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2['target']>0.0]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove site values which seem like outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dry Fire\n",
    "\n",
    "#WFP\n",
    "'''ant03.2012\n",
    "site12.2023 # lat long error - should be correted\n",
    "ntagfu0038.2012 # not too bad\n",
    "\n",
    "'''\n",
    "\n",
    "# Drop rows where sites seem to be outliers\n",
    "df3 = df2[df2['site_clean'] != 'ant03.2012']\n",
    "df4 = df3[df3['site_clean'] != 'site12.2023']\n",
    "df2 = df4[df4['site_clean'] != 'ntagfu0038.2012']\n",
    "df2\n",
    "\n",
    "\n",
    "\"\"\"#b1 dbifm\n",
    "nc02.2013\n",
    "ntamgd0001.2014\n",
    "nc02.2013\n",
    "\n",
    "#b2 dbifm\n",
    "ntamgd0001.2014\n",
    "girra02.2012 # minor\n",
    "\n",
    "#b3 dbifm\n",
    "ntamgd0001.2014\n",
    "girra02.2012 # minor\n",
    "\n",
    "#b4 dbifm\n",
    "Noisy\n",
    "\n",
    "#b5 dbifm\n",
    "reasonable\n",
    "\n",
    "#b2 dp1\n",
    "looks pritty reasonable\n",
    "\n",
    "#b3 dp1\n",
    "Noisy <1200\n",
    "\n",
    "#b6 dbifm\n",
    "wh07.2012\n",
    "reasonable\n",
    "\n",
    "#h99\n",
    "\n",
    "ntastu0003.2016\n",
    "nttdab0001.2014\n",
    "ntagfu0035.2012\n",
    "ntagfu0034.2012\n",
    "\n",
    "#hcv\n",
    "site10.2023\n",
    "site16.2023\n",
    "site23.2023\n",
    "girra02.2012\n",
    "vrd37.2012\n",
    "ntagfu0034.2012\n",
    "ntagfu0035.2012\n",
    "\n",
    "#hmc\n",
    "nttdab0001.2014\n",
    "ntastu0003.2016\n",
    "\n",
    "#n17\n",
    "ntagfu0003.2012\n",
    "wh02.2012\n",
    "wh07.2012 >10\n",
    "#many are class 1\n",
    "\n",
    "#wfp looks pritty reasonable\n",
    "\n",
    "#et ma mean\n",
    "noisy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop AGB numbers which are low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2['target']>0.0]\n",
    "#df2 = df2[df2['target']>1000.0]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop AGB numbers which are high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the 7 tern sites that apear to be outliers\n",
    "df2 =df2[df2['target'] <= 40000]\n",
    "df2.to_csv(os.path.join(output_, \"{0}_lt_40000.csv\".format('target')))\n",
    "#df2 =df2[df2['target'] > 40000]\n",
    "#df2.value_counts(['site_clean', value_x, value_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all outliers 3 std deviations above the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_outliers(df):\n",
    "    filtered_df = pd.DataFrame()  # Initialize an empty DataFrame to store filtered data\n",
    "    \n",
    "    for column in df.columns[4:]:\n",
    "        print(\"_\"*20)\n",
    "        print(\"column: \", column)\n",
    "        column_data = df[column]\n",
    "        mean = column_data.mean()\n",
    "        print(\"mean: \", mean)\n",
    "        std_dev = column_data.std()\n",
    "        print(\"std_dev: \", std_dev)\n",
    "        threshold = 3 * std_dev\n",
    "        print(\"threshold: \", threshold)\n",
    "        \n",
    "        # Define a boolean mask to filter outliers for the current column\n",
    "        mask = (column_data > (mean - threshold)) & (column_data < (mean + threshold))\n",
    "        #print(mask)\n",
    "        # Apply the mask to filter the column data\n",
    "        filtered_column_data = column_data[mask]\n",
    "        \n",
    "        # Assign the filtered column data to the filtered DataFrame\n",
    "        filtered_df[column] = filtered_column_data\n",
    "        print(filtered_df.shape)\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "# Filter outliers\n",
    "filtered_df = filter_outliers(df2)\n",
    "# print(\"Original DataFrame:\")\n",
    "# print(df2)\n",
    "# print(\"\\nFiltered DataFrame:\")\n",
    "# print(filtered_df)\n",
    "\n",
    "ft_orig = df2[df2.columns[:4]]\n",
    "out_df = pd.concat([ft_orig, filtered_df],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = out_df\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_list = ['dis_one', 'dis_two', 'dis_three', 'dis_four', 'dis_five', 'dis_six', 'dis_seven', 'dis_eight', 'dis_nine', 'dis_ten',\n",
    "#  'dka_jan', 'dka_feb', 'dka_mar', 'dka_april', 'dka_may', 'dka_june', 'dka_july', 'dka_aug', 'dka_sep', 'dka_oct', 'dka_nov', 'dka_dec',\n",
    "#     'stc_one', 'stc_two', 'stc_three', 'stc_four', 'stc_five', 'stc_six', 'stc_seven', 'stc_eight', 'stc_nine', 'stc_ten', 'stc_elev', \n",
    "#     'stc_twelv', 'stc_thirt', 'stc_fourt', 'stc_fift', 'stc_sixt', 'stc_sevent', 'dka_sum', 'dka_sum.1', 'dka_sum.2', 'dka_sum.3', \n",
    "#              'stc_sum', 'stc_sum.1', 'stc_sum.2', 'stc_sum.3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop multiple columns\n",
    "# df2.drop(drop_list, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = df2.columns\n",
    "print(column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted value is x\n",
    "value_x = 'target'\n",
    "# variable is y\n",
    "value_y = \"b1_wfp_mean\"\n",
    "value_a = 'b2_dp1fm_dry_mean'\n",
    "value_b = 'b1_h99_mean'\n",
    "\n",
    "\n",
    "site = 'site_clean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ = r\"{0}:\\cdu\\data\\zonal_stats\\output\\{1}\\plots\\3_std_error\".format(drive, date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(value_x, value_y):\n",
    "    # Output to file\n",
    "    output_file(os.path.join(output_,'all_sites_{0}_{1}.html'.format(value_x, value_y)),\n",
    "                title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")))\n",
    "\n",
    "\n",
    "    #Specify the selection tools to be made available\n",
    "    select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'zoom_in', 'zoom_out', 'wheel_zoom', 'reset']\n",
    "\n",
    "    #print(test)\n",
    "    # Format the tooltip\n",
    "    tooltips = [\n",
    "                ('Site', '@site_clean'),\n",
    "                (value_x, '@{0}'.format(value_x)),\n",
    "                (value_y, '@{0}'.format(value_y)),   \n",
    "                (value_a, '@{0}'.format(value_a)),\n",
    "                (value_b, '@{0}'.format(value_b)) \n",
    "               ]\n",
    "\n",
    "    # Create the figure\n",
    "    fig = figure(plot_height=400,\n",
    "                 plot_width=1500,\n",
    "                 y_axis_label= value_y.replace(\"_\", \" \"), \n",
    "                 x_axis_label= value_x.replace(\"_\", \" \"),\n",
    "                 title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")),\n",
    "                 toolbar_location='below',\n",
    "                 tools=select_tools)\n",
    "\n",
    "    # # Format the y-axis tick label\n",
    "    fig.yaxis[0].formatter = NumeralTickFormatter(format='0')\n",
    "\n",
    "    # Add square representing each site\n",
    "    fig.square(x= value_x,\n",
    "               y= value_y,\n",
    "               source=df2.round(4),\n",
    "               size=5,\n",
    "               color='royalblue',\n",
    "               selection_color='deepskyblue',\n",
    "               nonselection_color='lightgray',\n",
    "               nonselection_alpha=0.3)\n",
    "\n",
    "    # Add the HoverTool to the figure\n",
    "    fig.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "    # Visualize\n",
    "    save(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2['target']>0.0]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = df2.columns.to_list()\n",
    "y_list = column_list[3:]\n",
    "value_x = column_list[1:2][0]\n",
    "\n",
    "\n",
    "for i in y_list:\n",
    "    value_y = i\n",
    "    save_fig(value_x, value_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(column_list[3:])\n",
    "print(column_list[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which data set to run the models from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_ml.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some of the unwanted values\n",
    "df_ml.drop(['site_clean',], axis=1, inplace=True)\n",
    "#df_ml.drop(['fpca2_imdate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce level of 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # due to the number of field sites with no basal collected data is stratified\n",
    "no0_df = df_ml[df_ml['target']>0.0]\n",
    "#no0_df = df_ml[df_ml['target']>=10.0]\n",
    "# agb_0 = df_ml[df_ml['bio_agb_kg1ha']==0.0].sample(3)\n",
    "# some0_df = pd.concat([no0_df, agb_0])\n",
    "\n",
    "## use this for reduced variables\n",
    "#no0_df = df[df['bio_agb_kg1ha']>0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the dataset to run the models from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define if you are using all variabes or selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All variables\n",
    "df_ml = no0_df\n",
    "\n",
    "# select variables\n",
    "#df = select_df\n",
    "df_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_ml[df_ml['target']>40000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plots with error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in df_ml.columns[1:]:\n",
    "#     print(i)\n",
    "#     value_x = 'target'\n",
    "#     value_y_loop = str(i)\n",
    "#     print(value_y_loop)\n",
    "#     plt.figure(figsize=(10,4))\n",
    "#     # left plot\n",
    "#     plt.subplot(1,2,1)\n",
    "#     sns.regplot(data = df_ml, x=value_x, y =value_y_loop, line_kws={\"color\":\"red\"})\n",
    "#     plt.xlabel(value_x)\n",
    "#     plt.ylabel(value_y_loop)\n",
    "#     plt.title(\"Regression {0} and {1}\".format(value_x, value_y_loop))\n",
    "    \n",
    "#     slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df_ml[value_x], df_ml[value_y_loop])\n",
    "\n",
    "#     print(\"=\"*50)\n",
    "#     print(\"Regression\")\n",
    "#     print(\"slope: \", slope)\n",
    "#     print(\"intersept: \", intercept)\n",
    "#     print(\"r2: \", r_value)\n",
    "#     print(\"P_value: \", p_value)\n",
    "#     print(\"std error: \", std_err)\n",
    "\n",
    "#     # right plot\n",
    "#     plt.subplot(1,2,2)\n",
    "#     sns.regplot(data=df_ml, x=value_x, y=value_y_loop, lowess=True, line_kws={\"color\":\"green\"})\n",
    "#     plt.xlabel(value_x)\n",
    "#     plt.ylabel(\"Error\")\n",
    "#     plt.title(\"Residual Error {0} and {1}\".format(value_x, value_y_loop))\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df_ml[value_x], df_ml[value_y])\n",
    "\n",
    "#     print(\"-\"*50)\n",
    "#     print(\"Residuals\")\n",
    "#     print(\"slope: \", slope)\n",
    "#     print(\"intersept: \", intercept)\n",
    "#     print(\"r2: \", r_value)\n",
    "#     print(\"P_value: \", p_value)\n",
    "#     print(\"std error: \", std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ml.to_csv(, index=False)\n",
    "df_ml.to_csv(os.path.join(output_, \"{0}_{1}_ml_data.csv\".format(var_, mdl)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "null_values = df_ml.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a value is in scientific notation\n",
    "def is_scientific_notation(value):\n",
    "    try:\n",
    "        float_value = float(value)\n",
    "        return '{:e}'.format(float_value) == value.lower()\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Check for scientific notation in each cell\n",
    "for column in df.columns:\n",
    "    for value in df[column]:\n",
    "        if is_scientific_notation(str(value)):\n",
    "            print(f\"Column {column}: {value} is in scientific notation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split off unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with 20%\n",
    "# values of original dataframe\n",
    "unseen_data = df_ml.sample(frac = 0.2)\n",
    " \n",
    "# Creating dataframe with\n",
    "# rest of the 80% values\n",
    "model_data = df_ml.drop(unseen_data.index)\n",
    "model_data = df_ml#.drop(unseen_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unseen data for histogram\n",
    "\n",
    "# xdata2_un = unseen_data.iloc[:, 1:].astype('float32')\n",
    "# ydata1_un = unseen_data[['target']].astype('float32')\n",
    "# ydata2_un = ydata1_un.values\n",
    "# ydata3_un = ydata2_un.ravel()\n",
    "\n",
    "# ydata_un = ydata3_un.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly split data into train and test datasets, the user needs to define the variables \n",
    "xdata1 = model_data.iloc[:, 1:].astype('float32')\n",
    "ydata1 = model_data[[value_x]].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata = ydata2.ravel()\n",
    "#y_data_float=ydata.astype(\"float32\")\n",
    "\n",
    "X_1, X_2, y_1, y_2 = train_test_split(xdata1, ydata, train_size=0.70)  \n",
    "         \n",
    "print(X_1.shape, y_1.shape)\n",
    "print(X_2.shape, y_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot up Histograms for train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create subplots\n",
    "#fig, axs = plt.subplots(1, 2, figsize=(10, 4))  # 1 row, 2 columns\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(3, 1, figsize=(4, 8))  # 3 rows, 1 column\n",
    "\n",
    "# Plot data on each subplot\n",
    "axs[0].hist(y_1)\n",
    "axs[0].set_title('Training')\n",
    "axs[0].set_xlabel('Target')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "axs[1].hist(y_2)\n",
    "axs[1].set_title('Testing')\n",
    "axs[1].set_xlabel('Target')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "axs[2].hist(ydata_un)\n",
    "axs[2].set_title('Unseen')\n",
    "axs[2].set_xlabel('Target')\n",
    "axs[2].set_ylabel('Frequency')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "out = os.path.join(output_, \"{0}_{1}_{2}_train_test_unseen_hist.png\".format(var_, fac, mdl))\n",
    "#print(out)                   \n",
    "plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()\n",
    "\n",
    "print(\"saved to: \", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterise the Random Forest Regressor alogorthim\n",
    "\n",
    "for details see: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(xdata1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data\n",
    "#X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(xdata1, ydata, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "if mdl == \"rfr\":\n",
    "\n",
    "    # Define model\n",
    "    model = rfr()\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [2, 10, 30, 40, 50, 100, 150, 200, 300], #5, 10, 20, 30, 40, \n",
    "        'max_depth': [None, 2, 3, 4, 5, 10, 20],\n",
    "        #'min_samples_split': [2, 3, 4, 5, 10],\n",
    "        #'min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "elif mdl == \"gbr\":\n",
    "    # Define model\n",
    "    model = gbr()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "    'n_estimators': [2, 5, 10, 50, 100, 150, 200, 300], #5, 10, 20, 30, 40, \n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    }\n",
    "\n",
    "elif mdl == \"abr\":\n",
    "    # Define model\n",
    "    model = abr()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "    'n_estimators': [2, 5, 10, 50, 100, 150, 200, 300], #5, 10, 20, 30, 40, \n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    }\n",
    "else:\n",
    "    print(\"ERROR__\"*100)\n",
    "\n",
    "# Define custom scorer for RMSE\n",
    "def custom_rmse_scorer(y_true, y_pred):\n",
    "    rmse = -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    #print(\"rmse: \", rmse)\n",
    "    return rmse\n",
    "\n",
    "# Define custom scorer for MAE\n",
    "def custom_mae_scorer(y_true, y_pred):\n",
    "    mae = -mean_absolute_error(y_true, y_pred)\n",
    "    #print(\"mae: \", mae)\n",
    "    return mae\n",
    "\n",
    "# Define custom scorer for MAE\n",
    "def custom_r2_scorer(y_true, y_pred):\n",
    "    # Mean of true target values\n",
    "    y_mean = np.mean(y_true)\n",
    "\n",
    "    # Calculate sum of squares of residuals\n",
    "    ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "    #print(\"ss_residual: \", ss_residual)\n",
    "\n",
    "    # Calculate sum of squares of total\n",
    "    ss_total = np.sum((y_true - y_mean) ** 2)\n",
    "    #print(\"ss_total: \", ss_total)\n",
    "    \n",
    "    # Calculate R^2\n",
    "    r2 = 1 - (ss_residual / ss_total)\n",
    "    print(\"r2: \", r2)\n",
    "\n",
    "\n",
    "    #r2 = r2_score(y_true, y_pred)\n",
    "    #print(\"r2: \", r2)\n",
    "    return r2\n",
    "\n",
    "# Make it a scorer\n",
    "#rmse_scorer = make_scorer(custom_rmse_scorer)\n",
    "#mae_scorer = make_scorer(custom_mae_scorer)\n",
    "r2_scorer = make_scorer(custom_r2_scorer)\n",
    "\n",
    "# def custom_r2_scorer(y_true, y_pred):\n",
    "\n",
    "#     r2 = r2_score(y_true, y_pred)\n",
    "#     print(\"r2: \", r2)\n",
    "#     return r2\n",
    "\n",
    "# Make it a scorer\n",
    "rmse_scorer = make_scorer(custom_rmse_scorer)\n",
    "mae_scorer = make_scorer(custom_mae_scorer)\n",
    "r2_scorer = make_scorer(custom_r2_scorer)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Create GridSearchCV object with RMSE scoring\n",
    "grid_search_rmse = GridSearchCV(model, param_grid, scoring=rmse_scorer, cv=5)\n",
    "grid_search_rmse.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(mdl)\n",
    "print(\"-\"*100)\n",
    "# Print the best score and parameters\n",
    "print(\"RMSE Best Score: \", grid_search_rmse.best_score_)\n",
    "print(\"RMSE Best Parameters: \", grid_search_rmse.best_params_)\n",
    "\n",
    "# Create GridSearchCV object with MAE scoring\n",
    "grid_search_mae = GridSearchCV(model, param_grid, scoring=mae_scorer, cv=5)\n",
    "grid_search_mae.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and parameters\n",
    "print(\"MAE Best Score: \", grid_search_mae.best_score_)\n",
    "print(\"MAE Best Parameters: \", grid_search_mae.best_params_)\n",
    "\n",
    "# Create GridSearchCV object with r2 scoring\n",
    "grid_search_r2 = GridSearchCV(model, param_grid, scoring=r2_scorer, cv=5)\n",
    "grid_search_r2.fit(X_train, y_train)\n",
    "\n",
    "# Print the best score and parameters\n",
    "print(\"r2 Best Score: \", grid_search_r2.best_score_)\n",
    "print(\"r2 Best Parameters: \", grid_search_r2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best RMSE parameters\n",
    "#best_params = grid_search_rmse.best_params_\n",
    "best_rf = grid_search_rmse.best_estimator_\n",
    "fac = \"RMSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best MAE parameters\n",
    "#best_params = grid_search_rmse.best_params_\n",
    "best_rf = grid_search_mae.best_estimator_\n",
    "fac = \"MAE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best R2 parameters\n",
    "#best_params = grid_search_rmse.best_params_\n",
    "best_rf = grid_search_r2.best_estimator_\n",
    "fac = \"r2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit random forest regressor model and compute variable importance score \n",
    "\n",
    "may need to restrict the number of variables for the bar graph to be legible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfrLCHM = rfrModel_1.fit(X_1, y_1)\n",
    "rfrLCHM = best_rf.fit(X_1, y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### good info on the feature importance score - http://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rfrLCHM.feature_importances_\n",
    "\n",
    "### TRY THIS\n",
    "# use \"feature importance\" scores to see what the top 10 important features are\n",
    "fi = enumerate(rfrLCHM.feature_importances_)\n",
    "cols = xdata1.columns\n",
    "fiResult = [(value,cols[i]) for (i,value) in fi]\n",
    "\n",
    "r2 = round(rfrLCHM.score(X_1, y_1),2)\n",
    "mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))**2), 2)\n",
    "rmse = round(np.sqrt(np.mean((y_1 - rfrLCHM.predict(X_1))**2)), 2)\n",
    "              \n",
    "\n",
    "plt.scatter(rfrLCHM.predict(X_1), y_1,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30000]\n",
    "y = [-1,30000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30000)\n",
    "plt.ylim(-1, 30000)\n",
    "\n",
    "plt.ylabel('Observed AGB')\n",
    "plt.xlabel('Predicted AGB')\n",
    "plt.title(f'Training data: {var_} - {mdl}')\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "# Add text to the plot\n",
    "plt.text(500, 28000, f'r2: {r2}', fontsize=10, color='black')\n",
    "plt.text(500, 26500, f'MSE: {mse}', fontsize=10, color='black')\n",
    "plt.text(500, 25000, f'RMSE: {rmse}', fontsize=10, color='black')\n",
    "plt.text(500, 23500, f'n: {len(y_1)}', fontsize=10, color='black')\n",
    "\n",
    "\n",
    "\n",
    "out = os.path.join(output_, \"{0}_{1}_{2}_train.pdf\".format(var_, fac, mdl))\n",
    "#print(out)                   \n",
    "plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()\n",
    "\n",
    "print(\"saved to: \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_predict = rfrLCHM.predict(X_2)\n",
    "\n",
    "r2 = round(rfrLCHM.score(X_2, y_2),2)\n",
    "mse = round(np.mean((y_2 - rfrLCHM.predict(X_2))** 2), 2)\n",
    "rmse = round(np.sqrt(np.mean((y2_predict - y_2) ** 2)), 2)\n",
    "bias = round(np.mean(y_2) - np.mean(y2_predict), 2)\n",
    "var = round(explained_variance_score(y_2, y2_predict), 2)\n",
    "\n",
    "plt.scatter(y2_predict, y_2)# ,s=10, c='b', marker='o')\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30000]\n",
    "y = [-1,30000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30000)\n",
    "plt.ylim(-1, 30000)\n",
    "plt.ylabel('Observed AGB')\n",
    "plt.xlabel('Predicted AGB')\n",
    "plt.title(f'Testing data: {mdl}')\n",
    "# 1 for 1 line\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "# Add text to the plot\n",
    "plt.text(500, 28000, f'r2: {r2}', fontsize=10, color='black')\n",
    "plt.text(500, 26500, f'MSE: {mse}', fontsize=10, color='black')\n",
    "plt.text(500, 25000, f'RMSE: {rmse}', fontsize=10, color='black')\n",
    "plt.text(500, 23500, f'Bias: {bias}', fontsize=10, color='black')\n",
    "plt.text(500, 22000, f'Exp var: {var}', fontsize=10, color='black')\n",
    "plt.text(500, 22000, f'n: {len(y_1)}', fontsize=10, color='black')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(output_, \"{0}_{1}_{2}_test_data.pdf\".format(var_, fac, mdl)), dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "fiResult = np.array(fiResult)\n",
    "score = (fiResult[:,0])\n",
    "arr_unicode =score\n",
    "# Convert Unicode strings to float values\n",
    "arr_float = arr_unicode.astype(np.float)\n",
    "\n",
    "# Round float values to two decimal places\n",
    "score_4 = np.around(arr_float, decimals=4)\n",
    "\n",
    "band = fiResult[:,1]\n",
    "a = fiResult[np.argsort(fiResult[:, 1])]\n",
    "\n",
    "df_band = pd.DataFrame(dict(band=band,n=score_4))\n",
    "df_band['n'].astype('float')\n",
    "dfsort = df_band.sort_values(['n'], ascending=[False])\n",
    "print(dfsort)\n",
    " \n",
    "## my complicated way to get the bar plot to sort in ascending order and display the assocated band names in the y axis\n",
    "dfsort2 = df_band.sort_values(['n'], ascending=[True])\n",
    "b = dfsort2[['band']]\n",
    "c = b.values.tolist()\n",
    "# convert the list of band names in the correct order to a string\n",
    "e = str(c)\n",
    "# strips all the rubbish from the string\n",
    "f = e.replace('[','').replace(']','').replace(\"'\",'').replace(\",\",' ')\n",
    "# convert the cleaned up string back into a list to plot the band names in the bar graph\n",
    "g = f.split()\n",
    " \n",
    "ind = np.arange(len(df_band))\n",
    "width = 0.4\n",
    " \n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(ind, dfsort2.n, width, color='blue')\n",
    "ax.set(yticks=ind + width, yticklabels= g, ylim=[2*width - 1, len(df_band)])\n",
    "ax.set_xlabel('Performance') #, rotation=45)\n",
    "ax.set_ylabel('Ranked variables') #, rotation=45)\n",
    "plt.xticks(rotation='vertical')\n",
    "ax.set_title('Variable Importance Rank')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "# fig.savefig('Band_Importance_Score.pdf',dpi=600)# save out your figure to a pdf \n",
    "# Save the plot\n",
    "\n",
    "out = os.path.join(output_, \"{0}_{1}_{2}_Band_Importance_Score.pdf\".format(var_, fac, mdl))\n",
    "plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the selected model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_band.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsort['n'].astype('float')\n",
    "dfsort.info()\n",
    "dfsort['n'] = dfsort['n'].astype('float')\n",
    "dfsort.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot has value at the top with very small n value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot has value at the top with very small n value\n",
    "\n",
    "sel_num = 10\n",
    "df_var = dfsort.head(sel_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_var = dfsort[dfsort['n'] > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_var = df_var.band.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_var.insert(0, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df = model_data[column_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = select_df.corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsort.to_csv(os.path.join(output_, \"{0}_{1}_{2}_variable_score.csv\".format(var_, fac, mdl)))\n",
    "df_corr.to_csv(os.path.join(output_, \"{0}_{1}_{2}_select_variable_corrolation.csv\".format(var_, fac, mdl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(df_corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(output_, \"{0}_{1}_{2}_variable_score.png\".format(var_, fac, mdl)), dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rerun on Selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata1 = select_df.iloc[:, 1:].astype('float32')\n",
    "ydata1 = select_df[[value_x]].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata = ydata2.ravel()\n",
    "\n",
    "X_1, X_2, y_1, y_2 = train_test_split(xdata1, ydata, train_size=0.70)  \n",
    "         \n",
    "print(X_1.shape, y_1.shape)\n",
    "print(X_2.shape, y_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "rfrModel_1 = rfr(n_estimators=100, random_state=rng)\n",
    "#rfrModel_1 = rfr(dtr(max_depth=None), n_estimators=100, min_samples_split=2, min_samples_leaf=1, random_state=rng)\n",
    "rfrModel_1\n",
    "\n",
    "#Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfrLCHM = rfrModel_1.fit(X_1, y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train model on selected paramiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rfrModel_1.feature_importances_\n",
    "\n",
    "### TRY THIS\n",
    "# use \"feature importance\" scores to see what the top 10 important features are\n",
    "fi = enumerate(rfrModel_1.feature_importances_)\n",
    "cols = xdata1.columns\n",
    "fiResult = [(value,cols[i]) for (i,value) in fi]\n",
    "#fiResult = [(value,cols[i]) for (i,value) in fi if value > 0.001]\n",
    "## Change the value 0.04 which we picked empirically to give us 10 variables\n",
    "## try running this code after changing the value up and down so you get more or less variables\n",
    "## do you see how this might be useful in refining the model?\n",
    "## Here is the code in case you mess up the line above\n",
    "## [(value,cols[i]) for (i,value) in fi if value > 0.04]\n",
    "#print fiResult\n",
    "\n",
    "print('Fitted model r2 =' ,  format(rfrLCHM.score(X_1, y_1), '.2f'))\n",
    "print('Fitted model mse =', format(np.mean((y_1 - rfrLCHM.predict(X_1))**2), '.2f'))\n",
    "print('n =', len(y_1))\n",
    "\n",
    "r2 = round(rfrLCHM.score(X_1, y_1),2)\n",
    "mse = round(np.mean((y_1 - rfrLCHM.predict(X_1))** 2), 2)\n",
    "rmse = round(np.sqrt(np.mean((y_1 - rfrLCHM.predict(X_1))** 2)), 2)\n",
    "#bias = round(np.mean(y_2) - np.mean(y2_predict), 2)\n",
    "\n",
    "\n",
    "plt.scatter(rfrLCHM.predict(X_1), y_1,)  \n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30000]\n",
    "y = [-1,30000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30000)\n",
    "plt.ylim(-1,30000)\n",
    "\n",
    "plt.ylabel('Observed AGB')\n",
    "\n",
    "plt.xlabel('Predicted AGB')\n",
    "plt.title(f'Training selected {str(sel_num)} data: {var_} - {mdl}')\n",
    "\n",
    "# Add text to the plot\n",
    "plt.text(500, 28000, f'r2: {r2}', fontsize=10, color='black')\n",
    "plt.text(500, 26500, f'MSE: {mse}', fontsize=10, color='black')\n",
    "plt.text(500, 25000, f'RMSE: {rmse}', fontsize=10, color='black')\n",
    "#plt.text(500, 23500, f'Bias: {bias}', fontsize=10, color='black')\n",
    "plt.text(500, 23500, f'n: {len(y_1)}', fontsize=10, color='black')\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "plt.savefig(os.path.join(output_, \"{0}_{1}_{2}_sel{3}_train.pdf\".format(var_, fac, mdl, sel_num)), dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiResult = np.array(fiResult)\n",
    "score = (fiResult[:,0])\n",
    "band = fiResult[:,1]\n",
    "a = fiResult[np.argsort(fiResult[:, 1])]\n",
    "\n",
    "arr_unicode =score\n",
    "# Convert Unicode strings to float values\n",
    "arr_float = arr_unicode.astype(np.float)\n",
    "\n",
    "# Round float values to two decimal places\n",
    "score_4 = np.around(arr_float, decimals=4)\n",
    "\n",
    "band = fiResult[:,1]\n",
    "a = fiResult[np.argsort(fiResult[:, 1])]\n",
    "\n",
    "df_band = pd.DataFrame(dict(band=band,n=score_4))\n",
    "df_band['n'].astype('float')\n",
    "dfsort = df_band.sort_values(['n'], ascending=[False])\n",
    "print(dfsort)\n",
    " \n",
    "## my complicated way to get the bar plot to sort in ascending order and display the assocated band names in the y axis\n",
    "dfsort2 = df_band.sort_values(['n'], ascending=[True])\n",
    "b = dfsort2[['band']]\n",
    "c = b.values.tolist()\n",
    "# convert the list of band names in the correct order to a string\n",
    "e = str(c)\n",
    "# strips all the rubbish from the string\n",
    "f = e.replace('[','').replace(']','').replace(\"'\",'').replace(\",\",' ')\n",
    "# convert the cleaned up string back into a list to plot the band names in the bar graph\n",
    "g = f.split()\n",
    " \n",
    "ind = np.arange(len(df_band))\n",
    "width = 0.4\n",
    " \n",
    "# Create a figure with a specific size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(ind, dfsort2.n, width, color='blue')\n",
    "ax.set(yticks=ind + width, yticklabels= g, ylim=[2*width - 1, len(df_band)])\n",
    "ax.set_xlabel('Performance')\n",
    "ax.set_ylabel('Ranked variables')\n",
    "plt.xticks(rotation='vertical')\n",
    "ax.set_title('Variable Importance Rank')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.show()\n",
    "# fig.savefig('Band_Importance_Score.pdf',dpi=600)# save out your figure to a pdf \n",
    "# Save the plot\n",
    "out = os.path.join(output_, \"{0}_{1}_{2}_select_{3}_Band_Importance_Score.pdf\".format(var_, fac, mdl, str(sel_num)))\n",
    "plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()\n",
    "print(\"plot: \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_predict = rfrLCHM.predict(X_2)\n",
    "\n",
    "r2 = round(rfrLCHM.score(X_2, y_2),2)\n",
    "mse = round(np.mean((y_2 - rfrLCHM.predict(X_2))** 2), 2)\n",
    "rmse = round(np.sqrt(np.mean((y2_predict - y_2) ** 2)), 2)\n",
    "bias = round(np.mean(y_2) - np.mean(y2_predict), 2)\n",
    "var = round(explained_variance_score(y_2, y2_predict), 2)\n",
    "\n",
    "plt.scatter(y2_predict, y_2) # ,s=10, c='b', marker='o')\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30000]\n",
    "y = [-1,30000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30000)\n",
    "plt.ylim(-1, 30000)\n",
    "plt.ylabel('Observed mean AGB')\n",
    "plt.xlabel('Predicted mean AGB')\n",
    "plt.title(f'Testing selected {str(sel_num)} data: {var_} - {mdl}')\n",
    "# 1 for 1 line\n",
    "plt.plot(x, y, color = 'r')\n",
    "\n",
    "# Add text to the plot\n",
    "plt.text(500, 28000, f'r2: {r2}', fontsize=10, color='black')\n",
    "plt.text(500, 26500, f'MSE: {mse}', fontsize=10, color='black')\n",
    "plt.text(500, 25000, f'RMSE: {rmse}', fontsize=10, color='black')\n",
    "plt.text(500, 23500, f'Bias: {bias}', fontsize=10, color='black')\n",
    "plt.text(500, 22000, f'Exp var: {var}', fontsize=10, color='black')\n",
    "plt.text(500, 20500, f'n: {len(y_1)}', fontsize=10, color='black')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(output_, \"{0}_{1}_{2}_sel{3}_test.pdf\".format(var_, fac, mdl, sel_num)), dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_imp_list = dfsort.band.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP - do you realy want to save this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remember to change the cPickle file name !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save current fitted model and apply to unseen validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#rfrL8CHM = rfr()\n",
    "#rfrL8CHM.fit(X_1, y_1)\n",
    "\n",
    "with open(\"{0}_{1}_{2}_sel_{3}_model\".format(var_, fac, mdl, sel_num), 'wb') as f:\n",
    "    pickle.dump(rfrLCHM, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in your validation dataset which has never been seen by rfr model - NOTE in this example I am just reading the same data used to train the model\n",
    "\n",
    "unseen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list = unseen_data.columns.tolist()\n",
    "c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = unseen_data[column_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df[(df['comp'] == 'l57')]\n",
    "df1 = df[(df['target'] > 0.0)]\n",
    "df1.dropna(inplace=True)\n",
    "print (df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfx = df1[:1]\n",
    "# dfy = df1[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[column_var].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xdata2 = df1['target'].astype('float32')\n",
    "\n",
    "# ydata1 = df1.drop('target', axis=1).astype('float32')\n",
    "# #df1.drop(\"target\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# ydata2 = ydata1.values\n",
    "\n",
    "# ydata = ydata2.ravel()\n",
    "\n",
    "# print(len(ydata))\n",
    "# #ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata2 = df1.iloc[:, 1:].astype('float32')\n",
    "ydata1 = df1[[value_x]].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata3 = ydata2.ravel()\n",
    "\n",
    "ydata = ydata3.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{0}_{1}_{2}_sel_{3}_model\".format(var_, fac, mdl, sel_num), 'rb') as f:\n",
    "        rf = pickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "\n",
    "r2 = round(rf.score(xdata2, ydata),2)\n",
    "mse = round(np.mean((ydata - rf.predict(xdata2))** 2), 2)\n",
    "rmse = round(np.sqrt(np.mean((predicted - ydata) ** 2)), 2)\n",
    "bias = round(np.mean(ydata) - np.mean(predicted), 2)\n",
    "var = round(explained_variance_score(ydata, predicted), 2)\n",
    "\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata) #,s=8, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30000]\n",
    "y = [-1,30000]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 30000)\n",
    "plt.ylim(-1, 30000)\n",
    "\n",
    "# Add text to the plot\n",
    "plt.text(500, 28000, f'r2: {r2}', fontsize=10, color='black')\n",
    "plt.text(500, 26500, f'MSE: {mse}', fontsize=10, color='black')\n",
    "plt.text(500, 25000, f'RMSE: {rmse}', fontsize=10, color='black')\n",
    "plt.text(500, 23500, f'Bias: {bias}', fontsize=10, color='black')\n",
    "plt.text(500, 22000, f'Exp var: {var}', fontsize=10, color='black')\n",
    "plt.text(500, 20500, f'n: {len(y_1)}', fontsize=10, color='black')\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "fig.savefig(\"{0}_{1}_{2}_sel_{3}_data.png\".format(var_, fac, mdl, str(sel_num)),dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = predicted\n",
    "y = ydata\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=0.5, edgecolor='')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "a = [-1,30]\n",
    "b = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30)\n",
    "plt.ylim(-1,30)\n",
    "plt.ylabel('Observed mean CHM')\n",
    "plt.xlabel('Predicted mean CHM')\n",
    "# 1 for 1 line\n",
    "ax.plot(a, b, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{0}_{1}_{2}_{3}_sel_data\".format(var_, d_type, fac, mdl)', 'rb') as f:\n",
    "        rf = cPickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print 'Predicted data r2 =', rf.score(xdata2, ydata)\n",
    "print 'MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f')\n",
    "print 'RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f')\n",
    "print 'explained_var =',format(explained_variance_score(ydata, predicted),  '.3f') \n",
    "print 'bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f')\n",
    "print 'n =' , len(ydata)\n",
    "\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=0.002, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30]\n",
    "y = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 30)\n",
    "plt.ylim(-1, 30)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "fig.savefig(\"{0}_{1}_{2}_{3}_sel_data.png\".format(var_, d_type, fac, mdl),dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = predicted\n",
    "y = ydata\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=0.5, edgecolor='')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "a = [-1,30]\n",
    "b = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30)\n",
    "plt.ylim(-1,30)\n",
    "plt.ylabel('Observed mean CHM')\n",
    "plt.xlabel('Predicted mean CHM')\n",
    "# 1 for 1 line\n",
    "ax.plot(a, b, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfr_modelNamel57', 'rb') as f:\n",
    "        rf = cPickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print 'Predicted data r2 =', rf.score(xdata2, ydata)\n",
    "print 'MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f')\n",
    "print 'RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f')\n",
    "print 'explained_var =',format(explained_variance_score(ydata, predicted),  '.3f') \n",
    "print 'bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f')\n",
    "print 'n =' , len(ydata)\n",
    "\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=0.002, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30]\n",
    "y = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 30)\n",
    "plt.ylim(-1, 30)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "fig.savefig('predicted_Observed_Validation.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = predicted\n",
    "y = ydata\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=0.5, edgecolor='')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "a = [-1,30]\n",
    "b = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30)\n",
    "plt.ylim(-1,30)\n",
    "plt.ylabel('Observed mean CHM')\n",
    "plt.xlabel('Predicted mean CHM')\n",
    "# 1 for 1 line\n",
    "ax.plot(a, b, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfr_modelNamel57', 'rb') as f:\n",
    "        rf = cPickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print 'Predicted data r2 =', rf.score(xdata2, ydata)\n",
    "print 'MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f')\n",
    "print 'RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f')\n",
    "print 'explained_var =',format(explained_variance_score(ydata, predicted),  '.3f') \n",
    "print 'bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f')\n",
    "print 'n =' , len(ydata)\n",
    "\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=0.002, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30]\n",
    "y = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 30)\n",
    "plt.ylim(-1, 30)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "fig.savefig('predicted_Observed_Validationgtr4m.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# data to plot\n",
    "x = predicted\n",
    "y = ydata\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=0.5, edgecolor='')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "a = [-1,30]\n",
    "b = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1,30)\n",
    "plt.ylim(-1,30)\n",
    "plt.ylabel('Observed mean CHM')\n",
    "plt.xlabel('Predicted mean CHM')\n",
    "# 1 for 1 line\n",
    "ax.plot(a, b, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rfr_modelNamel78', 'rb') as f:\n",
    "        rf = cPickle.load(f)\n",
    "\n",
    "        predicted = rf.predict(xdata2)\n",
    "\n",
    "#print 'r2 =' ,  rf.score(predicted, y_2)\n",
    "#print 'rmse =', np.sqrt(np.mean((y_2 - predicted)**2))\n",
    "#print 'n =' , len(y_2)\n",
    "\n",
    "print 'Predicted data r2 =', rf.score(xdata2, ydata)\n",
    "print 'MSE =', format(np.mean((ydata - rf.predict(xdata2))** 2), '.3f')\n",
    "print 'RMSE =', format(np.sqrt(np.mean((predicted - ydata) ** 2)), '.3f')\n",
    "print 'explained_var =',format(explained_variance_score(ydata, predicted),  '.3f') \n",
    "print 'bias =' , format(np.mean(ydata) - np.mean(predicted), '.3f')\n",
    "print 'n =' , len(ydata)\n",
    "\n",
    "\n",
    "# plot up predicted and observed data \n",
    "plt.scatter(predicted, ydata,s=0.002, c='b', marker='o')\n",
    "\n",
    "# data for the 1 for 1 line\n",
    "x = [-1,30]\n",
    "y = [-1,30]\n",
    "\n",
    "#sets the limits of the axis\n",
    "plt.xlim(-1, 30)\n",
    "plt.ylim(-1, 30)\n",
    "\n",
    "# 1 for 1 line\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot(x, y, color = 'black')\n",
    "fig.savefig('predicted_Observed_Validation.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
