{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# GBR_all_data_w_met_sddv4_h99_add_knn_xgboost"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following conditions apply:\n",
    "\n",
    " - env = biomass_zonal\n",
    " - data merged_slats_field_agb_dp1_start.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:51.496948Z",
     "start_time": "2024-08-02T06:26:51.069690Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import ExtraTreesRegressor as etr\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.ensemble import AdaBoostRegressor as abr\n",
    "from sklearn.tree import DecisionTreeRegressor as dtr\n",
    "from sklearn.neighbors import KNeighborsRegressor as knn\n",
    "from xgboost import XGBRegressor as xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as sc\n",
    "import textwrap\n",
    "\n",
    "# stats module\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "%matplotlib inline\n",
    "\n",
    "# import plotting and stats modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "# Set option to display floating-point numbers without scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import save # figure, show, \n",
    "#%matplotlib inline\n",
    "\n",
    "# Bokeh Libraries\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_file\n",
    "from bokeh.models import ColumnDataSource, NumeralTickFormatter, HoverTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.591384Z",
     "start_time": "2024-08-02T06:26:52.578377Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# mdl = \"RFR\"\n",
    "# model_name = \"Random Forrest Regressor\"\n",
    "\n",
    "\n",
    "#mdl = \"ABR\"\n",
    "#model_name = \"AdaBoost Regressor\"\n",
    "\n",
    "mdl = \"GBR\"\n",
    "model_name = \"Gradient Boosting Regressor\"\n",
    "\n",
    "# mdl = \"KNN\"\n",
    "# model_name = \"K-Nearest Neighbors Regressor\"\n",
    "\n",
    "# mdl = \"XGBR\"\n",
    "# model_name = \"XGBoost Regressor\"\n",
    "\n",
    "\n",
    "rs = 0\n",
    "drive = \"D\"\n",
    "data_comp = f\"{mdl}_dp1_dbi_si_dry_mask_density_sddv4_h99\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.654412Z",
     "start_time": "2024-08-02T06:26:52.640411Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_file = r\"C:\\Users\\robot\\projects\\biomass\\collated_zonal_stats\\dry_mask\\dp1_dbi_si_dry_mask_density.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set output file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.734412Z",
     "start_time": "2024-08-02T06:26:52.722411Z"
    }
   },
   "outputs": [],
   "source": [
    "output = r\"C:\\Users\\robot\\projects\\biomass\\model\\{}\".format(data_comp)\n",
    "output_ = os.path.join(output, \"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.766412Z",
     "start_time": "2024-08-02T06:26:52.752411Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(output):\n",
    "    os.mkdir(output)\n",
    "if not os.path.isdir(output_):\n",
    "    os.mkdir(output_)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_path = os.path.join(output_, \"DEF\")    \n",
    "if not os.path.isdir(def_path):\n",
    "    os.mkdir(def_path)\n",
    "    \n",
    "r2_path = os.path.join(output_, \"R2\")    \n",
    "if not os.path.isdir(r2_path):\n",
    "    os.mkdir(r2_path)\n",
    "    \n",
    "mae_path = os.path.join(output_, \"MAE\")    \n",
    "if not os.path.isdir(mae_path):\n",
    "    os.mkdir(mae_path)\n",
    "    \n",
    "rmse_path = os.path.join(output_, \"RMSE\")    \n",
    "if not os.path.isdir(rmse_path):\n",
    "    os.mkdir(rmse_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.860731Z",
     "start_time": "2024-08-02T06:26:52.833411Z"
    }
   },
   "outputs": [],
   "source": [
    "# read as dataframe and copy\n",
    "df1 = pd.read_csv(csv_file, header=0) # the first row is read in as the header for you columns\n",
    "print(df1.shape) # prints out the number of rows and columns in your csv file \n",
    "print(list(df1))\n",
    "df1.shape\n",
    "#df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.876721Z",
     "start_time": "2024-08-02T06:26:52.867732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for null values in each column\n",
    "columns_with_nulls = df1.columns[df1.isnull().any()]\n",
    "columns_with_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.970722Z",
     "start_time": "2024-08-02T06:26:52.938723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill missing values with the minimum value of each column\n",
    "df1 = df1.apply(lambda col: col.fillna(col.min()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.002722Z",
     "start_time": "2024-08-02T06:26:52.987723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for null values in each column\n",
    "columns_with_nulls = df1.columns[df1.isnull().any()]\n",
    "columns_with_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.082722Z",
     "start_time": "2024-08-02T06:26:53.066722Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df1.rename(columns={'bio_agb_kg1ha': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.190722Z",
     "start_time": "2024-08-02T06:26:53.168723Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.238722Z",
     "start_time": "2024-08-02T06:26:53.231722Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_with_nulls = df.columns[df.isnull().any()]\n",
    "columns_with_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.359721Z",
     "start_time": "2024-08-02T06:26:53.341722Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.436722Z",
     "start_time": "2024-08-02T06:26:53.431722Z"
    }
   },
   "outputs": [],
   "source": [
    "#main major and h99 \n",
    "var_ = data_comp\n",
    "\n",
    "df_columns = list(df.columns)\n",
    "keep = ['site_clean', \"target\", \n",
    "        #\"mean\", \n",
    "        \"major\", \n",
    "        \"p99\", \n",
    "        \"GNDVI\", \"MSR\", \"NBR\", \"_NDVI\", \"CVI\", \"GDVI\", \"GSAVI\",\n",
    "        \"NDGI\",\"RI\", \"NDII\", \"MSAVI\", \"SAVI\"\n",
    "       'r32', 'r42', 'r43',\n",
    "         'r52', 'r53', 'r54', 'r62', 'r63', 'r64', 'r65',\n",
    "         #'dr_', 'ma_', 'tx_', 'tn_', 'rx_', 'rn_'\n",
    "        ]\n",
    "header = [ele for ele in df_columns for x in keep if x in ele]\n",
    "df2 = df[header]\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop fdc - no need for this data\n",
    "\n",
    "# Identify columns that contain \"fdc\" in their column names\n",
    "columns_to_drop = df2.columns[df2.columns.str.contains(\"fdc\", case=False)]\n",
    "\n",
    "# Drop these columns\n",
    "df2 = df2.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.577124Z",
     "start_time": "2024-08-02T06:26:53.562622Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df2.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.656830Z",
     "start_time": "2024-08-02T06:26:53.642822Z"
    }
   },
   "outputs": [],
   "source": [
    "df_columns = list(df2.columns)\n",
    "keep = ['major']\n",
    "       \n",
    "classified_cols = [ele for ele in df_columns for x in keep if x in ele]\n",
    "print(classified_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.704822Z",
     "start_time": "2024-08-02T06:26:53.692822Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2 = df2[['site_clean', 'target', 'dbifmdry_r42', 'dbifmdry_r43', 'dbifmdry_r52', 'dbifmdry_r53', 'dbifmdry_r54', 'dbifmdry_r62', 'dbifmdry_r63', 'dbifmdry_r64', 'dbifmdry_r65', 'dbifmdry_NDVI',\n",
    "# \n",
    "#  ]]\n",
    "# print(df2.columns.tolist())\n",
    "# var_ = \"_ratio_NDVI_only_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.846825Z",
     "start_time": "2024-08-02T06:26:53.829822Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.908826Z",
     "start_time": "2024-08-02T06:26:53.903826Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for duplicate columns and print them\n",
    "duplicate_columns = df2.columns[df2.columns.duplicated()]\n",
    "\n",
    "if duplicate_columns.any():\n",
    "    print(\"Duplicate columns found:\")\n",
    "    for col in duplicate_columns:\n",
    "        print(col)\n",
    "else:\n",
    "    print(\"No duplicate columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove site values which seem like outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect outliers using Z score on all columns including Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.048829Z",
     "start_time": "2024-08-02T06:26:54.028823Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Z score outliers on all columns except target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.456937Z",
     "start_time": "2024-08-02T06:26:54.412937Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "# Function to detect outliers using Z-score\n",
    "def detect_outliers(df, target_column):\n",
    "    # Select only numeric columns except the target column\n",
    "    numeric_df = df.select_dtypes(include=[np.number]).drop(columns=[target_column])\n",
    "    \n",
    "    # Calculate the Z-scores\n",
    "    z_scores = np.abs(zscore(numeric_df))\n",
    "    \n",
    "    # Identify rows with Z-scores greater than 3 in any column\n",
    "    outliers = (z_scores > 4).any(axis=1)\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "# Assuming df2 is your DataFrame with mixed data types and 'target' is the target column\n",
    "df = df2.copy()\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'target'  # Replace 'target' with the name of your target column\n",
    "\n",
    "# Detect outliers\n",
    "outliers = detect_outliers(df, target_column)\n",
    "\n",
    "# Print the detected outliers\n",
    "print(\"Detected Outliers:\")\n",
    "print(df[outliers])\n",
    "\n",
    "# If you want to highlight these outliers in the original DataFrame\n",
    "df_highlighted = df.copy()\n",
    "\n",
    "for col in df.select_dtypes(include=[np.number]).drop(columns=[target_column]).columns:\n",
    "    df_highlighted[col + '_outlier'] = np.where(outliers, 'Outlier', 'Normal')\n",
    "\n",
    "print(\"Original DataFrame with Outliers Highlighted:\")\n",
    "print(df_highlighted)\n",
    "\n",
    "output_ = os.path.join(output, f\"dry_mask_{var_}_not_target_outlier.csv\")\n",
    "df_highlighted.to_csv(output_, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.550938Z",
     "start_time": "2024-08-02T06:26:54.515939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to detect outliers using Z-score\n",
    "def detect_outliers(df):\n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Calculate the Z-scores\n",
    "    z_scores = np.abs(zscore(numeric_df))\n",
    "    \n",
    "    # Identify rows with Z-scores greater than 3 in any column\n",
    "    outliers = (z_scores > 4).any(axis=1)\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "# Assuming df2 is your DataFrame with mixed data types\n",
    "df = df2.copy()\n",
    "\n",
    "# Detect outliers\n",
    "outliers = detect_outliers(df)\n",
    "\n",
    "# Print the detected outliers\n",
    "print(\"Detected Outliers:\")\n",
    "print(df[outliers].site_clean)\n",
    "\n",
    "# Drop rows that contain outliers\n",
    "df_cleaned = df[~outliers]\n",
    "\n",
    "print(\"Cleaned DataFrame (without outliers):\")\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.599968Z",
     "start_time": "2024-08-02T06:26:54.573948Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.728997Z",
     "start_time": "2024-08-02T06:26:54.722001Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.820998Z",
     "start_time": "2024-08-02T06:26:54.817998Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.901005Z",
     "start_time": "2024-08-02T06:26:54.886997Z"
    }
   },
   "outputs": [],
   "source": [
    "# predicted value is x\n",
    "value_x = 'target'\n",
    "# variable is y\n",
    "value_y = \"b1_wfp_mean\"\n",
    "value_a = 'b2_dp1fm_dry_mean'\n",
    "value_b = 'b1_h99_mean'\n",
    "\n",
    "\n",
    "site = 'site_clean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:55.104999Z",
     "start_time": "2024-08-02T06:26:55.086998Z"
    }
   },
   "outputs": [],
   "source": [
    "value_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:55.152998Z",
     "start_time": "2024-08-02T06:26:55.141998Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:55.246998Z",
     "start_time": "2024-08-02T06:26:55.230999Z"
    }
   },
   "outputs": [],
   "source": [
    "output_int = os.path.join(output, \"inter\")\n",
    "if not os.path.isdir(output_int):\n",
    "    os.mkdir(output_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:55.311Z",
     "start_time": "2024-08-02T06:26:55.287998Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_fig(value_x, value_y):\n",
    "    # Output to file\n",
    "    output_file(os.path.join(output_int,'all_sites_{0}_{1}.html'.format(value_x, value_y)),\n",
    "                title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")))\n",
    "\n",
    "\n",
    "    #Specify the selection tools to be made available\n",
    "    select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'zoom_in', 'zoom_out', 'wheel_zoom', 'reset']\n",
    "\n",
    "    #print(test)\n",
    "    # Format the tooltip\n",
    "    tooltips = [\n",
    "                ('Site', '@site_clean'),\n",
    "                (value_x, '@{0}'.format(value_x)),\n",
    "                (value_y, '@{0}'.format(value_y)),   \n",
    "                (value_a, '@{0}'.format(value_a)),\n",
    "                (value_b, '@{0}'.format(value_b)) \n",
    "               ]\n",
    "\n",
    "    # Create the figure\n",
    "    fig = figure(plot_height=400,\n",
    "                 plot_width=1500,\n",
    "                 y_axis_label= value_y.replace(\"_\", \" \"), \n",
    "                 x_axis_label= value_x.replace(\"_\", \" \"),\n",
    "                 title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")),\n",
    "                 toolbar_location='below',\n",
    "                 tools=select_tools)\n",
    "\n",
    "    # # Format the y-axis tick label\n",
    "    fig.yaxis[0].formatter = NumeralTickFormatter(format='0')\n",
    "\n",
    "    # Add square representing each site\n",
    "    fig.square(x= value_x,\n",
    "               y= value_y,\n",
    "               source=df2.round(4),\n",
    "               size=5,\n",
    "               color='royalblue',\n",
    "               selection_color='deepskyblue',\n",
    "               nonselection_color='lightgray',\n",
    "               nonselection_alpha=0.3)\n",
    "\n",
    "    # Add the HoverTool to the figure\n",
    "    fig.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "    # Visualize\n",
    "    save(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:55.466997Z",
     "start_time": "2024-08-02T06:26:55.453997Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.416305Z",
     "start_time": "2024-08-02T06:26:55.493997Z"
    }
   },
   "outputs": [],
   "source": [
    "column_list = df2.columns.to_list()\n",
    "y_list = column_list[3:]\n",
    "value_x = column_list[1:2][0]\n",
    "\n",
    "\n",
    "for i in y_list:\n",
    "    value_y = i\n",
    "    save_fig(value_x, value_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.432297Z",
     "start_time": "2024-08-02T06:26:56.417298Z"
    }
   },
   "outputs": [],
   "source": [
    "print(column_list[3:])\n",
    "print(column_list[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding (for Tree-based Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.448305Z",
     "start_time": "2024-08-02T06:26:56.433299Z"
    }
   },
   "outputs": [],
   "source": [
    "# add columns that contain class data n17\n",
    "classified_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.464377Z",
     "start_time": "2024-08-02T06:26:56.449298Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.479696Z",
     "start_time": "2024-08-02T06:26:56.465691Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in classified_cols:\n",
    "    df2 = pd.get_dummies(df2, columns=[i], prefix=f'{i}_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.495696Z",
     "start_time": "2024-08-02T06:26:56.480696Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_encoded\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which data set to run the models from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.511696Z",
     "start_time": "2024-08-02T06:26:56.496696Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.527696Z",
     "start_time": "2024-08-02T06:26:56.513696Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop some of the unwanted values\n",
    "df_ml.drop(['site_clean',], axis=1, inplace=True)\n",
    "#df_ml.drop(['fpca2_imdate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.542696Z",
     "start_time": "2024-08-02T06:26:56.529696Z"
    }
   },
   "outputs": [],
   "source": [
    "print(list(df_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.557696Z",
     "start_time": "2024-08-02T06:26:56.543696Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.573696Z",
     "start_time": "2024-08-02T06:26:56.559696Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce level of 0 values is this cell needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop AGB numbers which are low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.589696Z",
     "start_time": "2024-08-02T06:26:56.574696Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2 = df2[df2['target']>0.0]\n",
    "# #df2 = df2[df2['target']>1000.0]\n",
    "# df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.605701Z",
     "start_time": "2024-08-02T06:26:56.591701Z"
    }
   },
   "outputs": [],
   "source": [
    "# columns_with_nulls = df2.columns[df2.isnull().any()]\n",
    "# columns_with_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop AGB numbers which are high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.621214Z",
     "start_time": "2024-08-02T06:26:56.607204Z"
    }
   },
   "outputs": [],
   "source": [
    "# # drop the 7 tern sites that appear to be outliers\n",
    "# df2 =df2[df2['target'] <= 40000]\n",
    "# df2.to_csv(os.path.join(output, \"{0}_lt_40000.csv\".format('target')))\n",
    "# #df2 =df2[df2['target'] > 40000]\n",
    "# #df2.value_counts(['site_clean', value_x, value_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.636476Z",
     "start_time": "2024-08-02T06:26:56.622215Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.651989Z",
     "start_time": "2024-08-02T06:26:56.638476Z"
    }
   },
   "outputs": [],
   "source": [
    "#no removal\n",
    "out_df = df_ml\n",
    "samp = \"all_data\"\n",
    "\n",
    "# # due to the number of field sites with no basal collected data is stratified\n",
    "# out_df = df_ml[df_ml['target']>0.0]\n",
    "# samp = \"no0\"\n",
    "# out_df.to_csv(os.path.join(output, \"more_than_0kgha.csv\"))\n",
    "# out_df = df_ml[df_ml['target']>=10.0]\n",
    "# samp=\"more_t_10\"\n",
    "# out_df.to_csv(os.path.join(output, \"more_than_10kgha.csv\"))\n",
    "# \n",
    "# # create a random selection of 0 - based on sample size\n",
    "# sample_size = 3\n",
    "# no_0_df = df_ml[df_ml['target']>0.0]\n",
    "# samp = \"no0\"\n",
    "# agb_0 = df_ml[df_ml['bio_agb_kg1ha']==0.0].sample(sample_size)\n",
    "# out_df = pd.concat([no_0_df, agb_0])\n",
    "# out_df.to_csv(os.path.join(output, \"ml_df_0_sample_{0}kgha.csv\".format(str(sample_size))))\n",
    "# samp = f\"some0_{sample_size}\"\n",
    "# \n",
    "# \n",
    "# out_df =df_ml[df_ml['target'] <= 40000]\n",
    "# out_df.to_csv(os.path.join(output, \"less_than_40000kgha.csv\"))\n",
    "# samp = \"less_t_40\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.667502Z",
     "start_time": "2024-08-02T06:26:56.652990Z"
    }
   },
   "outputs": [],
   "source": [
    "test = out_df[out_df['target']>40000.0]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the dataset to run the models from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.683501Z",
     "start_time": "2024-08-02T06:26:56.668502Z"
    }
   },
   "outputs": [],
   "source": [
    "# All variables\n",
    "df_ml = out_df\n",
    "\n",
    "# select variables\n",
    "#df = select_df\n",
    "df_ml.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define if you are using all variabes or selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.699501Z",
     "start_time": "2024-08-02T06:26:56.684502Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.715502Z",
     "start_time": "2024-08-02T06:26:56.701502Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.731502Z",
     "start_time": "2024-08-02T06:26:56.717501Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.747502Z",
     "start_time": "2024-08-02T06:26:56.733502Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.811502Z",
     "start_time": "2024-08-02T06:26:56.750501Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plots with error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.827501Z",
     "start_time": "2024-08-02T06:26:56.812502Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_ml.to_csv(, index=False)\n",
    "df_ml.to_csv(os.path.join(output, \"{0}_{1}_{2}_ml_data.csv\".format(var_, mdl, samp)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.875503Z",
     "start_time": "2024-08-02T06:26:56.828502Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.891503Z",
     "start_time": "2024-08-02T06:26:56.876504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "null_values = df_ml.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.907513Z",
     "start_time": "2024-08-02T06:26:56.892503Z"
    }
   },
   "outputs": [],
   "source": [
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.922503Z",
     "start_time": "2024-08-02T06:26:56.908503Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.937502Z",
     "start_time": "2024-08-02T06:26:56.923503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to check if a value is in scientific notation\n",
    "def is_scientific_notation(value):\n",
    "    try:\n",
    "        float_value = float(value)\n",
    "        return '{:e}'.format(float_value) == value.lower()\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Check for scientific notation in each cell\n",
    "for column in df_ml.columns:\n",
    "    for value in df_ml[column]:\n",
    "        if is_scientific_notation(str(value)):\n",
    "            print(f\"Column {column}: {value} is in scientific notation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:27:43.511703Z",
     "start_time": "2024-08-02T06:26:56.939503Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_ml\n",
    "\n",
    "def plot_with_mean_median(df, columns):\n",
    "    for col in columns:\n",
    "        plt.figure(figsize=(14, 10))\n",
    "\n",
    "        # Top-left plot: Distribution with mean and median\n",
    "        plt.subplot(2, 2, 1)\n",
    "        sns.histplot(df[col], kde=True, color='blue', bins=30)\n",
    "        \n",
    "        # Calculate mean and median\n",
    "        mean = df[col].mean()\n",
    "        median = df[col].median()\n",
    "        \n",
    "        # Plot mean and median as dashed lines\n",
    "        plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "        plt.axvline(median, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "        \n",
    "        plt.title(f'Distribution of {col}', fontsize=16)\n",
    "        plt.xlabel(col, fontsize=14)\n",
    "        plt.ylabel('Frequency', fontsize=14)\n",
    "        plt.legend(fontsize=12)\n",
    "        \n",
    "        # Top-right plot: Regression plot\n",
    "        value_x = 'target'\n",
    "        C_value_x = \"Target\"\n",
    "        value_y_loop = col\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        sns.regplot(data=df_ml, x=value_x, y=value_y_loop, line_kws={\"color\": \"red\"}, scatter_kws={'s': 50, 'alpha': 0.5, 'color': 'blue'})\n",
    "        plt.xlabel(C_value_x, fontsize=14)\n",
    "        plt.ylabel(value_y_loop, fontsize=14)\n",
    "        plt.title(f\"Regression of {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df_ml[value_x], df_ml[value_y_loop])\n",
    "\n",
    "        # Annotate the stats\n",
    "        plt.text(0.95, 0.95, f'slope: {slope:.2f}\\nintercept: {intercept:.2f}\\nr2: {r_value:.2f}\\np-value: {p_value:.2f}\\nstd err: {std_err:.2f}',\n",
    "                 transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='right', fontsize=12)\n",
    "\n",
    "        # Bottom-left plot: Residuals plot\n",
    "        plt.subplot(2, 2, 3)\n",
    "        sns.regplot(data=df_ml, x=value_x, y=value_y_loop, lowess=True, line_kws={\"color\": \"green\"}, scatter_kws={'s': 50, 'alpha': 0.5, 'color': 'blue'})\n",
    "        plt.xlabel(C_value_x, fontsize=14)\n",
    "        plt.ylabel(\"Error\", fontsize=14)\n",
    "        plt.title(f\"Residuals of Regression: {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "\n",
    "        residuals = df_ml[value_y_loop] - (slope * df_ml[value_x] + intercept)\n",
    "\n",
    "        # Compute additional residual statistics\n",
    "        mean_res = np.mean(residuals)\n",
    "        std_res = np.std(residuals)\n",
    "        rmse_res = np.sqrt(np.mean(residuals**2))\n",
    "        mae_res = np.mean(np.abs(residuals))\n",
    "        r2_res = scipy.stats.linregress(df_ml[value_x], residuals)[2]**2\n",
    "\n",
    "        # Annotate the residual stats\n",
    "        plt.text(0.95, 0.95, f'Mean: {mean_res:.2f}\\nStd: {std_res:.2f}\\nRMSE: {rmse_res:.2f}\\nMAE: {mae_res:.2f}\\nr2: {r2_res:.2f}',\n",
    "                 transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='right', fontsize=12)\n",
    "\n",
    "        # Bottom-right plot: Q-Q plot\n",
    "        plt.subplot(2, 2, 4)\n",
    "        scipy.stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "        plt.title(f\"Q-Q Plot of Residuals: {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "        \n",
    "        # Increase font size for Q-Q plot\n",
    "        plt.xlabel('Theoretical Quantiles', fontsize=14)\n",
    "        plt.ylabel('Sample Quantiles', fontsize=14)\n",
    "        plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        plt_out = os.path.join(output, \"plots\", f\"{var_}_{mdl}_{value_y_loop}_{rs}_combined_plot_tr.JPG\")\n",
    "        plt.savefig(plt_out, dpi=300)\n",
    "        plt.show()\n",
    "        print(\"plot: \", plt_out)\n",
    "        plt.close()\n",
    "\n",
    "# Assuming df_ml.columns[1:] contains the columns to be plotted\n",
    "plot_with_mean_median(df, df_ml.columns[1:])\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:28:17.129358Z",
     "start_time": "2024-08-02T06:27:43.512694Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_ml\n",
    "\n",
    "def plot_with_mean_median(df, columns):\n",
    "    for col in columns:\n",
    "        plt.figure(figsize=(14, 10))\n",
    "\n",
    "        # Top-left plot: Distribution with mean and median\n",
    "        plt.subplot(2, 2, 1)\n",
    "        sns.histplot(df[col], kde=True, color='blue', bins=30)\n",
    "        \n",
    "        # Calculate mean and median\n",
    "        mean = df[col].mean()\n",
    "        median = df[col].median()\n",
    "        \n",
    "        # Plot mean and median as dashed lines\n",
    "        plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "        plt.axvline(median, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "        \n",
    "        plt.title(f'Distribution of {col}', fontsize=16)\n",
    "        plt.xlabel(col, fontsize=14)\n",
    "        plt.ylabel('Frequency', fontsize=14)\n",
    "        plt.legend(fontsize=12)\n",
    "        \n",
    "        # Top-right plot: Regression plot\n",
    "        value_x = 'target'\n",
    "        C_value_x = 'Target'\n",
    "        value_y_loop = col\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        sns.regplot(data=df_ml, x=value_x, y=value_y_loop, line_kws={\"color\": \"red\"}, scatter_kws={'s': 50, 'alpha': 0.5, 'color': 'blue'})\n",
    "        plt.xlabel(C_value_x, fontsize=14)\n",
    "        plt.ylabel(value_y_loop, fontsize=14)\n",
    "        plt.title(f\"Regression of {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df_ml[value_x], df_ml[value_y_loop])\n",
    "\n",
    "        # Annotate the stats\n",
    "        plt.text(0.95, 0.05, f'slope: {slope:.2f}\\nintercept: {intercept:.2f}\\nr2: {r_value:.2f}\\np-value: {p_value:.2f}\\nstd err: {std_err:.2f}',\n",
    "                 transform=plt.gca().transAxes, verticalalignment='bottom', horizontalalignment='right', fontsize=12)\n",
    "\n",
    "        # Bottom-left plot: Residuals plot\n",
    "        plt.subplot(2, 2, 3)\n",
    "        sns.regplot(data=df_ml, x=value_x, y=value_y_loop, lowess=True, line_kws={\"color\": \"green\"}, scatter_kws={'s': 50, 'alpha': 0.5, 'color': 'blue'})\n",
    "        plt.xlabel(C_value_x, fontsize=14)\n",
    "        plt.ylabel(\"Error\", fontsize=14)\n",
    "        plt.title(f\"Residuals of Regression: {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "\n",
    "        residuals = df_ml[value_y_loop] - (slope * df_ml[value_x] + intercept)\n",
    "\n",
    "        # Compute additional residual statistics\n",
    "        mean_res = np.mean(residuals)\n",
    "        std_res = np.std(residuals)\n",
    "        rmse_res = np.sqrt(np.mean(residuals**2))\n",
    "        mae_res = np.mean(np.abs(residuals))\n",
    "        r2_res = scipy.stats.linregress(df_ml[value_x], residuals)[2]**2\n",
    "\n",
    "        # Annotate the residual stats\n",
    "        plt.text(0.95, 0.05, f'Mean: {mean_res:.2f}\\nStd: {std_res:.2f}\\nRMSE: {rmse_res:.2f}\\nMAE: {mae_res:.2f}\\nr2: {r2_res:.2f}',\n",
    "                 transform=plt.gca().transAxes, verticalalignment='bottom', horizontalalignment='right', fontsize=12)\n",
    "\n",
    "        # Bottom-right plot: Q-Q plot\n",
    "        plt.subplot(2, 2, 4)\n",
    "        scipy.stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "        plt.title(f\"Q-Q Plot of Residuals: {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "        \n",
    "        # Increase font size for Q-Q plot\n",
    "        plt.xlabel('Theoretical Quantiles', fontsize=14)\n",
    "        plt.ylabel('Sample Quantiles', fontsize=14)\n",
    "        plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        plt_out = os.path.join(output, \"plots\", f\"{var_}_{mdl}_{value_y_loop}_{rs}_combined_plot_br.JPG\")\n",
    "        plt.savefig(plt_out, dpi=300)\n",
    "        #plt.show()\n",
    "        print(\"plot: \", plt_out)\n",
    "        plt.close()\n",
    "\n",
    "# Assuming df_ml.columns[1:] contains the columns to be plotted\n",
    "plot_with_mean_median(df, df_ml.columns[1:])\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split off validation test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:28:17.145079Z",
     "start_time": "2024-08-02T06:28:17.130283Z"
    }
   },
   "outputs": [],
   "source": [
    "value_x = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:28:17.160999Z",
     "start_time": "2024-08-02T06:28:17.146001Z"
    }
   },
   "outputs": [],
   "source": [
    "#select random state\n",
    "#rs = 0\n",
    "\n",
    "# randomly split data into train and test datasets, the user needs to define the variables \n",
    "xdata1 = df_ml.iloc[:, 1:].astype('float32')\n",
    "ydata1 = df_ml[[value_x]].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata = ydata2.ravel()\n",
    "#y_data_float=ydata.astype(\"float32\")\n",
    "x_validation, x_remaining, y_validation, y_remaining = train_test_split(xdata1, ydata, train_size=0.20, random_state=rs)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_remaining, y_remaining, train_size=0.70, random_state=rs)  \n",
    "print(x_validation.shape, y_validation.shape)\n",
    "print(\"remaining.....\")\n",
    "print(x_remaining.shape, y_remaining.shape)\n",
    "print(\"-\"*50)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot up Histograms for train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:28:17.740462Z",
     "start_time": "2024-08-02T06:28:17.162024Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# output = '.'  # Replace with your actual output directory\n",
    "# var_ = 'example_var'\n",
    "# mdl = 'example_model'\n",
    "# rs = 'example_run'\n",
    "\n",
    "# Create subplots: 1 row, 3 columns\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))  # Adjust figsize as needed\n",
    "\n",
    "# Define the data and titles for each subplot\n",
    "data = [y_train, y_test, y_validation]\n",
    "titles = ['Training Data Distribution', 'Testing Data Distribution', 'Validation Data Distribution']\n",
    "\n",
    "for i, (data_set, title) in enumerate(zip(data, titles)):\n",
    "    mean = np.mean(data_set)\n",
    "    median = np.median(data_set)\n",
    "    \n",
    "    # Plot histogram with seaborn\n",
    "    sns.histplot(data_set, kde=True, bins=20, ax=axs[i], color='blue', alpha=0.7)\n",
    "    \n",
    "    # Plot mean and median lines\n",
    "    axs[i].axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "    axs[i].axvline(median, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "    \n",
    "    axs[i].set_title(title, fontsize=16)\n",
    "    axs[i].set_xlabel('Target', fontsize=14)\n",
    "    axs[i].set_ylabel('Frequency', fontsize=14)\n",
    "    axs[i].legend(fontsize=12)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "out = os.path.join(output, \"plots\", f\"{var_}_{mdl}_{rs}_train_test_validation_distribution.JPG\")\n",
    "plt.savefig(out, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"saved to: \", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterise algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "if mdl == \"RFR\":\n",
    "    from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "\n",
    "    # Define model\n",
    "    model = rfr()\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200, 300],\n",
    "        'max_depth': [None, 2, 3, 4, 5, 10, 20],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "elif mdl == \"GBR\":\n",
    "    from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "\n",
    "    # Define model\n",
    "    model = gbr()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "        'max_depth': [3, 5, 7],\n",
    "    }\n",
    "\n",
    "elif mdl == \"ABR\":\n",
    "    from sklearn.ensemble import AdaBoostRegressor as abr\n",
    "\n",
    "    # Define model\n",
    "    model = abr()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "    }\n",
    "\n",
    "elif mdl == \"XGBR\":\n",
    "    from xgboost import XGBRegressor as xgboost\n",
    "\n",
    "    # Define model\n",
    "    model = xgboost()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    }\n",
    "\n",
    "elif mdl == \"KNN\":\n",
    "    from sklearn.neighbors import KNeighborsRegressor as knn\n",
    "\n",
    "    # Define model\n",
    "    model = knn()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 10, 15],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]  # p=1 is for Manhattan distance, p=2 is for Euclidean distance\n",
    "    }\n",
    "\n",
    "else:\n",
    "    print(\"ERROR__\" * 100)\n",
    "\n",
    "# Define custom scorers for RMSE, MAE, R2\n",
    "def custom_rmse_scorer(y_true, y_pred):\n",
    "    return -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def custom_mae_scorer(y_true, y_pred):\n",
    "    return -mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def custom_r2_scorer(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)\n",
    "\n",
    "r2_scorer = make_scorer(custom_r2_scorer)\n",
    "rmse_scorer = make_scorer(custom_rmse_scorer)\n",
    "mae_scorer = make_scorer(custom_mae_scorer)\n",
    "\n",
    "# Create GridSearchCV objects\n",
    "grid_search_rmse = GridSearchCV(model, param_grid, scoring=rmse_scorer, cv=5)\n",
    "grid_search_rmse.fit(x_train, y_train)\n",
    "\n",
    "# ----------------------------- RMSE ---------------------------------\n",
    "print(mdl)\n",
    "print(\"-\" * 100)\n",
    "print(\"RMSE Best Score: \", grid_search_rmse.best_score_)\n",
    "print(\"RMSE Best Parameters: \", grid_search_rmse.best_params_)\n",
    "\n",
    "grid_search_mae = GridSearchCV(model, param_grid, scoring=mae_scorer, cv=5)\n",
    "grid_search_mae.fit(x_train, y_train)\n",
    "\n",
    "# ----------------------------- MAE ---------------------------------\n",
    "print(\"MAE Best Score: \", grid_search_mae.best_score_)\n",
    "print(\"MAE Best Parameters: \", grid_search_mae.best_params_)\n",
    "\n",
    "grid_search_r2 = GridSearchCV(model, param_grid, scoring=r2_scorer, cv=5)\n",
    "grid_search_r2.fit(x_train, y_train)\n",
    "\n",
    "# ----------------------------- R2 ---------------------------------\n",
    "print(\"R2 Best Score: \", grid_search_r2.best_score_)\n",
    "print(\"R2 Best Parameters: \", grid_search_r2.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best RMSE parameters\n",
    "#best_params = grid_search_rmse.best_params_\n",
    "best_model = grid_search_rmse.best_estimator_\n",
    "fac = \"RMSE\"\n",
    "p_out = rmse_path\n",
    "print(\"RMSE Best Score: \", grid_search_rmse.best_score_)\n",
    "print(\"RMSE Best Parameters: \", grid_search_rmse.best_params_)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:07.134084Z",
     "start_time": "2024-08-02T06:32:07.131083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get best MAE parameters\n",
    "#best_params = grid_search_rmse.best_params_\n",
    "best_model = grid_search_mae.best_estimator_\n",
    "fac = \"MAE\"\n",
    "p_out = mae_path\n",
    "print(\"MAE Best Score: \", grid_search_mae.best_score_)\n",
    "print(\"MAE Best Parameters: \", grid_search_mae.best_params_)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best r2 parameters\n",
    "#best_params = grid_search_r2.best_params_\n",
    "best_model = grid_search_r2.best_estimator_\n",
    "fac = \"r2\"\n",
    "p_out = r2_path\n",
    "print(\"r2 Best Score: \", grid_search_r2.best_score_)\n",
    "print(\"r2Best Parameters: \", grid_search_r2.best_params_)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default\n",
    "best_model = rfr()\n",
    "fac = \"DEF\"\n",
    "p_out = def_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter manualy when required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual \n",
    "#best_model = rfr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit regressor model and compute variable importance score \n",
    "\n",
    "may need to restrict the number of variables for the bar graph to be legible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree_model = best_model.fit(X_1, y_1)\n",
    "best_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### good info on the feature importance score - http://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calculate feature importance for tree-based models\n",
    "def tree_based_feature_importance(model, x_train, cols):\n",
    "    fi = enumerate(model.feature_importances_)\n",
    "    fiResult = [(value, cols[i]) for (i, value) in fi]\n",
    "    return fiResult\n",
    "\n",
    "# Calculate permutation importance\n",
    "def permutation_feature_importance(model, x_train, y_train, cols):\n",
    "    result = permutation_importance(model, x_train, y_train, n_repeats=10, random_state=42)\n",
    "    fiResult = [(importance, cols[i]) for i, importance in enumerate(result.importances_mean)]\n",
    "    return fiResult\n",
    "\n",
    "# Plot feature importance\n",
    "def plot_feature_importance(fiResult, model_name, var_, fac, mdl, output):\n",
    "    df_band = pd.DataFrame(fiResult, columns=['importance', 'feature'])\n",
    "    df_band['importance'] = df_band['importance'].astype(float)\n",
    "    dfsort = df_band.sort_values(['importance'], ascending=[False]).head(20)  # Select top 20 features\n",
    "\n",
    "    ind = np.arange(len(dfsort))\n",
    "    width = 0.4\n",
    "\n",
    "    # Increase figure size\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Bar plot\n",
    "    ax.barh(ind, dfsort['importance'], width, color='blue')\n",
    "\n",
    "    # Adjust y-tick labels\n",
    "    wrapped_labels = [textwrap.fill(label, 20) for label in dfsort['feature']]\n",
    "    ax.set(yticks=ind, yticklabels=wrapped_labels, ylim=[-1, len(dfsort)])\n",
    "    ax.set_xlabel('Importance Score', fontsize=14)\n",
    "    ax.set_ylabel('Features', fontsize=14)\n",
    "    ax.set_title(f'Top 20 Feature Importance ({model_name})', fontsize=14)\n",
    "\n",
    "    # Reverse the order of y-axis to display highest to lowest\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out = os.path.join(output, f\"{var_}_{fac}_{mdl}_Top20_Feature_Importance_Score.JPG\")\n",
    "    plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "    plt.show()\n",
    "    print(out)\n",
    "\n",
    "    return dfsort\n",
    "\n",
    "# Feature importance\n",
    "cols = xdata1.columns\n",
    "\n",
    "if mdl in [\"rfr\", \"abr\", \"gbr\", \"xgboost\"]:\n",
    "    fiResult = tree_based_feature_importance(best_model, x_train, cols)\n",
    "else:\n",
    "    fiResult = permutation_feature_importance(best_model, x_train, y_train, cols)\n",
    "\n",
    "# Plot feature importance\n",
    "dfsort = plot_feature_importance(fiResult, mdl, var_, fac, mdl, p_out)\n",
    "\n",
    "# Generate scatter plot for model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "y_pred = best_model.predict(x_train)\n",
    "\n",
    "r2 = round(best_model.score(x_train, y_train), 2)\n",
    "mse = round(np.mean((y_train - y_pred) ** 2), 2)\n",
    "rmse = round(np.sqrt(mse), 2)\n",
    "mae = round(mean_absolute_error(y_train, y_pred), 2)\n",
    "bias = round(np.mean(y_train) - np.mean(y_pred), 2)\n",
    "\n",
    "plt.scatter(y_pred, y_train, s=70, alpha=0.5, color='blue', edgecolors='w')\n",
    "\n",
    "# Data for the 1 for 1 line\n",
    "x = [-500, 40000]\n",
    "y = [-500, 40000]\n",
    "\n",
    "# Set the limits of the axis\n",
    "plt.xlim(-500, 40000)\n",
    "plt.ylim(-500, 40000)\n",
    "\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Observed Target', fontsize=14)\n",
    "plt.xlabel('Predicted Target', fontsize=14)\n",
    "plt.title(f'Data Used in {mdl} Training', fontsize=16)\n",
    "\n",
    "# Annotate the stats in the top left corner\n",
    "plt.text(0.05, 0.95, f'r2: {r2:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}\\nn: {len(y_train)}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "\n",
    "out = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_train.JPG\")\n",
    "plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()\n",
    "\n",
    "print(\"saved to: \", out)\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\t - r2: {r2}\")\n",
    "print(f\"\\t - mse: {mse}\")\n",
    "print(f\"\\t - rmse: {rmse}\")\n",
    "print(f\"\\t - mae: {mae}\")\n",
    "print(f\"\\t - bias: {bias}\")\n",
    "print(f\"\\t - n: {len(y_train)}\")\n",
    "\n",
    "# Example metrics\n",
    "metrics_dict = {\n",
    "    'r2': r2,\n",
    "    'mse': mse,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'bias': bias,\n",
    "    'n': len(y_train)\n",
    "}\n",
    "\n",
    "# Adding the site as a key-value pair\n",
    "metrics_dict['model'] = mdl\n",
    "metrics_dict['status'] = \"train\"\n",
    "metrics_dict['var'] = var_\n",
    "metrics_dict['fac'] = fac\n",
    "metrics_dict['features'] = list(x_train)\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "train_metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "out_metrics = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_train_metrics.csv\")\n",
    "train_metrics_df.to_csv(out_metrics, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:15.914694Z",
     "start_time": "2024-08-02T06:32:15.652720Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_absolute_error\n",
    "import os\n",
    "\n",
    "# Evaluate and plot for the best model\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use the best estimator from the grid search\n",
    "#best_model = grid_search_r2.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y2_predict = best_model.predict(x_test)\n",
    "\n",
    "# Calculate metrics\n",
    "r2 = round(best_model.score(x_test, y_test), 2)\n",
    "mse = round(np.mean((y_test - y2_predict) ** 2), 2)\n",
    "rmse = round(np.sqrt(mse), 2)\n",
    "mae = round(mean_absolute_error(y_test, y2_predict), 2)\n",
    "bias = round(np.mean(y_test) - np.mean(y2_predict), 2)\n",
    "var = round(explained_variance_score(y_test, y2_predict), 2)\n",
    "\n",
    "# Generate scatter plot\n",
    "plt.scatter(y2_predict, y_test, s=70, alpha=0.5, color='blue', edgecolors='w')\n",
    "\n",
    "# Data for the 1 for 1 line\n",
    "x = [-500, 40000]\n",
    "y = [-500, 40000]\n",
    "\n",
    "# Set limits of the axis\n",
    "plt.xlim(-500, 40000)\n",
    "plt.ylim(-500, 40000)\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Observed Target', fontsize=14)\n",
    "plt.xlabel('Predicted Target', fontsize=14)\n",
    "plt.title(f'Data Used in {mdl} Testing', fontsize=16)\n",
    "\n",
    "# Annotate the stats in the top left corner\n",
    "plt.text(0.05, 0.95, f'r2: {r2:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}\\nn: {len(y_test)}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "\n",
    "# Save the plot\n",
    "out_plot = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_test_data.JPG\")\n",
    "plt.savefig(out_plot, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Plot: \", out_plot)\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\t - r2: {r2}\")\n",
    "print(f\"\\t - mse: {mse}\")\n",
    "print(f\"\\t - rmse: {rmse}\")\n",
    "print(f\"\\t - mae: {mae}\")\n",
    "print(f\"\\t - bias: {bias}\")\n",
    "print(f\"\\t - n: {len(y_test)}\")\n",
    "\n",
    "\n",
    "# Example metrics\n",
    "metrics_dict = {\n",
    "    'r2': r2,\n",
    "    'mse': mse,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'bias': bias,\n",
    "    'n': len(y_test)\n",
    "}\n",
    "\n",
    "# Adding the site as a key-value pair\n",
    "metrics_dict['model'] = mdl\n",
    "metrics_dict['status'] = \"test\"\n",
    "metrics_dict['var'] = var_\n",
    "metrics_dict['fac'] = fac\n",
    "metrics_dict['features'] = list(x_test)\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "test_metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "out_metrics = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_test_metrics.csv\")\n",
    "test_metrics_df.to_csv(out_metrics, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dfsort = dfsort.copy()\n",
    "#dfsort = orig_dfsort\n",
    "#dfsort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:20.554784Z",
     "start_time": "2024-08-02T06:32:20.535778Z"
    }
   },
   "outputs": [],
   "source": [
    "dfsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the selected model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:27.649271Z",
     "start_time": "2024-08-02T06:32:27.634141Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plot has value at the top with very small n value\n",
    "\n",
    "sel_num = 20\n",
    "df_var = dfsort.head(sel_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:28.887837Z",
     "start_time": "2024-08-02T06:32:28.878561Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_var = dfsort[dfsort['n'] > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:29.361212Z",
     "start_time": "2024-08-02T06:32:29.345930Z"
    }
   },
   "outputs": [],
   "source": [
    "df_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:29.471734Z",
     "start_time": "2024-08-02T06:32:29.457735Z"
    }
   },
   "outputs": [],
   "source": [
    "column_var = df_var.feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:29.816964Z",
     "start_time": "2024-08-02T06:32:29.802726Z"
    }
   },
   "outputs": [],
   "source": [
    "#column_var.insert(0, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:30.855285Z",
     "start_time": "2024-08-02T06:32:30.842125Z"
    }
   },
   "outputs": [],
   "source": [
    "column_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:30.870292Z",
     "start_time": "2024-08-02T06:32:30.857284Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:31.196291Z",
     "start_time": "2024-08-02T06:32:31.188286Z"
    }
   },
   "outputs": [],
   "source": [
    "select_df = df_ml[column_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:31.558592Z",
     "start_time": "2024-08-02T06:32:31.545593Z"
    }
   },
   "outputs": [],
   "source": [
    "df_corr = select_df.corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:31.920160Z",
     "start_time": "2024-08-02T06:32:31.906154Z"
    }
   },
   "outputs": [],
   "source": [
    "dfsort.to_csv(os.path.join(p_out, \"{0}_{1}_{2}_sel_{3}_variable_score.csv\".format(var_, fac, mdl, sel_num)))\n",
    "df_corr.to_csv(os.path.join(p_out, \"{0}_{1}_{2}_sel_{3}_variable_correlation.csv\".format(var_, fac, mdl, sel_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:34.239741Z",
     "start_time": "2024-08-02T06:32:32.873243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(df_corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Save the plot\n",
    "plot_out = os.path.join(p_out, \"{0}_{1}_{2}_sel_{3}_variable_score.JPG\".format(var_, fac, mdl, sel_num))\n",
    "plt.savefig(plot_out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()\n",
    "print(\"Plot: \", plot_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:35.087206Z",
     "start_time": "2024-08-02T06:32:35.068205Z"
    }
   },
   "outputs": [],
   "source": [
    "select_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rerun on Selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:35.577680Z",
     "start_time": "2024-08-02T06:32:35.561494Z"
    }
   },
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test, x_validation, y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:36.017364Z",
     "start_time": "2024-08-02T06:32:36.002353Z"
    }
   },
   "outputs": [],
   "source": [
    "sel_x_train = x_train[column_var]\n",
    "sel_x_test = x_test[column_var]\n",
    "sel_x_validation = x_validation[column_var]\n",
    "sel_y_train = y_train\n",
    "sel_y_test = y_test\n",
    "sel_y_validation = y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set model with feature names for Notebook testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:40.190913Z",
     "start_time": "2024-08-02T06:32:40.174913Z"
    }
   },
   "outputs": [],
   "source": [
    "select_model = best_model.fit(sel_x_train, sel_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train model on selected paramiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "# Calculate feature importance for tree-based models\n",
    "def tree_based_feature_importance(model, x_train, cols):\n",
    "    fi = enumerate(model.feature_importances_)\n",
    "    fiResult = [(value, cols[i]) for (i, value) in fi]\n",
    "    return fiResult\n",
    "\n",
    "# Calculate permutation importance\n",
    "def permutation_feature_importance(model, x_train, y_train, cols):\n",
    "    result = permutation_importance(model, x_train, y_train, n_repeats=10, random_state=42)\n",
    "    fiResult = [(importance, cols[i]) for i, importance in enumerate(result.importances_mean)]\n",
    "    return fiResult\n",
    "\n",
    "# Plot feature importance\n",
    "def plot_feature_importance(fiResult, model_name, var_, fac, mdl, output):\n",
    "    df_band = pd.DataFrame(fiResult, columns=['importance', 'feature'])\n",
    "    df_band['importance'] = df_band['importance'].astype(float)\n",
    "    dfsort = df_band.sort_values(['importance'], ascending=[False]).head(20)  # Select top 20 features\n",
    "\n",
    "    ind = np.arange(len(dfsort))\n",
    "    width = 0.4\n",
    "\n",
    "    # Increase figure size\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Bar plot\n",
    "    ax.barh(ind, dfsort['importance'], width, color='blue')\n",
    "\n",
    "    # Adjust y-tick labels\n",
    "    wrapped_labels = [textwrap.fill(label, 16) for label in dfsort['feature']]\n",
    "    ax.set(yticks=ind, yticklabels=wrapped_labels, ylim=[-1, len(dfsort)])\n",
    "    ax.set_xlabel('Importance Score', fontsize=12)\n",
    "    ax.set_ylabel('Features', fontsize=12)\n",
    "    ax.set_title(f'Top {sel_num} Feature Importance ({mdl})', fontsize=14)\n",
    "\n",
    "    # Reverse the order of y-axis to display highest to lowest\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out = os.path.join(p_out, f\"{var_}_{fac}_{mdl}_Top_{sel_num}_Feature_Importance_Score.JPG\")\n",
    "    plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "    plt.show()\n",
    "    print(out)\n",
    "\n",
    "    return dfsort\n",
    "\n",
    "# Feature importance\n",
    "cols = xdata1.columns\n",
    "\n",
    "if isinstance(select_model, (rfr, abr, gbr)):\n",
    "    fiResult = tree_based_feature_importance(select_model, sel_x_train, cols)\n",
    "else:\n",
    "    fiResult = permutation_feature_importance(select_model, sel_x_train, sel_y_train, cols)\n",
    "\n",
    "# Plot feature importance\n",
    "dfsort = plot_feature_importance(fiResult, mdl, var_, fac, mdl, p_out)\n",
    "\n",
    "# Generate scatter plot for model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sel_y_pred = select_model.predict(sel_x_train)\n",
    "\n",
    "r2 = round(select_model.score(sel_x_train, sel_y_train), 2)\n",
    "mse = round(np.mean((sel_y_train - sel_y_pred) ** 2), 2)\n",
    "rmse = round(np.sqrt(mse), 2)\n",
    "mae = round(mean_absolute_error(sel_y_train, sel_y_pred), 2)\n",
    "bias = round(np.mean(sel_y_train) - np.mean(sel_y_pred), 2)\n",
    "\n",
    "plt.scatter(sel_y_pred, sel_y_train, s=70, alpha=0.5, color='blue', edgecolors='w')\n",
    "\n",
    "# Data for the 1 for 1 line\n",
    "x = [-500, 40000]\n",
    "y = [-500, 40000]\n",
    "\n",
    "# Set the limits of the axis\n",
    "plt.xlim(-500, 40000)\n",
    "plt.ylim(-500, 40000)\n",
    "\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Observed Target', fontsize=14)\n",
    "plt.xlabel('Predicted Target', fontsize=14)\n",
    "plt.title(f'Data Used in {mdl} Training', fontsize=16)\n",
    "\n",
    "# Annotate the stats in the top left corner\n",
    "plt.text(0.05, 0.95, f'r2: {r2:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}\\nn: {len(sel_y_train)}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "\n",
    "out = os.path.join(output, f\"{var_}_{mdl}_{fac}_top_{sel_num}_retrain.JPG\")\n",
    "plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()\n",
    "\n",
    "print(\"saved to: \", out)\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\t - r2: {r2}\")\n",
    "print(f\"\\t - mse: {mse}\")\n",
    "print(f\"\\t - rmse: {rmse}\")\n",
    "print(f\"\\t - mae: {mae}\")\n",
    "print(f\"\\t - bias: {bias}\")\n",
    "print(f\"\\t - n: {len(sel_y_train)}\")\n",
    "\n",
    "\n",
    "# Example metrics\n",
    "metrics_dict = {\n",
    "    'r2': r2,\n",
    "    'mse': mse,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'bias': bias,\n",
    "    'n': len(sel_y_train)\n",
    "}\n",
    "\n",
    "# Adding the site as a key-value pair\n",
    "metrics_dict['model'] = mdl\n",
    "metrics_dict['status'] = \"retrain\"\n",
    "metrics_dict['var'] = var_\n",
    "metrics_dict['fac'] = fac\n",
    "metrics_dict['sel_num'] = sel_num\n",
    "metrics_dict['features'] = list(sel_x_train)\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "retrain_metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "out_metrics = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_top_{sel_num}_retrain_metrics.csv\")\n",
    "retrain_metrics_df.to_csv(out_metrics, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "y2_predict = select_model.predict(sel_x_test)\n",
    "\n",
    "r2 = round(select_model.score(sel_x_test, sel_y_test), 2)\n",
    "mse = round(np.mean((sel_y_test - select_model.predict(sel_x_test)) ** 2), 2)\n",
    "rmse = round(np.sqrt(np.mean((y2_predict - sel_y_test) ** 2)), 2)\n",
    "mae = round(mean_absolute_error(sel_y_test, y2_predict), 2)\n",
    "bias = round(np.mean(sel_y_test) - np.mean(y2_predict), 2)\n",
    "var = round(explained_variance_score(sel_y_test, y2_predict), 2)\n",
    "\n",
    "plt.scatter(y2_predict, sel_y_test, s=70, alpha=0.5, color='blue', edgecolors='w')\n",
    "\n",
    "# Data for the 1 for 1 line\n",
    "x = [-500, 40000]\n",
    "y = [-500, 40000]\n",
    "\n",
    "# Set the limits of the axis\n",
    "plt.xlim(-500, 40000)\n",
    "plt.ylim(-500, 40000)\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Observed Target', fontsize=14)\n",
    "plt.xlabel('Predicted Target', fontsize=14)\n",
    "plt.title(f'Data Used in {mdl} Testing', fontsize=16)\n",
    "\n",
    "# Annotate the stats in the top left corner\n",
    "plt.text(0.05, 0.95, f'r2: {r2:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}\\nn: {len(sel_y_test)}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(output, f\"{var_}_{mdl}_{fac}_top_{sel_num}_retest.JPG\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\t - r2: {r2}\")\n",
    "print(f\"\\t - mse: {mse}\")\n",
    "print(f\"\\t - rmse: {rmse}\")\n",
    "print(f\"\\t - mae: {mae}\")\n",
    "print(f\"\\t - bias: {bias}\")\n",
    "print(f\"\\t - n: {len(sel_y_test)}\")\n",
    "\n",
    "\n",
    "# Example metrics\n",
    "metrics_dict = {\n",
    "    'r2': r2,\n",
    "    'mse': mse,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'bias': bias,\n",
    "    'n': len(y_test)\n",
    "}\n",
    "\n",
    "# Adding the site as a key-value pair\n",
    "metrics_dict['model'] = mdl\n",
    "metrics_dict['status'] = \"retest\"\n",
    "metrics_dict['var'] = var_\n",
    "metrics_dict['fac'] = fac\n",
    "metrics_dict['sel_num'] = sel_num\n",
    "metrics_dict['features'] = list(sel_x_test)\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "retest_metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "out_metrics = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_top_{sel_num}_metrics_retest.csv\")\n",
    "retest_metrics_df.to_csv(out_metrics, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:46.247317Z",
     "start_time": "2024-08-02T06:32:46.237282Z"
    }
   },
   "outputs": [],
   "source": [
    "variable_imp_list = dfsort.feature.to_list()\n",
    "print(variable_imp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP - do you realy want to save this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remember to change the cPickle file name !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save current fitted model and apply to validation validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:49.624082Z",
     "start_time": "2024-08-02T06:32:49.610089Z"
    }
   },
   "outputs": [],
   "source": [
    "select_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:50.489118Z",
     "start_time": "2024-08-02T06:32:50.480442Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#rfrL8CHM = rfr()\n",
    "#rfrL8CHM.fit(sel_x_train, sel_y_train)\n",
    "pickle_file = os.path.join(output, \"{0}_{1}_{2}_sel_{3}_{4}_model.pickle\".format(var_, fac, mdl, sel_num, samp))\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(select_model, f)\n",
    "print(\"pickle saved: \", pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:50.783746Z",
     "start_time": "2024-08-02T06:32:50.754322Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in your validation dataset which has never been seen by rfr model - NOTE in this example I am just reading the same data used to train the model\n",
    "sel_y_validation\n",
    "sel_x_validation\n",
    "#validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:51.702820Z",
     "start_time": "2024-08-02T06:32:51.696526Z"
    }
   },
   "outputs": [],
   "source": [
    "c_list = sel_x_validation.columns.tolist()\n",
    "c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:52.333071Z",
     "start_time": "2024-08-02T06:32:52.318071Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_df = sel_x_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:52.349108Z",
     "start_time": "2024-08-02T06:32:52.336073Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert array as the first column\n",
    "validation_df.insert(0, 'target', sel_y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:52.723878Z",
     "start_time": "2024-08-02T06:32:52.708948Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_out = os.path.join(output, \"validation_data.csv\")\n",
    "validation_df.to_csv(validation_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:52.867433Z",
     "start_time": "2024-08-02T06:32:52.852423Z"
    }
   },
   "outputs": [],
   "source": [
    "#select_validation_df = validation_df[column_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:53.780669Z",
     "start_time": "2024-08-02T06:32:53.762664Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:54.030318Z",
     "start_time": "2024-08-02T06:32:54.019316Z"
    }
   },
   "outputs": [],
   "source": [
    "column_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:54.441449Z",
     "start_time": "2024-08-02T06:32:54.430949Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_xdata = validation_df.iloc[:, 1:].astype('float32')\n",
    "ydata1 = validation_df[[value_x]].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata3 = ydata2.ravel()\n",
    "\n",
    "validation_ydata = ydata3.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:54.848131Z",
     "start_time": "2024-08-02T06:32:54.834802Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:55.182119Z",
     "start_time": "2024-08-02T06:32:55.167121Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Load the model\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    rf = pickle.load(f)\n",
    "\n",
    "predicted = rf.predict(validation_xdata)\n",
    "\n",
    "# Calculate metrics\n",
    "r2 = round(rf.score(validation_xdata, validation_ydata), 2)\n",
    "mse = round(np.mean((validation_ydata - predicted) ** 2), 2)\n",
    "rmse = round(np.sqrt(np.mean((predicted - validation_ydata) ** 2)), 2)\n",
    "mae = round(mean_absolute_error(validation_ydata, predicted), 2)\n",
    "bias = round(np.mean(validation_ydata) - np.mean(predicted), 2)\n",
    "var = round(explained_variance_score(validation_ydata, predicted), 2)\n",
    "\n",
    "# Plot predicted vs observed data\n",
    "plt.scatter(predicted, validation_ydata, s=70, alpha=0.5, color='blue', edgecolors='w')\n",
    "\n",
    "# Data for the 1-for-1 line\n",
    "x = [-500, 40000]\n",
    "y = [-500, 40000]\n",
    "\n",
    "# Set the limits of the axis\n",
    "plt.xlim(-500, 40000)\n",
    "plt.ylim(-500, 40000)\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Observed Target', fontsize=14)\n",
    "plt.xlabel('Predicted Target', fontsize=14)\n",
    "plt.title(f'Data Used in {mdl} Validation', fontsize=16)\n",
    "\n",
    "# Annotate the stats in the top left corner\n",
    "plt.text(0.05, 0.95, f'r2: {r2:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}\\nn: {len(validation_ydata)}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "\n",
    "# 1-for-1 line\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# Save the plot\n",
    "output_plot = os.path.join(output, \"{0}_{1}_{2}_sel_{3}_data_validation.JPG\".format(var_, fac, mdl, str(sel_num)))\n",
    "plt.savefig(output_plot, dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"plot output: \", output_plot)\n",
    "print(\"Using: \", \"{0}_{1}_{2}_sel_{3}_model.pickle\".format(var_, fac, mdl, sel_num))\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\t - r2: {r2}\")\n",
    "print(f\"\\t - mse: {mse}\")\n",
    "print(f\"\\t - rmse: {rmse}\")\n",
    "print(f\"\\t - mae: {mae}\")\n",
    "print(f\"\\t - bias: {bias}\")\n",
    "print(f\"\\t - n: {len(validation_ydata)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Adding the site as a key-value pair\n",
    "metrics_dict['model'] = mdl\n",
    "metrics_dict['status'] = \"validate\"\n",
    "metrics_dict['var'] = var_\n",
    "metrics_dict['fac'] = fac\n",
    "metrics_dict['sel_num'] = sel_num\n",
    "metrics_dict['features'] = list(validation_df)\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "val_metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "\n",
    "out_metrics = os.path.join(output, f\"{var_}_{mdl}_{fac}_top_{sel_num}_validate_metrics.csv\")\n",
    "val_metrics_df.to_csv(out_metrics, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:56.287966Z",
     "start_time": "2024-08-02T06:32:56.273918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the pickled model\n",
    "import pickle\n",
    "\n",
    "with open(pickle_file, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "# validation x data\n",
    "data = validation_xdata\n",
    "\n",
    "# Check the feature names used during training\n",
    "training_feature_names = model.feature_names_in_\n",
    "\n",
    "# Check the feature names in the new dataset\n",
    "new_feature_names = data.columns\n",
    "\n",
    "print(\"Training feature names:\", training_feature_names)\n",
    "print(\"New feature names:\", new_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:56.732934Z",
     "start_time": "2024-08-02T06:32:56.727934Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust to export model with no feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:56.902421Z",
     "start_time": "2024-08-02T06:32:56.882935Z"
    }
   },
   "outputs": [],
   "source": [
    "xarray = sel_x_train.to_numpy()\n",
    "yarray = sel_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:57.400147Z",
     "start_time": "2024-08-02T06:32:57.386587Z"
    }
   },
   "outputs": [],
   "source": [
    "select_tree_model_no_headers = best_model.fit(xarray, yarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export selected model as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:58.157028Z",
     "start_time": "2024-08-02T06:32:58.144029Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#rfrL8CHM = rfr()\n",
    "#rfrL8CHM.fit(sel_x_train, sel_y_train)\n",
    "pickle_file_no_headers = os.path.join(output, \"{0}_{1}_{2}_sel_{3}_{4}_model_no_headers.pickle\".format(var_, fac, mdl, sel_num, samp))\n",
    "with open(pickle_file_no_headers, 'wb') as f:\n",
    "    pickle.dump(select_tree_model_no_headers, f)\n",
    "print(\"pickle saved: \", pickle_file_no_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:59.114459Z",
     "start_time": "2024-08-02T06:32:59.098458Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
