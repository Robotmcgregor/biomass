{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBR_all_data_w_met_sddv3_h99_add_knn_xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following conditions apply:\n",
    "\n",
    " - env = biomass_zonal\n",
    " - data merged_slats_field_agb_dp1_start.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:51.496948Z",
     "start_time": "2024-08-02T06:26:51.069690Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "from sklearn.ensemble import ExtraTreesRegressor as etr\n",
    "from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "from sklearn.ensemble import AdaBoostRegressor as abr\n",
    "from sklearn.tree import DecisionTreeRegressor as dtr\n",
    "from sklearn.neighbors import KNeighborsRegressor as knn\n",
    "from xgboost import XGBRegressor as xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as sc\n",
    "import textwrap\n",
    "\n",
    "# stats module\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "%matplotlib inline\n",
    "\n",
    "# import plotting and stats modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import scipy\n",
    "import pandas as pd\n",
    "\n",
    "# Set option to display floating-point numbers without scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "from bokeh.io import output_notebook, output_file\n",
    "from bokeh.plotting import save # figure, show, \n",
    "#%matplotlib inline\n",
    "\n",
    "# Bokeh Libraries\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_file\n",
    "from bokeh.models import ColumnDataSource, NumeralTickFormatter, HoverTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.591384Z",
     "start_time": "2024-08-02T06:26:52.578377Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# mdl = \"RFR\"\n",
    "# model_name = \"Random Forrest Regressor\"\n",
    "\n",
    "\n",
    "#mdl = \"ABR\"\n",
    "#model_name = \"AdaBoost Regressor\"\n",
    "\n",
    "mdl = \"GBR\"\n",
    "model_name = \"Gradient Boosting Regressor\"\n",
    "\n",
    "# mdl = \"KNN\"\n",
    "# model_name = \"K-Nearest Neighbors Regressor\"\n",
    "\n",
    "# mdl = \"XGBR\"\n",
    "# model_name = \"XGBoost Regressor\"\n",
    "\n",
    "\n",
    "rs = 0\n",
    "drive = \"D\"\n",
    "data_comp = f\"{mdl}_dp1_dbi_si_dry_mask_density_sddv3_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.654412Z",
     "start_time": "2024-08-02T06:26:52.640411Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_file = r\"C:\\Users\\robot\\projects\\biomass\\collated_zonal_stats\\dry_mask\\dp1_dbi_si_dry_mask_density_near_met_fire.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set output file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.734412Z",
     "start_time": "2024-08-02T06:26:52.722411Z"
    }
   },
   "outputs": [],
   "source": [
    "output = r\"C:\\Users\\robot\\projects\\biomass\\model\\{}\".format(data_comp)\n",
    "output_ = os.path.join(output, \"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.766412Z",
     "start_time": "2024-08-02T06:26:52.752411Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(output):\n",
    "    os.mkdir(output)\n",
    "if not os.path.isdir(output_):\n",
    "    os.mkdir(output_)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_path = os.path.join(output_, \"DEF\")    \n",
    "if not os.path.isdir(def_path):\n",
    "    os.mkdir(def_path)\n",
    "    \n",
    "r2_path = os.path.join(output_, \"R2\")    \n",
    "if not os.path.isdir(r2_path):\n",
    "    os.mkdir(r2_path)\n",
    "    \n",
    "mae_path = os.path.join(output_, \"MAE\")    \n",
    "if not os.path.isdir(mae_path):\n",
    "    os.mkdir(mae_path)\n",
    "    \n",
    "rmse_path = os.path.join(output_, \"RMSE\")    \n",
    "if not os.path.isdir(rmse_path):\n",
    "    os.mkdir(rmse_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.860731Z",
     "start_time": "2024-08-02T06:26:52.833411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 380)\n",
      "['uid', 'site_clean', 'date', 'lon_gda94', 'lat_gda94', 'bio_l_kg1ha', 'bio_t_kg1ha', 'bio_b_kg1ha', 'bio_w_kg1ha', 'bio_br_kg1ha', 'bio_s_kg1ha', 'bio_r_kg1ha', 'bio_agb_kg1ha', 'c_l_kg1ha', 'c_t_kg1ha', 'c_b_kg1ha', 'c_w_kg1ha', 'c_br_kg1ha', 'c_s_kg1ha', 'c_r_kg1ha', 'c_agb_kg1ha', 'mean_f_afsm', 'min_f_afsm', 'max_f_afsm', 'mean_f_apos', 'min_f_apos', 'max_f_apos', 'mean_f_ario', 'min_f_ario', 'max_f_ario', 'mean_f_dfsm', 'min_f_dfsm', 'max_f_dfsm', 'mean_f_dpos', 'min_f_dpos', 'max_f_dpos', 'mean_f_drio', 'min_f_drio', 'max_f_drio', 'mean_f_lfsm', 'min_f_lfsm', 'max_f_lfsm', 'mean_f_lpos', 'min_f_lpos', 'max_f_lpos', 'mean_f_lrio', 'min_f_lrio', 'max_f_lrio', 'dr_asav', 'dr_asmd', 'dr_aavg', 'dr_amed', 'dr_asiv', 'dr_asid', 'dr_asum', 'dr_corr', 'dr_dsav', 'dr_dsmd', 'dr_davg', 'dr_dmed', 'dr_dsiv', 'dr_dsid', 'dr_dsum', 'dr_mavg', 'dr_mmed', 'dr_msum', 'dr_wsav', 'dr_wsmd', 'dr_wavg', 'dr_wmed', 'dr_wsiv', 'dr_wsid', 'dr_wsum', 'ma_asav', 'ma_asmd', 'ma_aavg', 'ma_amed', 'ma_asiv', 'ma_asid', 'ma_asum', 'ma_corr', 'ma_dsav', 'ma_dsmd', 'ma_davg', 'ma_dmed', 'ma_dsiv', 'ma_dsid', 'ma_dsum', 'ma_mavg', 'ma_mmed', 'ma_msum', 'ma_wsav', 'ma_wsmd', 'ma_wavg', 'ma_wmed', 'ma_wsiv', 'ma_wsid', 'ma_wsum', 'tx_asav', 'tx_asmd', 'tx_aavg', 'tx_amed', 'tx_asiv', 'tx_asid', 'tx_asum', 'tx_corr', 'tx_dsav', 'tx_dsmd', 'tx_davg', 'tx_dmed', 'tx_dsiv', 'tx_dsid', 'tx_dsum', 'tx_mavg', 'tx_mmed', 'tx_msum', 'tx_wsav', 'tx_wsmd', 'tx_wavg', 'tx_wmed', 'tx_wsiv', 'tx_wsid', 'tx_wsum', 'tn_asav', 'tn_asmd', 'tn_aavg', 'tn_amed', 'tn_asiv', 'tn_asid', 'tn_asum', 'tn_corr', 'tn_dsav', 'tn_dsmd', 'tn_davg', 'tn_dmed', 'tn_dsiv', 'tn_dsid', 'tn_dsum', 'tn_mavg', 'tn_mmed', 'tn_msum', 'tn_wsav', 'tn_wsmd', 'tn_wavg', 'tn_wmed', 'tn_wsiv', 'tn_wsid', 'tn_wsum', 'rx_asav', 'rx_asmd', 'rx_aavg', 'rx_amed', 'rx_asiv', 'rx_asid', 'rx_asum', 'rx_corr', 'rx_dsav', 'rx_dsmd', 'rx_davg', 'rx_dmed', 'rx_dsiv', 'rx_dsid', 'rx_dsum', 'rx_mavg', 'rx_mmed', 'rx_msum', 'rx_wsav', 'rx_wsmd', 'rx_wavg', 'rx_wmed', 'rx_wsiv', 'rx_wsid', 'rx_wsum', 'rn_asav', 'rn_asmd', 'rn_aavg', 'rn_amed', 'rn_asiv', 'rn_asid', 'rn_asum', 'rn_corr', 'rn_dsav', 'rn_dsmd', 'rn_davg', 'rn_dmed', 'rn_dsiv', 'rn_dsid', 'rn_dsum', 'rn_mavg', 'rn_mmed', 'rn_msum', 'rn_wsav', 'rn_wsmd', 'rn_wavg', 'rn_wmed', 'rn_wsiv', 'rn_wsid', 'rn_wsum', 'b1_wfp_dry_min', 'b1_wfp_dry_max', 'b1_wfp_dry_mean', 'b1_wfp_dry_std', 'b1_wfp_dry_med', 'b1_wfp_dry_p25', 'b1_wfp_dry_p50', 'b1_wfp_dry_p75', 'b1_wfp_dry_p95', 'b1_wfp_dry_p99', 'b1_wdc_dry_major', 'b1_wdc_dry_minor', 'b1_n17_dry_major', 'b1_n17_dry_minor', 'b1_hsd_min', 'b1_hsd_max', 'b1_hsd_mean', 'b1_hsd_std', 'b1_hsd_med', 'b1_hsd_p25', 'b1_hsd_p50', 'b1_hsd_p75', 'b1_hsd_p95', 'b1_hsd_p99', 'b1_hmc_min', 'b1_hmc_max', 'b1_hmc_mean', 'b1_hmc_std', 'b1_hmc_med', 'b1_hmc_p25', 'b1_hmc_p50', 'b1_hmc_p75', 'b1_hmc_p95', 'b1_hmc_p99', 'b1_hcv_min', 'b1_hcv_max', 'b1_hcv_mean', 'b1_hcv_std', 'b1_hcv_med', 'b1_hcv_p25', 'b1_hcv_p50', 'b1_hcv_p75', 'b1_hcv_p95', 'b1_hcv_p99', 'b1_h99_min', 'b1_h99_max', 'b1_h99_mean', 'b1_h99_std', 'b1_h99_med', 'b1_h99_p25', 'b1_h99_p50', 'b1_h99_p75', 'b1_h99_p95', 'b1_h99_p99', 'b1_fdc_dry_major', 'b1_fdc_dry_minor', 'b1_ccw_dry_min', 'b1_ccw_dry_max', 'b1_ccw_dry_mean', 'b1_ccw_dry_std', 'b1_ccw_dry_med', 'b1_ccw_dry_p25', 'b1_ccw_dry_p50', 'b1_ccw_dry_p75', 'b1_ccw_dry_p95', 'b1_ccw_dry_p99', 'b1_dp1fm_dry_min', 'b1_dp1fm_dry_max', 'b1_dp1fm_dry_mean', 'b1_dp1fm_dry_std', 'b1_dp1fm_dry_med', 'b1_dp1fm_dry_p25', 'b1_dp1fm_dry_p50', 'b1_dp1fm_dry_p75', 'b1_dp1fm_dry_p95', 'b1_dp1fm_dry_p99', 'b2_dp1fm_dry_min', 'b2_dp1fm_dry_max', 'b2_dp1fm_dry_mean', 'b2_dp1fm_dry_std', 'b2_dp1fm_dry_med', 'b2_dp1fm_dry_p25', 'b2_dp1fm_dry_p50', 'b2_dp1fm_dry_p75', 'b2_dp1fm_dry_p95', 'b2_dp1fm_dry_p99', 'b3_dp1fm_dry_min', 'b3_dp1fm_dry_max', 'b3_dp1fm_dry_mean', 'b3_dp1fm_dry_std', 'b3_dp1fm_dry_med', 'b3_dp1fm_dry_p25', 'b3_dp1fm_dry_p50', 'b3_dp1fm_dry_p75', 'b3_dp1fm_dry_p95', 'b3_dp1fm_dry_p99', 'b1_dbifm_dry_std', 'b1_dbifm_dry_med', 'b1_dbifm_dry_p25', 'b1_dbifm_dry_p50', 'b1_dbifm_dry_p75', 'b1_dbifm_dry_p95', 'b1_dbifm_dry_p99', 'b2_dbifm_dry_min', 'b2_dbifm_dry_max', 'b2_dbifm_dry_mean', 'b2_dbifm_dry_std', 'b2_dbifm_dry_med', 'b2_dbifm_dry_p25', 'b2_dbifm_dry_p50', 'b2_dbifm_dry_p75', 'b2_dbifm_dry_p95', 'b2_dbifm_dry_p99', 'b3_dbifm_dry_min', 'b3_dbifm_dry_max', 'b3_dbifm_dry_mean', 'b3_dbifm_dry_std', 'b3_dbifm_dry_med', 'b3_dbifm_dry_p25', 'b3_dbifm_dry_p50', 'b3_dbifm_dry_p75', 'b3_dbifm_dry_p95', 'b3_dbifm_dry_p99', 'b4_dbifm_dry_min', 'b4_dbifm_dry_max', 'b4_dbifm_dry_mean', 'b4_dbifm_dry_std', 'b4_dbifm_dry_med', 'b4_dbifm_dry_p25', 'b4_dbifm_dry_p50', 'b4_dbifm_dry_p75', 'b4_dbifm_dry_p95', 'b4_dbifm_dry_p99', 'b5_dbifm_dry_min', 'b5_dbifm_dry_max', 'b5_dbifm_dry_mean', 'b5_dbifm_dry_std', 'b5_dbifm_dry_med', 'b5_dbifm_dry_p25', 'b5_dbifm_dry_p50', 'b5_dbifm_dry_p75', 'b5_dbifm_dry_p95', 'b5_dbifm_dry_p99', 'b6_dbifm_dry_min', 'b6_dbifm_dry_max', 'b6_dbifm_dry_mean', 'b6_dbifm_dry_std', 'b6_dbifm_dry_med', 'b6_dbifm_dry_p25', 'b6_dbifm_dry_p50', 'b6_dbifm_dry_p75', 'b6_dbifm_dry_p95', 'b6_dbifm_dry_p99', 'dbifmdry_psB1a', 'dbifmdry_psB2a', 'dbifmdry_psB3a', 'dbifmdry_psB4a', 'dbifmdry_psB5a', 'dbifmdry_psB6a', 'dbifmdry_r32', 'dbifmdry_r42', 'dbifmdry_r43', 'dbifmdry_r52', 'dbifmdry_r53', 'dbifmdry_r54', 'dbifmdry_r62', 'dbifmdry_r63', 'dbifmdry_r64', 'dbifmdry_r65', 'dbifmdry_GSAVI', 'dbifmdry_GNDVI', 'dbifmdry_CVI', 'dbifmdry_NDGI', 'dbifmdry_RI', 'dbifmdry_NBR', 'dbifmdry_NDII', 'dbifmdry_GDVI', 'dbifmdry_MSAVI', 'dbifmdry_DVI', 'dbifmdry_SAVI', 'dbifmdry_NDVI', 'dbifmdry_MSR']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200, 380)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read as dataframe and copy\n",
    "df1 = pd.read_csv(csv_file, header=0) # the first row is read in as the header for you columns\n",
    "print(df1.shape) # prints out the number of rows and columns in your csv file \n",
    "print(list(df1))\n",
    "df1.shape\n",
    "#df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.876721Z",
     "start_time": "2024-08-02T06:26:52.867732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dr_corr', 'ma_corr', 'tx_corr', 'tn_corr', 'rx_corr', 'rn_corr',\n",
       "       'b1_wfp_dry_min', 'b1_wfp_dry_max', 'b1_wfp_dry_mean', 'b1_wfp_dry_std',\n",
       "       'b1_wfp_dry_med', 'b1_wfp_dry_p25', 'b1_wfp_dry_p50', 'b1_wfp_dry_p75',\n",
       "       'b1_wfp_dry_p95', 'b1_wfp_dry_p99', 'b1_wdc_dry_major',\n",
       "       'b1_wdc_dry_minor', 'b1_ccw_dry_min', 'b1_ccw_dry_max',\n",
       "       'b1_ccw_dry_mean', 'b1_ccw_dry_std', 'b1_ccw_dry_med', 'b1_ccw_dry_p25',\n",
       "       'b1_ccw_dry_p50', 'b1_ccw_dry_p75', 'b1_ccw_dry_p95', 'b1_ccw_dry_p99',\n",
       "       'b1_dp1fm_dry_min', 'b2_dp1fm_dry_min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values in each column\n",
    "columns_with_nulls = df1.columns[df1.isnull().any()]\n",
    "columns_with_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:52.970722Z",
     "start_time": "2024-08-02T06:26:52.938723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill missing values with the minimum value of each column\n",
    "df1 = df1.apply(lambda col: col.fillna(col.min()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.002722Z",
     "start_time": "2024-08-02T06:26:52.987723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values in each column\n",
    "columns_with_nulls = df1.columns[df1.isnull().any()]\n",
    "columns_with_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.082722Z",
     "start_time": "2024-08-02T06:26:53.066722Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df1.rename(columns={'bio_agb_kg1ha': 'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.190722Z",
     "start_time": "2024-08-02T06:26:53.168723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>site_clean</th>\n",
       "      <th>date</th>\n",
       "      <th>lon_gda94</th>\n",
       "      <th>lat_gda94</th>\n",
       "      <th>bio_l_kg1ha</th>\n",
       "      <th>bio_t_kg1ha</th>\n",
       "      <th>bio_b_kg1ha</th>\n",
       "      <th>bio_w_kg1ha</th>\n",
       "      <th>bio_br_kg1ha</th>\n",
       "      <th>...</th>\n",
       "      <th>dbifmdry_NDGI</th>\n",
       "      <th>dbifmdry_RI</th>\n",
       "      <th>dbifmdry_NBR</th>\n",
       "      <th>dbifmdry_NDII</th>\n",
       "      <th>dbifmdry_GDVI</th>\n",
       "      <th>dbifmdry_MSAVI</th>\n",
       "      <th>dbifmdry_DVI</th>\n",
       "      <th>dbifmdry_SAVI</th>\n",
       "      <th>dbifmdry_NDVI</th>\n",
       "      <th>dbifmdry_MSR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82</td>\n",
       "      <td>nt001</td>\n",
       "      <td>20110523</td>\n",
       "      <td>131.21</td>\n",
       "      <td>-13.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-963139</td>\n",
       "      <td>963139</td>\n",
       "      <td>2033821</td>\n",
       "      <td>-266174</td>\n",
       "      <td>1873000</td>\n",
       "      <td>2729666</td>\n",
       "      <td>1711000</td>\n",
       "      <td>3000000</td>\n",
       "      <td>4812940</td>\n",
       "      <td>6898960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>barkely01</td>\n",
       "      <td>20111025</td>\n",
       "      <td>135.04</td>\n",
       "      <td>-18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2091201</td>\n",
       "      <td>2091201</td>\n",
       "      <td>1916078</td>\n",
       "      <td>-665772</td>\n",
       "      <td>1673000</td>\n",
       "      <td>1549615</td>\n",
       "      <td>1086000</td>\n",
       "      <td>1718354</td>\n",
       "      <td>2424107</td>\n",
       "      <td>2806064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>barkely02</td>\n",
       "      <td>20111026</td>\n",
       "      <td>135.26</td>\n",
       "      <td>-18.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2041078</td>\n",
       "      <td>2041078</td>\n",
       "      <td>3188841</td>\n",
       "      <td>399323</td>\n",
       "      <td>2143000</td>\n",
       "      <td>2429125</td>\n",
       "      <td>1666000</td>\n",
       "      <td>2636076</td>\n",
       "      <td>3718750</td>\n",
       "      <td>4778632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>barkely04</td>\n",
       "      <td>20111026</td>\n",
       "      <td>135.23</td>\n",
       "      <td>-17.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2256318</td>\n",
       "      <td>2256318</td>\n",
       "      <td>2646032</td>\n",
       "      <td>-303355</td>\n",
       "      <td>1859000</td>\n",
       "      <td>2027352</td>\n",
       "      <td>1359000</td>\n",
       "      <td>2246281</td>\n",
       "      <td>3334969</td>\n",
       "      <td>4144739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>barkely03</td>\n",
       "      <td>20111026</td>\n",
       "      <td>135.29</td>\n",
       "      <td>-18.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1703353</td>\n",
       "      <td>1703353</td>\n",
       "      <td>2254432</td>\n",
       "      <td>-530218</td>\n",
       "      <td>1713000</td>\n",
       "      <td>1708085</td>\n",
       "      <td>1210000</td>\n",
       "      <td>1877716</td>\n",
       "      <td>2593228</td>\n",
       "      <td>3039292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>58</td>\n",
       "      <td>jnk102</td>\n",
       "      <td>20240526</td>\n",
       "      <td>130.99</td>\n",
       "      <td>-12.60</td>\n",
       "      <td>404.07</td>\n",
       "      <td>438.50</td>\n",
       "      <td>1524.19</td>\n",
       "      <td>8934.80</td>\n",
       "      <td>3221.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-1154879</td>\n",
       "      <td>1154879</td>\n",
       "      <td>3956975</td>\n",
       "      <td>683633</td>\n",
       "      <td>1647000</td>\n",
       "      <td>2598547</td>\n",
       "      <td>1518000</td>\n",
       "      <td>2932767</td>\n",
       "      <td>5492041</td>\n",
       "      <td>8538061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>38</td>\n",
       "      <td>cpr04</td>\n",
       "      <td>20240602</td>\n",
       "      <td>130.76</td>\n",
       "      <td>-12.66</td>\n",
       "      <td>283.98</td>\n",
       "      <td>308.45</td>\n",
       "      <td>1159.76</td>\n",
       "      <td>4483.53</td>\n",
       "      <td>2830.41</td>\n",
       "      <td>...</td>\n",
       "      <td>-1445887</td>\n",
       "      <td>1445887</td>\n",
       "      <td>1236181</td>\n",
       "      <td>-1274714</td>\n",
       "      <td>1183000</td>\n",
       "      <td>1751319</td>\n",
       "      <td>1016000</td>\n",
       "      <td>2076860</td>\n",
       "      <td>4345595</td>\n",
       "      <td>5928167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>35</td>\n",
       "      <td>cpr01</td>\n",
       "      <td>20240602</td>\n",
       "      <td>130.93</td>\n",
       "      <td>-12.76</td>\n",
       "      <td>221.03</td>\n",
       "      <td>239.89</td>\n",
       "      <td>942.06</td>\n",
       "      <td>6297.03</td>\n",
       "      <td>1917.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-1841869</td>\n",
       "      <td>1841869</td>\n",
       "      <td>3246922</td>\n",
       "      <td>-87294</td>\n",
       "      <td>1590000</td>\n",
       "      <td>2362340</td>\n",
       "      <td>1385000</td>\n",
       "      <td>2697001</td>\n",
       "      <td>5123936</td>\n",
       "      <td>7611556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>36</td>\n",
       "      <td>cpr02</td>\n",
       "      <td>20240602</td>\n",
       "      <td>130.89</td>\n",
       "      <td>-12.72</td>\n",
       "      <td>153.86</td>\n",
       "      <td>167.19</td>\n",
       "      <td>614.04</td>\n",
       "      <td>1952.06</td>\n",
       "      <td>1484.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-942788</td>\n",
       "      <td>942788</td>\n",
       "      <td>-487723</td>\n",
       "      <td>-1517696</td>\n",
       "      <td>852000</td>\n",
       "      <td>1272075</td>\n",
       "      <td>735000</td>\n",
       "      <td>1554349</td>\n",
       "      <td>3511706</td>\n",
       "      <td>4430780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>37</td>\n",
       "      <td>cpr03</td>\n",
       "      <td>20240602</td>\n",
       "      <td>130.81</td>\n",
       "      <td>-12.71</td>\n",
       "      <td>24.35</td>\n",
       "      <td>26.48</td>\n",
       "      <td>103.47</td>\n",
       "      <td>336.61</td>\n",
       "      <td>255.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-451207</td>\n",
       "      <td>451207</td>\n",
       "      <td>1684937</td>\n",
       "      <td>-441714</td>\n",
       "      <td>984000</td>\n",
       "      <td>1680773</td>\n",
       "      <td>941000</td>\n",
       "      <td>2034741</td>\n",
       "      <td>4858028</td>\n",
       "      <td>6998701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid site_clean      date  lon_gda94  lat_gda94  bio_l_kg1ha  bio_t_kg1ha  \\\n",
       "0     82      nt001  20110523     131.21     -13.95         0.00         0.00   \n",
       "1     24  barkely01  20111025     135.04     -18.00         0.00         0.00   \n",
       "2     25  barkely02  20111026     135.26     -18.06         0.00         0.00   \n",
       "3     27  barkely04  20111026     135.23     -17.98         0.00         0.00   \n",
       "4     26  barkely03  20111026     135.29     -18.02         0.00         0.00   \n",
       "..   ...        ...       ...        ...        ...          ...          ...   \n",
       "195   58     jnk102  20240526     130.99     -12.60       404.07       438.50   \n",
       "196   38      cpr04  20240602     130.76     -12.66       283.98       308.45   \n",
       "197   35      cpr01  20240602     130.93     -12.76       221.03       239.89   \n",
       "198   36      cpr02  20240602     130.89     -12.72       153.86       167.19   \n",
       "199   37      cpr03  20240602     130.81     -12.71        24.35        26.48   \n",
       "\n",
       "     bio_b_kg1ha  bio_w_kg1ha  bio_br_kg1ha  ...  dbifmdry_NDGI  dbifmdry_RI  \\\n",
       "0           0.00         0.00          0.00  ...        -963139       963139   \n",
       "1           0.00         0.00          0.00  ...       -2091201      2091201   \n",
       "2           0.00         0.00          0.00  ...       -2041078      2041078   \n",
       "3           0.00         0.00          0.00  ...       -2256318      2256318   \n",
       "4           0.00         0.00          0.00  ...       -1703353      1703353   \n",
       "..           ...          ...           ...  ...            ...          ...   \n",
       "195      1524.19      8934.80       3221.17  ...       -1154879      1154879   \n",
       "196      1159.76      4483.53       2830.41  ...       -1445887      1445887   \n",
       "197       942.06      6297.03       1917.75  ...       -1841869      1841869   \n",
       "198       614.04      1952.06       1484.17  ...        -942788       942788   \n",
       "199       103.47       336.61        255.25  ...        -451207       451207   \n",
       "\n",
       "     dbifmdry_NBR  dbifmdry_NDII  dbifmdry_GDVI  dbifmdry_MSAVI  dbifmdry_DVI  \\\n",
       "0         2033821        -266174        1873000         2729666       1711000   \n",
       "1         1916078        -665772        1673000         1549615       1086000   \n",
       "2         3188841         399323        2143000         2429125       1666000   \n",
       "3         2646032        -303355        1859000         2027352       1359000   \n",
       "4         2254432        -530218        1713000         1708085       1210000   \n",
       "..            ...            ...            ...             ...           ...   \n",
       "195       3956975         683633        1647000         2598547       1518000   \n",
       "196       1236181       -1274714        1183000         1751319       1016000   \n",
       "197       3246922         -87294        1590000         2362340       1385000   \n",
       "198       -487723       -1517696         852000         1272075        735000   \n",
       "199       1684937        -441714         984000         1680773        941000   \n",
       "\n",
       "     dbifmdry_SAVI  dbifmdry_NDVI  dbifmdry_MSR  \n",
       "0          3000000        4812940       6898960  \n",
       "1          1718354        2424107       2806064  \n",
       "2          2636076        3718750       4778632  \n",
       "3          2246281        3334969       4144739  \n",
       "4          1877716        2593228       3039292  \n",
       "..             ...            ...           ...  \n",
       "195        2932767        5492041       8538061  \n",
       "196        2076860        4345595       5928167  \n",
       "197        2697001        5123936       7611556  \n",
       "198        1554349        3511706       4430780  \n",
       "199        2034741        4858028       6998701  \n",
       "\n",
       "[200 rows x 380 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.238722Z",
     "start_time": "2024-08-02T06:26:53.231722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_nulls = df.columns[df.isnull().any()]\n",
    "columns_with_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.359721Z",
     "start_time": "2024-08-02T06:26:53.341722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uid', 'site_clean', 'date', 'lon_gda94', 'lat_gda94', 'bio_l_kg1ha', 'bio_t_kg1ha', 'bio_b_kg1ha', 'bio_w_kg1ha', 'bio_br_kg1ha', 'bio_s_kg1ha', 'bio_r_kg1ha', 'target', 'c_l_kg1ha', 'c_t_kg1ha', 'c_b_kg1ha', 'c_w_kg1ha', 'c_br_kg1ha', 'c_s_kg1ha', 'c_r_kg1ha', 'c_agb_kg1ha', 'mean_f_afsm', 'min_f_afsm', 'max_f_afsm', 'mean_f_apos', 'min_f_apos', 'max_f_apos', 'mean_f_ario', 'min_f_ario', 'max_f_ario', 'mean_f_dfsm', 'min_f_dfsm', 'max_f_dfsm', 'mean_f_dpos', 'min_f_dpos', 'max_f_dpos', 'mean_f_drio', 'min_f_drio', 'max_f_drio', 'mean_f_lfsm', 'min_f_lfsm', 'max_f_lfsm', 'mean_f_lpos', 'min_f_lpos', 'max_f_lpos', 'mean_f_lrio', 'min_f_lrio', 'max_f_lrio', 'dr_asav', 'dr_asmd', 'dr_aavg', 'dr_amed', 'dr_asiv', 'dr_asid', 'dr_asum', 'dr_corr', 'dr_dsav', 'dr_dsmd', 'dr_davg', 'dr_dmed', 'dr_dsiv', 'dr_dsid', 'dr_dsum', 'dr_mavg', 'dr_mmed', 'dr_msum', 'dr_wsav', 'dr_wsmd', 'dr_wavg', 'dr_wmed', 'dr_wsiv', 'dr_wsid', 'dr_wsum', 'ma_asav', 'ma_asmd', 'ma_aavg', 'ma_amed', 'ma_asiv', 'ma_asid', 'ma_asum', 'ma_corr', 'ma_dsav', 'ma_dsmd', 'ma_davg', 'ma_dmed', 'ma_dsiv', 'ma_dsid', 'ma_dsum', 'ma_mavg', 'ma_mmed', 'ma_msum', 'ma_wsav', 'ma_wsmd', 'ma_wavg', 'ma_wmed', 'ma_wsiv', 'ma_wsid', 'ma_wsum', 'tx_asav', 'tx_asmd', 'tx_aavg', 'tx_amed', 'tx_asiv', 'tx_asid', 'tx_asum', 'tx_corr', 'tx_dsav', 'tx_dsmd', 'tx_davg', 'tx_dmed', 'tx_dsiv', 'tx_dsid', 'tx_dsum', 'tx_mavg', 'tx_mmed', 'tx_msum', 'tx_wsav', 'tx_wsmd', 'tx_wavg', 'tx_wmed', 'tx_wsiv', 'tx_wsid', 'tx_wsum', 'tn_asav', 'tn_asmd', 'tn_aavg', 'tn_amed', 'tn_asiv', 'tn_asid', 'tn_asum', 'tn_corr', 'tn_dsav', 'tn_dsmd', 'tn_davg', 'tn_dmed', 'tn_dsiv', 'tn_dsid', 'tn_dsum', 'tn_mavg', 'tn_mmed', 'tn_msum', 'tn_wsav', 'tn_wsmd', 'tn_wavg', 'tn_wmed', 'tn_wsiv', 'tn_wsid', 'tn_wsum', 'rx_asav', 'rx_asmd', 'rx_aavg', 'rx_amed', 'rx_asiv', 'rx_asid', 'rx_asum', 'rx_corr', 'rx_dsav', 'rx_dsmd', 'rx_davg', 'rx_dmed', 'rx_dsiv', 'rx_dsid', 'rx_dsum', 'rx_mavg', 'rx_mmed', 'rx_msum', 'rx_wsav', 'rx_wsmd', 'rx_wavg', 'rx_wmed', 'rx_wsiv', 'rx_wsid', 'rx_wsum', 'rn_asav', 'rn_asmd', 'rn_aavg', 'rn_amed', 'rn_asiv', 'rn_asid', 'rn_asum', 'rn_corr', 'rn_dsav', 'rn_dsmd', 'rn_davg', 'rn_dmed', 'rn_dsiv', 'rn_dsid', 'rn_dsum', 'rn_mavg', 'rn_mmed', 'rn_msum', 'rn_wsav', 'rn_wsmd', 'rn_wavg', 'rn_wmed', 'rn_wsiv', 'rn_wsid', 'rn_wsum', 'b1_wfp_dry_min', 'b1_wfp_dry_max', 'b1_wfp_dry_mean', 'b1_wfp_dry_std', 'b1_wfp_dry_med', 'b1_wfp_dry_p25', 'b1_wfp_dry_p50', 'b1_wfp_dry_p75', 'b1_wfp_dry_p95', 'b1_wfp_dry_p99', 'b1_wdc_dry_major', 'b1_wdc_dry_minor', 'b1_n17_dry_major', 'b1_n17_dry_minor', 'b1_hsd_min', 'b1_hsd_max', 'b1_hsd_mean', 'b1_hsd_std', 'b1_hsd_med', 'b1_hsd_p25', 'b1_hsd_p50', 'b1_hsd_p75', 'b1_hsd_p95', 'b1_hsd_p99', 'b1_hmc_min', 'b1_hmc_max', 'b1_hmc_mean', 'b1_hmc_std', 'b1_hmc_med', 'b1_hmc_p25', 'b1_hmc_p50', 'b1_hmc_p75', 'b1_hmc_p95', 'b1_hmc_p99', 'b1_hcv_min', 'b1_hcv_max', 'b1_hcv_mean', 'b1_hcv_std', 'b1_hcv_med', 'b1_hcv_p25', 'b1_hcv_p50', 'b1_hcv_p75', 'b1_hcv_p95', 'b1_hcv_p99', 'b1_h99_min', 'b1_h99_max', 'b1_h99_mean', 'b1_h99_std', 'b1_h99_med', 'b1_h99_p25', 'b1_h99_p50', 'b1_h99_p75', 'b1_h99_p95', 'b1_h99_p99', 'b1_fdc_dry_major', 'b1_fdc_dry_minor', 'b1_ccw_dry_min', 'b1_ccw_dry_max', 'b1_ccw_dry_mean', 'b1_ccw_dry_std', 'b1_ccw_dry_med', 'b1_ccw_dry_p25', 'b1_ccw_dry_p50', 'b1_ccw_dry_p75', 'b1_ccw_dry_p95', 'b1_ccw_dry_p99', 'b1_dp1fm_dry_min', 'b1_dp1fm_dry_max', 'b1_dp1fm_dry_mean', 'b1_dp1fm_dry_std', 'b1_dp1fm_dry_med', 'b1_dp1fm_dry_p25', 'b1_dp1fm_dry_p50', 'b1_dp1fm_dry_p75', 'b1_dp1fm_dry_p95', 'b1_dp1fm_dry_p99', 'b2_dp1fm_dry_min', 'b2_dp1fm_dry_max', 'b2_dp1fm_dry_mean', 'b2_dp1fm_dry_std', 'b2_dp1fm_dry_med', 'b2_dp1fm_dry_p25', 'b2_dp1fm_dry_p50', 'b2_dp1fm_dry_p75', 'b2_dp1fm_dry_p95', 'b2_dp1fm_dry_p99', 'b3_dp1fm_dry_min', 'b3_dp1fm_dry_max', 'b3_dp1fm_dry_mean', 'b3_dp1fm_dry_std', 'b3_dp1fm_dry_med', 'b3_dp1fm_dry_p25', 'b3_dp1fm_dry_p50', 'b3_dp1fm_dry_p75', 'b3_dp1fm_dry_p95', 'b3_dp1fm_dry_p99', 'b1_dbifm_dry_std', 'b1_dbifm_dry_med', 'b1_dbifm_dry_p25', 'b1_dbifm_dry_p50', 'b1_dbifm_dry_p75', 'b1_dbifm_dry_p95', 'b1_dbifm_dry_p99', 'b2_dbifm_dry_min', 'b2_dbifm_dry_max', 'b2_dbifm_dry_mean', 'b2_dbifm_dry_std', 'b2_dbifm_dry_med', 'b2_dbifm_dry_p25', 'b2_dbifm_dry_p50', 'b2_dbifm_dry_p75', 'b2_dbifm_dry_p95', 'b2_dbifm_dry_p99', 'b3_dbifm_dry_min', 'b3_dbifm_dry_max', 'b3_dbifm_dry_mean', 'b3_dbifm_dry_std', 'b3_dbifm_dry_med', 'b3_dbifm_dry_p25', 'b3_dbifm_dry_p50', 'b3_dbifm_dry_p75', 'b3_dbifm_dry_p95', 'b3_dbifm_dry_p99', 'b4_dbifm_dry_min', 'b4_dbifm_dry_max', 'b4_dbifm_dry_mean', 'b4_dbifm_dry_std', 'b4_dbifm_dry_med', 'b4_dbifm_dry_p25', 'b4_dbifm_dry_p50', 'b4_dbifm_dry_p75', 'b4_dbifm_dry_p95', 'b4_dbifm_dry_p99', 'b5_dbifm_dry_min', 'b5_dbifm_dry_max', 'b5_dbifm_dry_mean', 'b5_dbifm_dry_std', 'b5_dbifm_dry_med', 'b5_dbifm_dry_p25', 'b5_dbifm_dry_p50', 'b5_dbifm_dry_p75', 'b5_dbifm_dry_p95', 'b5_dbifm_dry_p99', 'b6_dbifm_dry_min', 'b6_dbifm_dry_max', 'b6_dbifm_dry_mean', 'b6_dbifm_dry_std', 'b6_dbifm_dry_med', 'b6_dbifm_dry_p25', 'b6_dbifm_dry_p50', 'b6_dbifm_dry_p75', 'b6_dbifm_dry_p95', 'b6_dbifm_dry_p99', 'dbifmdry_psB1a', 'dbifmdry_psB2a', 'dbifmdry_psB3a', 'dbifmdry_psB4a', 'dbifmdry_psB5a', 'dbifmdry_psB6a', 'dbifmdry_r32', 'dbifmdry_r42', 'dbifmdry_r43', 'dbifmdry_r52', 'dbifmdry_r53', 'dbifmdry_r54', 'dbifmdry_r62', 'dbifmdry_r63', 'dbifmdry_r64', 'dbifmdry_r65', 'dbifmdry_GSAVI', 'dbifmdry_GNDVI', 'dbifmdry_CVI', 'dbifmdry_NDGI', 'dbifmdry_RI', 'dbifmdry_NBR', 'dbifmdry_NDII', 'dbifmdry_GDVI', 'dbifmdry_MSAVI', 'dbifmdry_DVI', 'dbifmdry_SAVI', 'dbifmdry_NDVI', 'dbifmdry_MSR']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.436722Z",
     "start_time": "2024-08-02T06:26:53.431722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 45)\n"
     ]
    }
   ],
   "source": [
    "#main major and h99 \n",
    "var_ = data_comp\n",
    "\n",
    "df_columns = list(df.columns)\n",
    "keep = ['site_clean', \"target\", \n",
    "        \"mean\", \n",
    "        #\"major\", \n",
    "        #\"p99\", \n",
    "        \"GNDVI\", \"MSR\", \"NBR\", \"_NDVI\", \"CVI\", \"GDVI\", \"GSAVI\",\n",
    "        \"NDGI\",\"RI\", \"NDII\", \"MSAVI\", \"SAVI\"\n",
    "       'r32', 'r42', 'r43',\n",
    "         'r52', 'r53', 'r54', 'r62', 'r63', 'r64', 'r65',\n",
    "         #'dr_', 'ma_', 'tx_', 'tn_', 'rx_', 'rn_'\n",
    "        ]\n",
    "header = [ele for ele in df_columns for x in keep if x in ele]\n",
    "df2 = df[header]\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop fdc - no need for this data\n",
    "\n",
    "# Identify columns that contain \"fdc\" in their column names\n",
    "columns_to_drop = df2.columns[df2.columns.str.contains(\"fdc\", case=False)]\n",
    "\n",
    "# Drop these columns\n",
    "df2 = df2.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 45)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.577124Z",
     "start_time": "2024-08-02T06:26:53.562622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['site_clean', 'target', 'mean_f_afsm', 'mean_f_apos', 'mean_f_ario', 'mean_f_dfsm', 'mean_f_dpos', 'mean_f_drio', 'mean_f_lfsm', 'mean_f_lpos', 'mean_f_lrio', 'b1_wfp_dry_mean', 'b1_hsd_mean', 'b1_hmc_mean', 'b1_hcv_mean', 'b1_h99_mean', 'b1_ccw_dry_mean', 'b1_dp1fm_dry_mean', 'b2_dp1fm_dry_mean', 'b3_dp1fm_dry_mean', 'b2_dbifm_dry_mean', 'b3_dbifm_dry_mean', 'b4_dbifm_dry_mean', 'b5_dbifm_dry_mean', 'b6_dbifm_dry_mean', 'dbifmdry_r42', 'dbifmdry_r43', 'dbifmdry_r52', 'dbifmdry_r53', 'dbifmdry_r54', 'dbifmdry_r62', 'dbifmdry_r63', 'dbifmdry_r64', 'dbifmdry_r65', 'dbifmdry_GSAVI', 'dbifmdry_GNDVI', 'dbifmdry_CVI', 'dbifmdry_NDGI', 'dbifmdry_RI', 'dbifmdry_NBR', 'dbifmdry_NDII', 'dbifmdry_GDVI', 'dbifmdry_MSAVI', 'dbifmdry_NDVI', 'dbifmdry_MSR']\n"
     ]
    }
   ],
   "source": [
    "print(df2.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.656830Z",
     "start_time": "2024-08-02T06:26:53.642822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "df_columns = list(df2.columns)\n",
    "keep = ['major']\n",
    "       \n",
    "classified_cols = [ele for ele in df_columns for x in keep if x in ele]\n",
    "print(classified_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.704822Z",
     "start_time": "2024-08-02T06:26:53.692822Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2 = df2[['site_clean', 'target', 'dbifmdry_r42', 'dbifmdry_r43', 'dbifmdry_r52', 'dbifmdry_r53', 'dbifmdry_r54', 'dbifmdry_r62', 'dbifmdry_r63', 'dbifmdry_r64', 'dbifmdry_r65', 'dbifmdry_NDVI',\n",
    "# \n",
    "#  ]]\n",
    "# print(df2.columns.tolist())\n",
    "# var_ = \"_ratio_NDVI_only_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.846825Z",
     "start_time": "2024-08-02T06:26:53.829822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['site_clean',\n",
       " 'target',\n",
       " 'b1_wfp_dry_mean',\n",
       " 'b1_hsd_mean',\n",
       " 'b1_hmc_mean',\n",
       " 'b1_hcv_mean',\n",
       " 'b1_h99_mean',\n",
       " 'b1_ccw_dry_mean',\n",
       " 'b1_dp1fm_dry_mean',\n",
       " 'b2_dp1fm_dry_mean',\n",
       " 'b3_dp1fm_dry_mean',\n",
       " 'b2_dbifm_dry_mean',\n",
       " 'b3_dbifm_dry_mean',\n",
       " 'b4_dbifm_dry_mean',\n",
       " 'b5_dbifm_dry_mean',\n",
       " 'b6_dbifm_dry_mean',\n",
       " 'dbifmdry_r42',\n",
       " 'dbifmdry_r43',\n",
       " 'dbifmdry_r52',\n",
       " 'dbifmdry_r53',\n",
       " 'dbifmdry_r54',\n",
       " 'dbifmdry_r62',\n",
       " 'dbifmdry_r63',\n",
       " 'dbifmdry_r64',\n",
       " 'dbifmdry_r65',\n",
       " 'dbifmdry_GSAVI',\n",
       " 'dbifmdry_GNDVI',\n",
       " 'dbifmdry_CVI',\n",
       " 'dbifmdry_NDGI',\n",
       " 'dbifmdry_RI',\n",
       " 'dbifmdry_NBR',\n",
       " 'dbifmdry_NDII',\n",
       " 'dbifmdry_GDVI',\n",
       " 'dbifmdry_MSAVI',\n",
       " 'dbifmdry_NDVI',\n",
       " 'dbifmdry_MSR']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:53.908826Z",
     "start_time": "2024-08-02T06:26:53.903826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate columns found.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate columns and print them\n",
    "duplicate_columns = df2.columns[df2.columns.duplicated()]\n",
    "\n",
    "if duplicate_columns.any():\n",
    "    print(\"Duplicate columns found:\")\n",
    "    for col in duplicate_columns:\n",
    "        print(col)\n",
    "else:\n",
    "    print(\"No duplicate columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove site values which seem like outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect outliers using Z score on all columns including Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.048829Z",
     "start_time": "2024-08-02T06:26:54.028823Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Z score outliers on all columns except target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.456937Z",
     "start_time": "2024-08-02T06:26:54.412937Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "# Function to detect outliers using Z-score\n",
    "def detect_outliers(df, target_column):\n",
    "    # Select only numeric columns except the target column\n",
    "    numeric_df = df.select_dtypes(include=[np.number]).drop(columns=[target_column])\n",
    "    \n",
    "    # Calculate the Z-scores\n",
    "    z_scores = np.abs(zscore(numeric_df))\n",
    "    \n",
    "    # Identify rows with Z-scores greater than 3 in any column\n",
    "    outliers = (z_scores > 3).any(axis=1)\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "# Assuming df2 is your DataFrame with mixed data types and 'target' is the target column\n",
    "df = df2.copy()\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'target'  # Replace 'target' with the name of your target column\n",
    "\n",
    "# Detect outliers\n",
    "outliers = detect_outliers(df, target_column)\n",
    "\n",
    "# Print the detected outliers\n",
    "print(\"Detected Outliers:\")\n",
    "print(df[outliers])\n",
    "\n",
    "# If you want to highlight these outliers in the original DataFrame\n",
    "df_highlighted = df.copy()\n",
    "\n",
    "for col in df.select_dtypes(include=[np.number]).drop(columns=[target_column]).columns:\n",
    "    df_highlighted[col + '_outlier'] = np.where(outliers, 'Outlier', 'Normal')\n",
    "\n",
    "print(\"Original DataFrame with Outliers Highlighted:\")\n",
    "print(df_highlighted)\n",
    "\n",
    "output_ = os.path.join(output, f\"dry_mask_{var_}_not_target_outlier.csv\")\n",
    "df_highlighted.to_csv(output_, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.550938Z",
     "start_time": "2024-08-02T06:26:54.515939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Outliers:\n",
      "5           amg08.2012\n",
      "20          auv07.2012\n",
      "40           ep01.2012\n",
      "48          hsf01.2012\n",
      "50         hshr01.2012\n",
      "62         legu03.2012\n",
      "76          lit01.2013\n",
      "84          nt004.2012\n",
      "132    ntamgd0002.2014\n",
      "142    ntastu0005.2016\n",
      "167        site21.2023\n",
      "191          wh03.2012\n",
      "192          wh04.2012\n",
      "Name: site_clean, dtype: object\n",
      "Cleaned DataFrame (without outliers):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_clean</th>\n",
       "      <th>target</th>\n",
       "      <th>b1_wfp_dry_mean</th>\n",
       "      <th>b1_hsd_mean</th>\n",
       "      <th>b1_hmc_mean</th>\n",
       "      <th>b1_hcv_mean</th>\n",
       "      <th>b1_h99_mean</th>\n",
       "      <th>b1_ccw_dry_mean</th>\n",
       "      <th>b1_dp1fm_dry_mean</th>\n",
       "      <th>b2_dp1fm_dry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>dbifmdry_GNDVI</th>\n",
       "      <th>dbifmdry_CVI</th>\n",
       "      <th>dbifmdry_NDGI</th>\n",
       "      <th>dbifmdry_RI</th>\n",
       "      <th>dbifmdry_NBR</th>\n",
       "      <th>dbifmdry_NDII</th>\n",
       "      <th>dbifmdry_GDVI</th>\n",
       "      <th>dbifmdry_MSAVI</th>\n",
       "      <th>dbifmdry_NDVI</th>\n",
       "      <th>dbifmdry_MSR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agb02.2012</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.89</td>\n",
       "      <td>103.63</td>\n",
       "      <td>107.13</td>\n",
       "      <td>151.32</td>\n",
       "      <td>114.13</td>\n",
       "      <td>68.00</td>\n",
       "      <td>10.67</td>\n",
       "      <td>44.33</td>\n",
       "      <td>...</td>\n",
       "      <td>5566970</td>\n",
       "      <td>47885270</td>\n",
       "      <td>-1538462</td>\n",
       "      <td>1538462</td>\n",
       "      <td>1964774</td>\n",
       "      <td>-383207</td>\n",
       "      <td>1409000</td>\n",
       "      <td>2022182</td>\n",
       "      <td>4405850</td>\n",
       "      <td>6047316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amg01.2012</td>\n",
       "      <td>8376.22</td>\n",
       "      <td>44.00</td>\n",
       "      <td>103.88</td>\n",
       "      <td>106.25</td>\n",
       "      <td>169.41</td>\n",
       "      <td>113.93</td>\n",
       "      <td>66.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>43.67</td>\n",
       "      <td>...</td>\n",
       "      <td>5898277</td>\n",
       "      <td>50775600</td>\n",
       "      <td>-1341991</td>\n",
       "      <td>1341991</td>\n",
       "      <td>2881356</td>\n",
       "      <td>-338983</td>\n",
       "      <td>1438000</td>\n",
       "      <td>2197130</td>\n",
       "      <td>4947937</td>\n",
       "      <td>7201101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amg03.2012</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.33</td>\n",
       "      <td>101.58</td>\n",
       "      <td>103.49</td>\n",
       "      <td>137.70</td>\n",
       "      <td>106.57</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.67</td>\n",
       "      <td>10.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5460945</td>\n",
       "      <td>58363315</td>\n",
       "      <td>-2629287</td>\n",
       "      <td>2629287</td>\n",
       "      <td>1429988</td>\n",
       "      <td>-1452928</td>\n",
       "      <td>1629000</td>\n",
       "      <td>1787156</td>\n",
       "      <td>3306405</td>\n",
       "      <td>4099401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amg05.2012</td>\n",
       "      <td>24670.80</td>\n",
       "      <td>34.83</td>\n",
       "      <td>103.14</td>\n",
       "      <td>105.14</td>\n",
       "      <td>157.61</td>\n",
       "      <td>111.49</td>\n",
       "      <td>54.75</td>\n",
       "      <td>8.75</td>\n",
       "      <td>37.25</td>\n",
       "      <td>...</td>\n",
       "      <td>5793397</td>\n",
       "      <td>47524435</td>\n",
       "      <td>-1173184</td>\n",
       "      <td>1173184</td>\n",
       "      <td>2241024</td>\n",
       "      <td>-539075</td>\n",
       "      <td>1088000</td>\n",
       "      <td>1753382</td>\n",
       "      <td>4957136</td>\n",
       "      <td>7222079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amg06.2012</td>\n",
       "      <td>3086.16</td>\n",
       "      <td>29.78</td>\n",
       "      <td>103.02</td>\n",
       "      <td>104.74</td>\n",
       "      <td>163.29</td>\n",
       "      <td>110.91</td>\n",
       "      <td>48.33</td>\n",
       "      <td>5.22</td>\n",
       "      <td>33.78</td>\n",
       "      <td>...</td>\n",
       "      <td>5341797</td>\n",
       "      <td>42394332</td>\n",
       "      <td>-1255729</td>\n",
       "      <td>1255729</td>\n",
       "      <td>2197205</td>\n",
       "      <td>-836979</td>\n",
       "      <td>1094000</td>\n",
       "      <td>1668140</td>\n",
       "      <td>4379863</td>\n",
       "      <td>5995724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>wh07.2012</td>\n",
       "      <td>240.24</td>\n",
       "      <td>2.25</td>\n",
       "      <td>100.94</td>\n",
       "      <td>102.21</td>\n",
       "      <td>140.04</td>\n",
       "      <td>103.96</td>\n",
       "      <td>2.25</td>\n",
       "      <td>35.33</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>3616564</td>\n",
       "      <td>30388263</td>\n",
       "      <td>-1751216</td>\n",
       "      <td>1751216</td>\n",
       "      <td>-653378</td>\n",
       "      <td>-1646321</td>\n",
       "      <td>1345000</td>\n",
       "      <td>1214483</td>\n",
       "      <td>1991475</td>\n",
       "      <td>2236580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>wh08.2012</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.92</td>\n",
       "      <td>102.08</td>\n",
       "      <td>103.29</td>\n",
       "      <td>156.05</td>\n",
       "      <td>107.97</td>\n",
       "      <td>21.25</td>\n",
       "      <td>30.33</td>\n",
       "      <td>19.67</td>\n",
       "      <td>...</td>\n",
       "      <td>4150995</td>\n",
       "      <td>34182549</td>\n",
       "      <td>-1711085</td>\n",
       "      <td>1711085</td>\n",
       "      <td>742810</td>\n",
       "      <td>-791061</td>\n",
       "      <td>1523000</td>\n",
       "      <td>1587738</td>\n",
       "      <td>2626459</td>\n",
       "      <td>3085874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>wh09.2012</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.89</td>\n",
       "      <td>100.82</td>\n",
       "      <td>101.59</td>\n",
       "      <td>144.41</td>\n",
       "      <td>103.81</td>\n",
       "      <td>14.22</td>\n",
       "      <td>1.78</td>\n",
       "      <td>15.67</td>\n",
       "      <td>...</td>\n",
       "      <td>4826087</td>\n",
       "      <td>42441388</td>\n",
       "      <td>-1939035</td>\n",
       "      <td>1939035</td>\n",
       "      <td>2065458</td>\n",
       "      <td>-545833</td>\n",
       "      <td>1776000</td>\n",
       "      <td>1952017</td>\n",
       "      <td>3185114</td>\n",
       "      <td>3909535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>wh13.2012</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>101.01</td>\n",
       "      <td>101.96</td>\n",
       "      <td>131.00</td>\n",
       "      <td>104.01</td>\n",
       "      <td>11.00</td>\n",
       "      <td>21.38</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3514137</td>\n",
       "      <td>29196771</td>\n",
       "      <td>-1670989</td>\n",
       "      <td>1670989</td>\n",
       "      <td>1488840</td>\n",
       "      <td>-458342</td>\n",
       "      <td>1218000</td>\n",
       "      <td>1131930</td>\n",
       "      <td>1958131</td>\n",
       "      <td>2194196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>wh15.2012</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>100.89</td>\n",
       "      <td>101.59</td>\n",
       "      <td>138.83</td>\n",
       "      <td>103.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.78</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4170644</td>\n",
       "      <td>36003359</td>\n",
       "      <td>-1938944</td>\n",
       "      <td>1938944</td>\n",
       "      <td>1487304</td>\n",
       "      <td>-952381</td>\n",
       "      <td>1398000</td>\n",
       "      <td>1389131</td>\n",
       "      <td>2428048</td>\n",
       "      <td>2811428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     site_clean   target  b1_wfp_dry_mean  b1_hsd_mean  b1_hmc_mean  \\\n",
       "0    agb02.2012     0.00            45.89       103.63       107.13   \n",
       "1    amg01.2012  8376.22            44.00       103.88       106.25   \n",
       "2    amg03.2012     0.00             3.33       101.58       103.49   \n",
       "3    amg05.2012 24670.80            34.83       103.14       105.14   \n",
       "4    amg06.2012  3086.16            29.78       103.02       104.74   \n",
       "..          ...      ...              ...          ...          ...   \n",
       "195   wh07.2012   240.24             2.25       100.94       102.21   \n",
       "196   wh08.2012     0.00            11.92       102.08       103.29   \n",
       "197   wh09.2012     0.00             7.89       100.82       101.59   \n",
       "198   wh13.2012     0.00             6.00       101.01       101.96   \n",
       "199   wh15.2012     0.00             1.00       100.89       101.59   \n",
       "\n",
       "     b1_hcv_mean  b1_h99_mean  b1_ccw_dry_mean  b1_dp1fm_dry_mean  \\\n",
       "0         151.32       114.13            68.00              10.67   \n",
       "1         169.41       113.93            66.00               1.33   \n",
       "2         137.70       106.57             6.92               0.67   \n",
       "3         157.61       111.49            54.75               8.75   \n",
       "4         163.29       110.91            48.33               5.22   \n",
       "..           ...          ...              ...                ...   \n",
       "195       140.04       103.96             2.25              35.33   \n",
       "196       156.05       107.97            21.25              30.33   \n",
       "197       144.41       103.81            14.22               1.78   \n",
       "198       131.00       104.01            11.00              21.38   \n",
       "199       138.83       103.90             1.00               5.78   \n",
       "\n",
       "     b2_dp1fm_dry_mean  ...  dbifmdry_GNDVI  dbifmdry_CVI  dbifmdry_NDGI  \\\n",
       "0                44.33  ...         5566970      47885270       -1538462   \n",
       "1                43.67  ...         5898277      50775600       -1341991   \n",
       "2                10.42  ...         5460945      58363315       -2629287   \n",
       "3                37.25  ...         5793397      47524435       -1173184   \n",
       "4                33.78  ...         5341797      42394332       -1255729   \n",
       "..                 ...  ...             ...           ...            ...   \n",
       "195               5.75  ...         3616564      30388263       -1751216   \n",
       "196              19.67  ...         4150995      34182549       -1711085   \n",
       "197              15.67  ...         4826087      42441388       -1939035   \n",
       "198               2.50  ...         3514137      29196771       -1670989   \n",
       "199               2.00  ...         4170644      36003359       -1938944   \n",
       "\n",
       "     dbifmdry_RI  dbifmdry_NBR  dbifmdry_NDII  dbifmdry_GDVI  dbifmdry_MSAVI  \\\n",
       "0        1538462       1964774        -383207        1409000         2022182   \n",
       "1        1341991       2881356        -338983        1438000         2197130   \n",
       "2        2629287       1429988       -1452928        1629000         1787156   \n",
       "3        1173184       2241024        -539075        1088000         1753382   \n",
       "4        1255729       2197205        -836979        1094000         1668140   \n",
       "..           ...           ...            ...            ...             ...   \n",
       "195      1751216       -653378       -1646321        1345000         1214483   \n",
       "196      1711085        742810        -791061        1523000         1587738   \n",
       "197      1939035       2065458        -545833        1776000         1952017   \n",
       "198      1670989       1488840        -458342        1218000         1131930   \n",
       "199      1938944       1487304        -952381        1398000         1389131   \n",
       "\n",
       "     dbifmdry_NDVI  dbifmdry_MSR  \n",
       "0          4405850       6047316  \n",
       "1          4947937       7201101  \n",
       "2          3306405       4099401  \n",
       "3          4957136       7222079  \n",
       "4          4379863       5995724  \n",
       "..             ...           ...  \n",
       "195        1991475       2236580  \n",
       "196        2626459       3085874  \n",
       "197        3185114       3909535  \n",
       "198        1958131       2194196  \n",
       "199        2428048       2811428  \n",
       "\n",
       "[187 rows x 36 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "# Function to detect outliers using Z-score\n",
    "def detect_outliers(df):\n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Calculate the Z-scores\n",
    "    z_scores = np.abs(zscore(numeric_df))\n",
    "    \n",
    "    # Identify rows with Z-scores greater than 3 in any column\n",
    "    outliers = (z_scores > 3).any(axis=1)\n",
    "    \n",
    "    return outliers\n",
    "\n",
    "# Assuming df2 is your DataFrame with mixed data types\n",
    "df = df2.copy()\n",
    "\n",
    "# Detect outliers\n",
    "outliers = detect_outliers(df)\n",
    "\n",
    "# Print the detected outliers\n",
    "print(\"Detected Outliers:\")\n",
    "print(df[outliers].site_clean)\n",
    "\n",
    "# Drop rows that contain outliers\n",
    "df_cleaned = df[~outliers]\n",
    "\n",
    "print(\"Cleaned DataFrame (without outliers):\")\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.599968Z",
     "start_time": "2024-08-02T06:26:54.573948Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.728997Z",
     "start_time": "2024-08-02T06:26:54.722001Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.820998Z",
     "start_time": "2024-08-02T06:26:54.817998Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:54.901005Z",
     "start_time": "2024-08-02T06:26:54.886997Z"
    }
   },
   "outputs": [],
   "source": [
    "# predicted value is x\n",
    "value_x = 'target'\n",
    "# variable is y\n",
    "value_y = \"b1_wfp_mean\"\n",
    "value_a = 'b2_dp1fm_dry_mean'\n",
    "value_b = 'b1_h99_mean'\n",
    "\n",
    "\n",
    "site = 'site_clean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:55.104999Z",
     "start_time": "2024-08-02T06:26:55.086998Z"
    }
   },
   "outputs": [],
   "source": [
    "value_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:55.152998Z",
     "start_time": "2024-08-02T06:26:55.141998Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:55.246998Z",
     "start_time": "2024-08-02T06:26:55.230999Z"
    }
   },
   "outputs": [],
   "source": [
    "output_int = os.path.join(output, \"inter\")\n",
    "if not os.path.isdir(output_int):\n",
    "    os.mkdir(output_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:55.311Z",
     "start_time": "2024-08-02T06:26:55.287998Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_fig(value_x, value_y):\n",
    "    # Output to file\n",
    "    output_file(os.path.join(output_int,'all_sites_{0}_{1}.html'.format(value_x, value_y)),\n",
    "                title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")))\n",
    "\n",
    "\n",
    "    #Specify the selection tools to be made available\n",
    "    select_tools = ['box_select', 'lasso_select', 'poly_select', 'tap', 'zoom_in', 'zoom_out', 'wheel_zoom', 'reset']\n",
    "\n",
    "    #print(test)\n",
    "    # Format the tooltip\n",
    "    tooltips = [\n",
    "                ('Site', '@site_clean'),\n",
    "                (value_x, '@{0}'.format(value_x)),\n",
    "                (value_y, '@{0}'.format(value_y)),   \n",
    "                (value_a, '@{0}'.format(value_a)),\n",
    "                (value_b, '@{0}'.format(value_b)) \n",
    "               ]\n",
    "\n",
    "    # Create the figure\n",
    "    fig = figure(plot_height=400,\n",
    "                 plot_width=1500,\n",
    "                 y_axis_label= value_y.replace(\"_\", \" \"), \n",
    "                 x_axis_label= value_x.replace(\"_\", \" \"),\n",
    "                 title='Relationship between {0} and {1}'.format(value_x.replace(\"_\", \" \"), value_y.replace(\"_\", \" \")),\n",
    "                 toolbar_location='below',\n",
    "                 tools=select_tools)\n",
    "\n",
    "    # # Format the y-axis tick label\n",
    "    fig.yaxis[0].formatter = NumeralTickFormatter(format='0')\n",
    "\n",
    "    # Add square representing each site\n",
    "    fig.square(x= value_x,\n",
    "               y= value_y,\n",
    "               source=df2.round(4),\n",
    "               size=5,\n",
    "               color='royalblue',\n",
    "               selection_color='deepskyblue',\n",
    "               nonselection_color='lightgray',\n",
    "               nonselection_alpha=0.3)\n",
    "\n",
    "    # Add the HoverTool to the figure\n",
    "    fig.add_tools(HoverTool(tooltips=tooltips))\n",
    "\n",
    "    # Visualize\n",
    "    save(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:55.466997Z",
     "start_time": "2024-08-02T06:26:55.453997Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.416305Z",
     "start_time": "2024-08-02T06:26:55.493997Z"
    }
   },
   "outputs": [],
   "source": [
    "column_list = df2.columns.to_list()\n",
    "y_list = column_list[3:]\n",
    "value_x = column_list[1:2][0]\n",
    "\n",
    "\n",
    "for i in y_list:\n",
    "    value_y = i\n",
    "    save_fig(value_x, value_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.432297Z",
     "start_time": "2024-08-02T06:26:56.417298Z"
    }
   },
   "outputs": [],
   "source": [
    "print(column_list[3:])\n",
    "print(column_list[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding (for Tree-based Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.448305Z",
     "start_time": "2024-08-02T06:26:56.433299Z"
    }
   },
   "outputs": [],
   "source": [
    "# add columns that contain class data n17\n",
    "classified_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.464377Z",
     "start_time": "2024-08-02T06:26:56.449298Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.479696Z",
     "start_time": "2024-08-02T06:26:56.465691Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in classified_cols:\n",
    "    df2 = pd.get_dummies(df2, columns=[i], prefix=f'{i}_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.495696Z",
     "start_time": "2024-08-02T06:26:56.480696Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_encoded\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which data set to run the models from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.511696Z",
     "start_time": "2024-08-02T06:26:56.496696Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.527696Z",
     "start_time": "2024-08-02T06:26:56.513696Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop some of the unwanted values\n",
    "df_ml.drop(['site_clean',], axis=1, inplace=True)\n",
    "#df_ml.drop(['fpca2_imdate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.542696Z",
     "start_time": "2024-08-02T06:26:56.529696Z"
    }
   },
   "outputs": [],
   "source": [
    "print(list(df_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.557696Z",
     "start_time": "2024-08-02T06:26:56.543696Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.573696Z",
     "start_time": "2024-08-02T06:26:56.559696Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce level of 0 values is this cell needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop AGB numbers which are low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.589696Z",
     "start_time": "2024-08-02T06:26:56.574696Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2 = df2[df2['target']>0.0]\n",
    "# #df2 = df2[df2['target']>1000.0]\n",
    "# df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.605701Z",
     "start_time": "2024-08-02T06:26:56.591701Z"
    }
   },
   "outputs": [],
   "source": [
    "# columns_with_nulls = df2.columns[df2.isnull().any()]\n",
    "# columns_with_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop AGB numbers which are high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.621214Z",
     "start_time": "2024-08-02T06:26:56.607204Z"
    }
   },
   "outputs": [],
   "source": [
    "# # drop the 7 tern sites that appear to be outliers\n",
    "# df2 =df2[df2['target'] <= 40000]\n",
    "# df2.to_csv(os.path.join(output, \"{0}_lt_40000.csv\".format('target')))\n",
    "# #df2 =df2[df2['target'] > 40000]\n",
    "# #df2.value_counts(['site_clean', value_x, value_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.636476Z",
     "start_time": "2024-08-02T06:26:56.622215Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.651989Z",
     "start_time": "2024-08-02T06:26:56.638476Z"
    }
   },
   "outputs": [],
   "source": [
    "#no removal\n",
    "out_df = df_ml\n",
    "samp = \"all_data\"\n",
    "\n",
    "# # due to the number of field sites with no basal collected data is stratified\n",
    "# out_df = df_ml[df_ml['target']>0.0]\n",
    "# samp = \"no0\"\n",
    "# out_df.to_csv(os.path.join(output, \"more_than_0kgha.csv\"))\n",
    "# out_df = df_ml[df_ml['target']>=10.0]\n",
    "# samp=\"more_t_10\"\n",
    "# out_df.to_csv(os.path.join(output, \"more_than_10kgha.csv\"))\n",
    "# \n",
    "# # create a random selection of 0 - based on sample size\n",
    "# sample_size = 3\n",
    "# no_0_df = df_ml[df_ml['target']>0.0]\n",
    "# samp = \"no0\"\n",
    "# agb_0 = df_ml[df_ml['bio_agb_kg1ha']==0.0].sample(sample_size)\n",
    "# out_df = pd.concat([no_0_df, agb_0])\n",
    "# out_df.to_csv(os.path.join(output, \"ml_df_0_sample_{0}kgha.csv\".format(str(sample_size))))\n",
    "# samp = f\"some0_{sample_size}\"\n",
    "# \n",
    "# \n",
    "# out_df =df_ml[df_ml['target'] <= 40000]\n",
    "# out_df.to_csv(os.path.join(output, \"less_than_40000kgha.csv\"))\n",
    "# samp = \"less_t_40\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.667502Z",
     "start_time": "2024-08-02T06:26:56.652990Z"
    }
   },
   "outputs": [],
   "source": [
    "test = out_df[out_df['target']>40000.0]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the dataset to run the models from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.683501Z",
     "start_time": "2024-08-02T06:26:56.668502Z"
    }
   },
   "outputs": [],
   "source": [
    "# All variables\n",
    "df_ml = out_df\n",
    "\n",
    "# select variables\n",
    "#df = select_df\n",
    "df_ml.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define if you are using all variabes or selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.699501Z",
     "start_time": "2024-08-02T06:26:56.684502Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.715502Z",
     "start_time": "2024-08-02T06:26:56.701502Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.731502Z",
     "start_time": "2024-08-02T06:26:56.717501Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.747502Z",
     "start_time": "2024-08-02T06:26:56.733502Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.811502Z",
     "start_time": "2024-08-02T06:26:56.750501Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter plots with error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.827501Z",
     "start_time": "2024-08-02T06:26:56.812502Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_ml.to_csv(, index=False)\n",
    "df_ml.to_csv(os.path.join(output, \"{0}_{1}_{2}_ml_data.csv\".format(var_, mdl, samp)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.875503Z",
     "start_time": "2024-08-02T06:26:56.828502Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.891503Z",
     "start_time": "2024-08-02T06:26:56.876504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "null_values = df_ml.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.907513Z",
     "start_time": "2024-08-02T06:26:56.892503Z"
    }
   },
   "outputs": [],
   "source": [
    "null_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.922503Z",
     "start_time": "2024-08-02T06:26:56.908503Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:26:56.937502Z",
     "start_time": "2024-08-02T06:26:56.923503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to check if a value is in scientific notation\n",
    "def is_scientific_notation(value):\n",
    "    try:\n",
    "        float_value = float(value)\n",
    "        return '{:e}'.format(float_value) == value.lower()\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Check for scientific notation in each cell\n",
    "for column in df_ml.columns:\n",
    "    for value in df_ml[column]:\n",
    "        if is_scientific_notation(str(value)):\n",
    "            print(f\"Column {column}: {value} is in scientific notation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:27:43.511703Z",
     "start_time": "2024-08-02T06:26:56.939503Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_ml\n",
    "\n",
    "def plot_with_mean_median(df, columns):\n",
    "    for col in columns:\n",
    "        plt.figure(figsize=(14, 10))\n",
    "\n",
    "        # Top-left plot: Distribution with mean and median\n",
    "        plt.subplot(2, 2, 1)\n",
    "        sns.histplot(df[col], kde=True, color='blue', bins=30)\n",
    "        \n",
    "        # Calculate mean and median\n",
    "        mean = df[col].mean()\n",
    "        median = df[col].median()\n",
    "        \n",
    "        # Plot mean and median as dashed lines\n",
    "        plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "        plt.axvline(median, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "        \n",
    "        plt.title(f'Distribution of {col}', fontsize=16)\n",
    "        plt.xlabel(col, fontsize=14)\n",
    "        plt.ylabel('Frequency', fontsize=14)\n",
    "        plt.legend(fontsize=12)\n",
    "        \n",
    "        # Top-right plot: Regression plot\n",
    "        value_x = 'target'\n",
    "        C_value_x = \"Target\"\n",
    "        value_y_loop = col\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        sns.regplot(data=df_ml, x=value_x, y=value_y_loop, line_kws={\"color\": \"red\"}, scatter_kws={'s': 50, 'alpha': 0.5, 'color': 'blue'})\n",
    "        plt.xlabel(C_value_x, fontsize=14)\n",
    "        plt.ylabel(value_y_loop, fontsize=14)\n",
    "        plt.title(f\"Regression of {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df_ml[value_x], df_ml[value_y_loop])\n",
    "\n",
    "        # Annotate the stats\n",
    "        plt.text(0.95, 0.95, f'slope: {slope:.2f}\\nintercept: {intercept:.2f}\\nr2: {r_value:.2f}\\np-value: {p_value:.2f}\\nstd err: {std_err:.2f}',\n",
    "                 transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='right', fontsize=12)\n",
    "\n",
    "        # Bottom-left plot: Residuals plot\n",
    "        plt.subplot(2, 2, 3)\n",
    "        sns.regplot(data=df_ml, x=value_x, y=value_y_loop, lowess=True, line_kws={\"color\": \"green\"}, scatter_kws={'s': 50, 'alpha': 0.5, 'color': 'blue'})\n",
    "        plt.xlabel(C_value_x, fontsize=14)\n",
    "        plt.ylabel(\"Error\", fontsize=14)\n",
    "        plt.title(f\"Residuals of Regression: {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "\n",
    "        residuals = df_ml[value_y_loop] - (slope * df_ml[value_x] + intercept)\n",
    "\n",
    "        # Compute additional residual statistics\n",
    "        mean_res = np.mean(residuals)\n",
    "        std_res = np.std(residuals)\n",
    "        rmse_res = np.sqrt(np.mean(residuals**2))\n",
    "        mae_res = np.mean(np.abs(residuals))\n",
    "        r2_res = scipy.stats.linregress(df_ml[value_x], residuals)[2]**2\n",
    "\n",
    "        # Annotate the residual stats\n",
    "        plt.text(0.95, 0.95, f'Mean: {mean_res:.2f}\\nStd: {std_res:.2f}\\nRMSE: {rmse_res:.2f}\\nMAE: {mae_res:.2f}\\nr2: {r2_res:.2f}',\n",
    "                 transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='right', fontsize=12)\n",
    "\n",
    "        # Bottom-right plot: Q-Q plot\n",
    "        plt.subplot(2, 2, 4)\n",
    "        scipy.stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "        plt.title(f\"Q-Q Plot of Residuals: {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "        \n",
    "        # Increase font size for Q-Q plot\n",
    "        plt.xlabel('Theoretical Quantiles', fontsize=14)\n",
    "        plt.ylabel('Sample Quantiles', fontsize=14)\n",
    "        plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        plt_out = os.path.join(output, \"plots\", f\"{var_}_{mdl}_{value_y_loop}_{rs}_combined_plot_tr.JPG\")\n",
    "        plt.savefig(plt_out, dpi=300)\n",
    "        plt.show()\n",
    "        print(\"plot: \", plt_out)\n",
    "        plt.close()\n",
    "\n",
    "# Assuming df_ml.columns[1:] contains the columns to be plotted\n",
    "plot_with_mean_median(df, df_ml.columns[1:])\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:28:17.129358Z",
     "start_time": "2024-08-02T06:27:43.512694Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_ml\n",
    "\n",
    "def plot_with_mean_median(df, columns):\n",
    "    for col in columns:\n",
    "        plt.figure(figsize=(14, 10))\n",
    "\n",
    "        # Top-left plot: Distribution with mean and median\n",
    "        plt.subplot(2, 2, 1)\n",
    "        sns.histplot(df[col], kde=True, color='blue', bins=30)\n",
    "        \n",
    "        # Calculate mean and median\n",
    "        mean = df[col].mean()\n",
    "        median = df[col].median()\n",
    "        \n",
    "        # Plot mean and median as dashed lines\n",
    "        plt.axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "        plt.axvline(median, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "        \n",
    "        plt.title(f'Distribution of {col}', fontsize=16)\n",
    "        plt.xlabel(col, fontsize=14)\n",
    "        plt.ylabel('Frequency', fontsize=14)\n",
    "        plt.legend(fontsize=12)\n",
    "        \n",
    "        # Top-right plot: Regression plot\n",
    "        value_x = 'target'\n",
    "        C_value_x = 'Target'\n",
    "        value_y_loop = col\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        sns.regplot(data=df_ml, x=value_x, y=value_y_loop, line_kws={\"color\": \"red\"}, scatter_kws={'s': 50, 'alpha': 0.5, 'color': 'blue'})\n",
    "        plt.xlabel(C_value_x, fontsize=14)\n",
    "        plt.ylabel(value_y_loop, fontsize=14)\n",
    "        plt.title(f\"Regression of {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(df_ml[value_x], df_ml[value_y_loop])\n",
    "\n",
    "        # Annotate the stats\n",
    "        plt.text(0.95, 0.05, f'slope: {slope:.2f}\\nintercept: {intercept:.2f}\\nr2: {r_value:.2f}\\np-value: {p_value:.2f}\\nstd err: {std_err:.2f}',\n",
    "                 transform=plt.gca().transAxes, verticalalignment='bottom', horizontalalignment='right', fontsize=12)\n",
    "\n",
    "        # Bottom-left plot: Residuals plot\n",
    "        plt.subplot(2, 2, 3)\n",
    "        sns.regplot(data=df_ml, x=value_x, y=value_y_loop, lowess=True, line_kws={\"color\": \"green\"}, scatter_kws={'s': 50, 'alpha': 0.5, 'color': 'blue'})\n",
    "        plt.xlabel(C_value_x, fontsize=14)\n",
    "        plt.ylabel(\"Error\", fontsize=14)\n",
    "        plt.title(f\"Residuals of Regression: {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "\n",
    "        residuals = df_ml[value_y_loop] - (slope * df_ml[value_x] + intercept)\n",
    "\n",
    "        # Compute additional residual statistics\n",
    "        mean_res = np.mean(residuals)\n",
    "        std_res = np.std(residuals)\n",
    "        rmse_res = np.sqrt(np.mean(residuals**2))\n",
    "        mae_res = np.mean(np.abs(residuals))\n",
    "        r2_res = scipy.stats.linregress(df_ml[value_x], residuals)[2]**2\n",
    "\n",
    "        # Annotate the residual stats\n",
    "        plt.text(0.95, 0.05, f'Mean: {mean_res:.2f}\\nStd: {std_res:.2f}\\nRMSE: {rmse_res:.2f}\\nMAE: {mae_res:.2f}\\nr2: {r2_res:.2f}',\n",
    "                 transform=plt.gca().transAxes, verticalalignment='bottom', horizontalalignment='right', fontsize=12)\n",
    "\n",
    "        # Bottom-right plot: Q-Q plot\n",
    "        plt.subplot(2, 2, 4)\n",
    "        scipy.stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "        plt.title(f\"Q-Q Plot of Residuals: {C_value_x} vs. {value_y_loop}\", fontsize=16)\n",
    "        \n",
    "        # Increase font size for Q-Q plot\n",
    "        plt.xlabel('Theoretical Quantiles', fontsize=14)\n",
    "        plt.ylabel('Sample Quantiles', fontsize=14)\n",
    "        plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot\n",
    "        plt_out = os.path.join(output, \"plots\", f\"{var_}_{mdl}_{value_y_loop}_{rs}_combined_plot_br.JPG\")\n",
    "        plt.savefig(plt_out, dpi=300)\n",
    "        #plt.show()\n",
    "        print(\"plot: \", plt_out)\n",
    "        plt.close()\n",
    "\n",
    "# Assuming df_ml.columns[1:] contains the columns to be plotted\n",
    "plot_with_mean_median(df, df_ml.columns[1:])\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split off validation test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:28:17.145079Z",
     "start_time": "2024-08-02T06:28:17.130283Z"
    }
   },
   "outputs": [],
   "source": [
    "value_x = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:28:17.160999Z",
     "start_time": "2024-08-02T06:28:17.146001Z"
    }
   },
   "outputs": [],
   "source": [
    "#select random state\n",
    "#rs = 0\n",
    "\n",
    "# randomly split data into train and test datasets, the user needs to define the variables \n",
    "xdata1 = df_ml.iloc[:, 1:].astype('float32')\n",
    "ydata1 = df_ml[[value_x]].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata = ydata2.ravel()\n",
    "#y_data_float=ydata.astype(\"float32\")\n",
    "x_validation, x_remaining, y_validation, y_remaining = train_test_split(xdata1, ydata, train_size=0.20, random_state=rs)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_remaining, y_remaining, train_size=0.70, random_state=rs)  \n",
    "print(x_validation.shape, y_validation.shape)\n",
    "print(\"remaining.....\")\n",
    "print(x_remaining.shape, y_remaining.shape)\n",
    "print(\"-\"*50)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot up Histograms for train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:28:17.740462Z",
     "start_time": "2024-08-02T06:28:17.162024Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# output = '.'  # Replace with your actual output directory\n",
    "# var_ = 'example_var'\n",
    "# mdl = 'example_model'\n",
    "# rs = 'example_run'\n",
    "\n",
    "# Create subplots: 1 row, 3 columns\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))  # Adjust figsize as needed\n",
    "\n",
    "# Define the data and titles for each subplot\n",
    "data = [y_train, y_test, y_validation]\n",
    "titles = ['Training Data Distribution', 'Testing Data Distribution', 'Validation Data Distribution']\n",
    "\n",
    "for i, (data_set, title) in enumerate(zip(data, titles)):\n",
    "    mean = np.mean(data_set)\n",
    "    median = np.median(data_set)\n",
    "    \n",
    "    # Plot histogram with seaborn\n",
    "    sns.histplot(data_set, kde=True, bins=20, ax=axs[i], color='blue', alpha=0.7)\n",
    "    \n",
    "    # Plot mean and median lines\n",
    "    axs[i].axvline(mean, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.2f}')\n",
    "    axs[i].axvline(median, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median:.2f}')\n",
    "    \n",
    "    axs[i].set_title(title, fontsize=16)\n",
    "    axs[i].set_xlabel('Target', fontsize=14)\n",
    "    axs[i].set_ylabel('Frequency', fontsize=14)\n",
    "    axs[i].legend(fontsize=12)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "out = os.path.join(output, \"plots\", f\"{var_}_{mdl}_{rs}_train_test_validation_distribution.JPG\")\n",
    "plt.savefig(out, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"saved to: \", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterise algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "if mdl == \"RFR\":\n",
    "    from sklearn.ensemble import RandomForestRegressor as rfr\n",
    "\n",
    "    # Define model\n",
    "    model = rfr()\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200, 300],\n",
    "        'max_depth': [None, 2, 3, 4, 5, 10, 20],\n",
    "        'max_features': ['auto', 'sqrt'],\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "elif mdl == \"GBR\":\n",
    "    from sklearn.ensemble import GradientBoostingRegressor as gbr\n",
    "\n",
    "    # Define model\n",
    "    model = gbr()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "        'max_depth': [3, 5, 7],\n",
    "    }\n",
    "\n",
    "elif mdl == \"ABR\":\n",
    "    from sklearn.ensemble import AdaBoostRegressor as abr\n",
    "\n",
    "    # Define model\n",
    "    model = abr()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 1.0],\n",
    "    }\n",
    "\n",
    "elif mdl == \"XGBR\":\n",
    "    from xgboost import XGBRegressor as xgboost\n",
    "\n",
    "    # Define model\n",
    "    model = xgboost()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    }\n",
    "\n",
    "elif mdl == \"KNN\":\n",
    "    from sklearn.neighbors import KNeighborsRegressor as knn\n",
    "\n",
    "    # Define model\n",
    "    model = knn()\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 10, 15],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]  # p=1 is for Manhattan distance, p=2 is for Euclidean distance\n",
    "    }\n",
    "\n",
    "else:\n",
    "    print(\"ERROR__\" * 100)\n",
    "\n",
    "# Define custom scorers for RMSE, MAE, R2\n",
    "def custom_rmse_scorer(y_true, y_pred):\n",
    "    return -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def custom_mae_scorer(y_true, y_pred):\n",
    "    return -mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def custom_r2_scorer(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)\n",
    "\n",
    "r2_scorer = make_scorer(custom_r2_scorer)\n",
    "rmse_scorer = make_scorer(custom_rmse_scorer)\n",
    "mae_scorer = make_scorer(custom_mae_scorer)\n",
    "\n",
    "# Create GridSearchCV objects\n",
    "grid_search_rmse = GridSearchCV(model, param_grid, scoring=rmse_scorer, cv=5)\n",
    "grid_search_rmse.fit(x_train, y_train)\n",
    "\n",
    "# ----------------------------- RMSE ---------------------------------\n",
    "print(mdl)\n",
    "print(\"-\" * 100)\n",
    "print(\"RMSE Best Score: \", grid_search_rmse.best_score_)\n",
    "print(\"RMSE Best Parameters: \", grid_search_rmse.best_params_)\n",
    "\n",
    "grid_search_mae = GridSearchCV(model, param_grid, scoring=mae_scorer, cv=5)\n",
    "grid_search_mae.fit(x_train, y_train)\n",
    "\n",
    "# ----------------------------- MAE ---------------------------------\n",
    "print(\"MAE Best Score: \", grid_search_mae.best_score_)\n",
    "print(\"MAE Best Parameters: \", grid_search_mae.best_params_)\n",
    "\n",
    "grid_search_r2 = GridSearchCV(model, param_grid, scoring=r2_scorer, cv=5)\n",
    "grid_search_r2.fit(x_train, y_train)\n",
    "\n",
    "# ----------------------------- R2 ---------------------------------\n",
    "print(\"R2 Best Score: \", grid_search_r2.best_score_)\n",
    "print(\"R2 Best Parameters: \", grid_search_r2.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best RMSE parameters\n",
    "#best_params = grid_search_rmse.best_params_\n",
    "best_model = grid_search_rmse.best_estimator_\n",
    "fac = \"RMSE\"\n",
    "p_out = rmse_path\n",
    "print(\"RMSE Best Score: \", grid_search_rmse.best_score_)\n",
    "print(\"RMSE Best Parameters: \", grid_search_rmse.best_params_)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:07.134084Z",
     "start_time": "2024-08-02T06:32:07.131083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get best MAE parameters\n",
    "#best_params = grid_search_rmse.best_params_\n",
    "best_model = grid_search_mae.best_estimator_\n",
    "fac = \"MAE\"\n",
    "p_out = mae_path\n",
    "print(\"MAE Best Score: \", grid_search_mae.best_score_)\n",
    "print(\"MAE Best Parameters: \", grid_search_mae.best_params_)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best r2 parameters\n",
    "#best_params = grid_search_r2.best_params_\n",
    "best_model = grid_search_r2.best_estimator_\n",
    "fac = \"r2\"\n",
    "p_out = r2_path\n",
    "print(\"r2 Best Score: \", grid_search_r2.best_score_)\n",
    "print(\"r2Best Parameters: \", grid_search_r2.best_params_)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default\n",
    "best_model = gbr()\n",
    "fac = \"DEF\"\n",
    "p_out = def_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter manualy when required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual \n",
    "#best_model = rfr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit regressor model and compute variable importance score \n",
    "\n",
    "may need to restrict the number of variables for the bar graph to be legible\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree_model = best_model.fit(X_1, y_1)\n",
    "best_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### good info on the feature importance score - http://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calculate feature importance for tree-based models\n",
    "def tree_based_feature_importance(model, x_train, cols):\n",
    "    fi = enumerate(model.feature_importances_)\n",
    "    fiResult = [(value, cols[i]) for (i, value) in fi]\n",
    "    return fiResult\n",
    "\n",
    "# Calculate permutation importance\n",
    "def permutation_feature_importance(model, x_train, y_train, cols):\n",
    "    result = permutation_importance(model, x_train, y_train, n_repeats=10, random_state=42)\n",
    "    fiResult = [(importance, cols[i]) for i, importance in enumerate(result.importances_mean)]\n",
    "    return fiResult\n",
    "\n",
    "# Plot feature importance\n",
    "def plot_feature_importance(fiResult, model_name, var_, fac, mdl, output):\n",
    "    df_band = pd.DataFrame(fiResult, columns=['importance', 'feature'])\n",
    "    df_band['importance'] = df_band['importance'].astype(float)\n",
    "    dfsort = df_band.sort_values(['importance'], ascending=[False]).head(20)  # Select top 20 features\n",
    "\n",
    "    ind = np.arange(len(dfsort))\n",
    "    width = 0.4\n",
    "\n",
    "    # Increase figure size\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Bar plot\n",
    "    ax.barh(ind, dfsort['importance'], width, color='blue')\n",
    "\n",
    "    # Adjust y-tick labels\n",
    "    wrapped_labels = [textwrap.fill(label, 20) for label in dfsort['feature']]\n",
    "    ax.set(yticks=ind, yticklabels=wrapped_labels, ylim=[-1, len(dfsort)])\n",
    "    ax.set_xlabel('Importance Score', fontsize=14)\n",
    "    ax.set_ylabel('Features', fontsize=14)\n",
    "    ax.set_title(f'Top 20 Feature Importance ({model_name})', fontsize=14)\n",
    "\n",
    "    # Reverse the order of y-axis to display highest to lowest\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out = os.path.join(output, f\"{var_}_{fac}_{mdl}_Top20_Feature_Importance_Score.JPG\")\n",
    "    plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "    plt.show()\n",
    "    print(out)\n",
    "\n",
    "    return dfsort\n",
    "\n",
    "# Feature importance\n",
    "cols = xdata1.columns\n",
    "\n",
    "if mdl in [\"rfr\", \"abr\", \"gbr\", \"xgboost\"]:\n",
    "    fiResult = tree_based_feature_importance(best_model, x_train, cols)\n",
    "else:\n",
    "    fiResult = permutation_feature_importance(best_model, x_train, y_train, cols)\n",
    "\n",
    "# Plot feature importance\n",
    "dfsort = plot_feature_importance(fiResult, mdl, var_, fac, mdl, p_out)\n",
    "\n",
    "# Generate scatter plot for model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "y_pred = best_model.predict(x_train)\n",
    "\n",
    "r2 = round(best_model.score(x_train, y_train), 2)\n",
    "mse = round(np.mean((y_train - y_pred) ** 2), 2)\n",
    "rmse = round(np.sqrt(mse), 2)\n",
    "mae = round(mean_absolute_error(y_train, y_pred), 2)\n",
    "bias = round(np.mean(y_train) - np.mean(y_pred), 2)\n",
    "\n",
    "plt.scatter(y_pred, y_train, s=70, alpha=0.5, color='blue', edgecolors='w')\n",
    "\n",
    "# Data for the 1 for 1 line\n",
    "x = [-500, 40000]\n",
    "y = [-500, 40000]\n",
    "\n",
    "# Set the limits of the axis\n",
    "plt.xlim(-500, 40000)\n",
    "plt.ylim(-500, 40000)\n",
    "\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Observed Target', fontsize=14)\n",
    "plt.xlabel('Predicted Target', fontsize=14)\n",
    "plt.title(f'Data Used in {mdl} Training', fontsize=16)\n",
    "\n",
    "# Annotate the stats in the top left corner\n",
    "plt.text(0.05, 0.95, f'r2: {r2:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}\\nn: {len(y_train)}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "\n",
    "out = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_train.JPG\")\n",
    "plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()\n",
    "\n",
    "print(\"saved to: \", out)\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\t - r2: {r2}\")\n",
    "print(f\"\\t - mse: {mse}\")\n",
    "print(f\"\\t - rmse: {rmse}\")\n",
    "print(f\"\\t - mae: {mae}\")\n",
    "print(f\"\\t - bias: {bias}\")\n",
    "print(f\"\\t - n: {len(y_train)}\")\n",
    "\n",
    "# Example metrics\n",
    "metrics_dict = {\n",
    "    'r2': r2,\n",
    "    'mse': mse,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'bias': bias,\n",
    "    'n': len(y_train)\n",
    "}\n",
    "\n",
    "# Adding the site as a key-value pair\n",
    "metrics_dict['mdl'] = mdl\n",
    "metrics_dict['status'] = \"train\"\n",
    "metrics_dict['var'] = var_\n",
    "metrics_dict['fac'] = fac\n",
    "metrics_dict['features'] = list(x_train)\n",
    "metrics_dict['model'] = best_model\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "train_metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "out_metrics = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_train_metrics.csv\")\n",
    "train_metrics_df.to_csv(out_metrics, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:15.914694Z",
     "start_time": "2024-08-02T06:32:15.652720Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_absolute_error\n",
    "import os\n",
    "\n",
    "# Evaluate and plot for the best model\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use the best estimator from the grid search\n",
    "#best_model = grid_search_r2.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y2_predict = best_model.predict(x_test)\n",
    "\n",
    "# Calculate metrics\n",
    "r2 = round(best_model.score(x_test, y_test), 2)\n",
    "mse = round(np.mean((y_test - y2_predict) ** 2), 2)\n",
    "rmse = round(np.sqrt(mse), 2)\n",
    "mae = round(mean_absolute_error(y_test, y2_predict), 2)\n",
    "bias = round(np.mean(y_test) - np.mean(y2_predict), 2)\n",
    "var = round(explained_variance_score(y_test, y2_predict), 2)\n",
    "\n",
    "# Generate scatter plot\n",
    "plt.scatter(y2_predict, y_test, s=70, alpha=0.5, color='blue', edgecolors='w')\n",
    "\n",
    "# Data for the 1 for 1 line\n",
    "x = [-500, 40000]\n",
    "y = [-500, 40000]\n",
    "\n",
    "# Set limits of the axis\n",
    "plt.xlim(-500, 40000)\n",
    "plt.ylim(-500, 40000)\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Observed Target', fontsize=14)\n",
    "plt.xlabel('Predicted Target', fontsize=14)\n",
    "plt.title(f'Data Used in {mdl} Testing', fontsize=16)\n",
    "\n",
    "# Annotate the stats in the top left corner\n",
    "plt.text(0.05, 0.95, f'r2: {r2:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}\\nn: {len(y_test)}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "\n",
    "# Save the plot\n",
    "out_plot = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_test_data.JPG\")\n",
    "plt.savefig(out_plot, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Plot: \", out_plot)\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\t - r2: {r2}\")\n",
    "print(f\"\\t - mse: {mse}\")\n",
    "print(f\"\\t - rmse: {rmse}\")\n",
    "print(f\"\\t - mae: {mae}\")\n",
    "print(f\"\\t - bias: {bias}\")\n",
    "print(f\"\\t - n: {len(y_test)}\")\n",
    "\n",
    "\n",
    "# Example metrics\n",
    "metrics_dict = {\n",
    "    'r2': r2,\n",
    "    'mse': mse,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'bias': bias,\n",
    "    'n': len(y_test)\n",
    "}\n",
    "\n",
    "# Adding the site as a key-value pair\n",
    "metrics_dict['mdl'] = mdl\n",
    "metrics_dict['status'] = \"test\"\n",
    "metrics_dict['var'] = var_\n",
    "metrics_dict['fac'] = fac\n",
    "metrics_dict['features'] = list(x_test)\n",
    "metrics_dict['model'] = best_model\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "test_metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "out_metrics = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_test_metrics.csv\")\n",
    "test_metrics_df.to_csv(out_metrics, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dfsort = dfsort.copy()\n",
    "dfsort_copy = dfsort.copy()\n",
    "#dfsort = orig_dfsort\n",
    "#dfsort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the selected model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:27.649271Z",
     "start_time": "2024-08-02T06:32:27.634141Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plot has value at the top with very small n value\n",
    "\n",
    "sel_num = 20\n",
    "df_var = dfsort.head(sel_num).copy()\n",
    "sel_out_dfsort = out_dfsort.head(sel_num).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:28.887837Z",
     "start_time": "2024-08-02T06:32:28.878561Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_var = dfsort[dfsort['n'] > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sel_out_dfsort[\"var\"] = var_\n",
    "sel_out_dfsort[\"mdl\"] = mdl\n",
    "sel_out_dfsort[\"fac\"] = fac\n",
    "sel_out_dfsort[\"sel_num\"] = sel_num\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:29.361212Z",
     "start_time": "2024-08-02T06:32:29.345930Z"
    }
   },
   "outputs": [],
   "source": [
    "df_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:29.471734Z",
     "start_time": "2024-08-02T06:32:29.457735Z"
    }
   },
   "outputs": [],
   "source": [
    "column_var = df_var.feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:29.816964Z",
     "start_time": "2024-08-02T06:32:29.802726Z"
    }
   },
   "outputs": [],
   "source": [
    "#column_var.insert(0, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:30.855285Z",
     "start_time": "2024-08-02T06:32:30.842125Z"
    }
   },
   "outputs": [],
   "source": [
    "column_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:30.870292Z",
     "start_time": "2024-08-02T06:32:30.857284Z"
    }
   },
   "outputs": [],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:31.196291Z",
     "start_time": "2024-08-02T06:32:31.188286Z"
    }
   },
   "outputs": [],
   "source": [
    "select_df = df_ml[column_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:31.558592Z",
     "start_time": "2024-08-02T06:32:31.545593Z"
    }
   },
   "outputs": [],
   "source": [
    "df_corr = select_df.corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:31.920160Z",
     "start_time": "2024-08-02T06:32:31.906154Z"
    }
   },
   "outputs": [],
   "source": [
    "#dfsort.to_csv(os.path.join(p_out, \"{0}_{1}_{2}_sel_{3}_variable_score.csv\".format(var_, fac, mdl, sel_num)))\n",
    "sel_out_dfsort.to_csv(os.path.join(p_out, \"{0}_{1}_{2}_sel_{3}_variable_score.csv\".format(var_, fac, mdl, sel_num)))\n",
    "df_corr.to_csv(os.path.join(p_out, \"{0}_{1}_{2}_sel_{3}_variable_correlation.csv\".format(var_, fac, mdl, sel_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:34.239741Z",
     "start_time": "2024-08-02T06:32:32.873243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(df_corr, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Save the plot\n",
    "plot_out = os.path.join(p_out, \"{0}_{1}_{2}_sel_{3}_variable_score.JPG\".format(var_, fac, mdl, sel_num))\n",
    "plt.savefig(plot_out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()\n",
    "print(\"Plot: \", plot_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:35.087206Z",
     "start_time": "2024-08-02T06:32:35.068205Z"
    }
   },
   "outputs": [],
   "source": [
    "select_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rerun on Selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:35.577680Z",
     "start_time": "2024-08-02T06:32:35.561494Z"
    }
   },
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test, x_validation, y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:36.017364Z",
     "start_time": "2024-08-02T06:32:36.002353Z"
    }
   },
   "outputs": [],
   "source": [
    "sel_x_train = x_train[column_var]\n",
    "sel_x_test = x_test[column_var]\n",
    "sel_x_validation = x_validation[column_var]\n",
    "sel_y_train = y_train\n",
    "sel_y_test = y_test\n",
    "sel_y_validation = y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set model with feature names for Notebook testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:40.190913Z",
     "start_time": "2024-08-02T06:32:40.174913Z"
    }
   },
   "outputs": [],
   "source": [
    "select_model = best_model.fit(sel_x_train, sel_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train model on selected paramiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "# Calculate feature importance for tree-based models\n",
    "def tree_based_feature_importance(model, x_train, cols):\n",
    "    fi = enumerate(model.feature_importances_)\n",
    "    fiResult = [(value, cols[i]) for (i, value) in fi]\n",
    "    return fiResult\n",
    "\n",
    "# Calculate permutation importance\n",
    "def permutation_feature_importance(model, x_train, y_train, cols):\n",
    "    result = permutation_importance(model, x_train, y_train, n_repeats=10, random_state=42)\n",
    "    fiResult = [(importance, cols[i]) for i, importance in enumerate(result.importances_mean)]\n",
    "    return fiResult\n",
    "\n",
    "# Plot feature importance\n",
    "def plot_feature_importance(fiResult, model_name, var_, fac, mdl, output):\n",
    "    df_band = pd.DataFrame(fiResult, columns=['importance', 'feature'])\n",
    "    df_band['importance'] = df_band['importance'].astype(float)\n",
    "    dfsort = df_band.sort_values(['importance'], ascending=[False]).head(20)  # Select top 20 features\n",
    "\n",
    "    ind = np.arange(len(dfsort))\n",
    "    width = 0.4\n",
    "\n",
    "    # Increase figure size\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Bar plot\n",
    "    ax.barh(ind, dfsort['importance'], width, color='blue')\n",
    "\n",
    "    # Adjust y-tick labels\n",
    "    wrapped_labels = [textwrap.fill(label, 16) for label in dfsort['feature']]\n",
    "    ax.set(yticks=ind, yticklabels=wrapped_labels, ylim=[-1, len(dfsort)])\n",
    "    ax.set_xlabel('Importance Score', fontsize=12)\n",
    "    ax.set_ylabel('Features', fontsize=12)\n",
    "    ax.set_title(f'Top {sel_num} Feature Importance ({mdl})', fontsize=14)\n",
    "\n",
    "    # Reverse the order of y-axis to display highest to lowest\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out = os.path.join(p_out, f\"{var_}_{fac}_{mdl}_Top_{sel_num}_Feature_Importance_Score.JPG\")\n",
    "    plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "    plt.show()\n",
    "    print(out)\n",
    "\n",
    "    return dfsort\n",
    "\n",
    "# Feature importance\n",
    "cols = xdata1.columns\n",
    "\n",
    "if isinstance(select_model, (rfr, abr, gbr)):\n",
    "    fiResult = tree_based_feature_importance(select_model, sel_x_train, cols)\n",
    "else:\n",
    "    fiResult = permutation_feature_importance(select_model, sel_x_train, sel_y_train, cols)\n",
    "\n",
    "# Plot feature importance\n",
    "dfsort = plot_feature_importance(fiResult, mdl, var_, fac, mdl, p_out)\n",
    "\n",
    "# Generate scatter plot for model predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "sel_y_pred = select_model.predict(sel_x_train)\n",
    "\n",
    "r2 = round(select_model.score(sel_x_train, sel_y_train), 2)\n",
    "mse = round(np.mean((sel_y_train - sel_y_pred) ** 2), 2)\n",
    "rmse = round(np.sqrt(mse), 2)\n",
    "mae = round(mean_absolute_error(sel_y_train, sel_y_pred), 2)\n",
    "bias = round(np.mean(sel_y_train) - np.mean(sel_y_pred), 2)\n",
    "\n",
    "plt.scatter(sel_y_pred, sel_y_train, s=70, alpha=0.5, color='blue', edgecolors='w')\n",
    "\n",
    "# Data for the 1 for 1 line\n",
    "x = [-500, 40000]\n",
    "y = [-500, 40000]\n",
    "\n",
    "# Set the limits of the axis\n",
    "plt.xlim(-500, 40000)\n",
    "plt.ylim(-500, 40000)\n",
    "\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Observed Target', fontsize=14)\n",
    "plt.xlabel('Predicted Target', fontsize=14)\n",
    "plt.title(f'Data Used in {mdl} Training', fontsize=16)\n",
    "\n",
    "# Annotate the stats in the top left corner\n",
    "plt.text(0.05, 0.95, f'r2: {r2:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}\\nn: {len(sel_y_train)}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "\n",
    "out = os.path.join(output, f\"{var_}_{mdl}_{fac}_top_{sel_num}_retrain.JPG\")\n",
    "plt.savefig(out, dpi=300)  # dpi sets the resolution in dots per inch\n",
    "plt.show()\n",
    "\n",
    "print(\"saved to: \", out)\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\t - r2: {r2}\")\n",
    "print(f\"\\t - mse: {mse}\")\n",
    "print(f\"\\t - rmse: {rmse}\")\n",
    "print(f\"\\t - mae: {mae}\")\n",
    "print(f\"\\t - bias: {bias}\")\n",
    "print(f\"\\t - n: {len(sel_y_train)}\")\n",
    "\n",
    "\n",
    "# Example metrics\n",
    "metrics_dict = {\n",
    "    'r2': r2,\n",
    "    'mse': mse,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'bias': bias,\n",
    "    'n': len(sel_y_train)\n",
    "}\n",
    "\n",
    "# Adding the site as a key-value pair\n",
    "metrics_dict['mdl'] = mdl\n",
    "metrics_dict['status'] = \"retrain\"\n",
    "metrics_dict['var'] = var_\n",
    "metrics_dict['fac'] = fac\n",
    "metrics_dict['sel_num'] = sel_num\n",
    "metrics_dict['features'] = list(sel_x_train)\n",
    "metrics_dict['model'] = select_model\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "retrain_metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "out_metrics = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_top_{sel_num}_retrain_metrics.csv\")\n",
    "retrain_metrics_df.to_csv(out_metrics, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "y2_predict = select_model.predict(sel_x_test)\n",
    "\n",
    "r2 = round(select_model.score(sel_x_test, sel_y_test), 2)\n",
    "mse = round(np.mean((sel_y_test - select_model.predict(sel_x_test)) ** 2), 2)\n",
    "rmse = round(np.sqrt(np.mean((y2_predict - sel_y_test) ** 2)), 2)\n",
    "mae = round(mean_absolute_error(sel_y_test, y2_predict), 2)\n",
    "bias = round(np.mean(sel_y_test) - np.mean(y2_predict), 2)\n",
    "var = round(explained_variance_score(sel_y_test, y2_predict), 2)\n",
    "\n",
    "plt.scatter(y2_predict, sel_y_test, s=70, alpha=0.5, color='blue', edgecolors='w')\n",
    "\n",
    "# Data for the 1 for 1 line\n",
    "x = [-500, 40000]\n",
    "y = [-500, 40000]\n",
    "\n",
    "# Set the limits of the axis\n",
    "plt.xlim(-500, 40000)\n",
    "plt.ylim(-500, 40000)\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Observed Target', fontsize=14)\n",
    "plt.xlabel('Predicted Target', fontsize=14)\n",
    "plt.title(f'Data Used in {mdl} Testing', fontsize=16)\n",
    "\n",
    "# Annotate the stats in the top left corner\n",
    "plt.text(0.05, 0.95, f'r2: {r2:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}\\nn: {len(sel_y_test)}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(output, f\"{var_}_{mdl}_{fac}_top_{sel_num}_retest.JPG\"), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\t - r2: {r2}\")\n",
    "print(f\"\\t - mse: {mse}\")\n",
    "print(f\"\\t - rmse: {rmse}\")\n",
    "print(f\"\\t - mae: {mae}\")\n",
    "print(f\"\\t - bias: {bias}\")\n",
    "print(f\"\\t - n: {len(sel_y_test)}\")\n",
    "\n",
    "\n",
    "# Example metrics\n",
    "metrics_dict = {\n",
    "    'r2': r2,\n",
    "    'mse': mse,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'bias': bias,\n",
    "    'n': len(y_test)\n",
    "}\n",
    "\n",
    "# Adding the site as a key-value pair\n",
    "metrics_dict['mdl'] = mdl\n",
    "metrics_dict['status'] = \"retest\"\n",
    "metrics_dict['var'] = var_\n",
    "metrics_dict['fac'] = fac\n",
    "metrics_dict['sel_num'] = sel_num\n",
    "metrics_dict['features'] = list(sel_x_test)\n",
    "metrics_dict['model'] = select_model\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "retest_metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "out_metrics = os.path.join(p_out, f\"{var_}_{mdl}_{fac}_top_{sel_num}_metrics_retest.csv\")\n",
    "retest_metrics_df.to_csv(out_metrics, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:46.247317Z",
     "start_time": "2024-08-02T06:32:46.237282Z"
    }
   },
   "outputs": [],
   "source": [
    "variable_imp_list = dfsort.feature.to_list()\n",
    "print(variable_imp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP - do you realy want to save this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remember to change the cPickle file name !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save current fitted model and apply to validation validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:49.624082Z",
     "start_time": "2024-08-02T06:32:49.610089Z"
    }
   },
   "outputs": [],
   "source": [
    "select_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:50.489118Z",
     "start_time": "2024-08-02T06:32:50.480442Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#rfrL8CHM = rfr()\n",
    "#rfrL8CHM.fit(sel_x_train, sel_y_train)\n",
    "pickle_file = os.path.join(output, \"{0}_{1}_{2}_sel_{3}_{4}_model.pickle\".format(var_, fac, mdl, sel_num, samp))\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(select_model, f)\n",
    "print(\"pickle saved: \", pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:50.783746Z",
     "start_time": "2024-08-02T06:32:50.754322Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in your validation dataset which has never been seen by rfr model - NOTE in this example I am just reading the same data used to train the model\n",
    "sel_y_validation\n",
    "sel_x_validation\n",
    "#validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:51.702820Z",
     "start_time": "2024-08-02T06:32:51.696526Z"
    }
   },
   "outputs": [],
   "source": [
    "c_list = sel_x_validation.columns.tolist()\n",
    "c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:52.333071Z",
     "start_time": "2024-08-02T06:32:52.318071Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_df = sel_x_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:52.349108Z",
     "start_time": "2024-08-02T06:32:52.336073Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert array as the first column\n",
    "validation_df.insert(0, 'target', sel_y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:52.723878Z",
     "start_time": "2024-08-02T06:32:52.708948Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_out = os.path.join(output, \"validation_data.csv\")\n",
    "validation_df.to_csv(validation_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:52.867433Z",
     "start_time": "2024-08-02T06:32:52.852423Z"
    }
   },
   "outputs": [],
   "source": [
    "#select_validation_df = validation_df[column_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:53.780669Z",
     "start_time": "2024-08-02T06:32:53.762664Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:54.030318Z",
     "start_time": "2024-08-02T06:32:54.019316Z"
    }
   },
   "outputs": [],
   "source": [
    "column_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:54.441449Z",
     "start_time": "2024-08-02T06:32:54.430949Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_xdata = validation_df.iloc[:, 1:].astype('float32')\n",
    "ydata1 = validation_df[[value_x]].astype('float32')\n",
    "ydata2 = ydata1.values\n",
    "ydata3 = ydata2.ravel()\n",
    "\n",
    "validation_ydata = ydata3.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:54.848131Z",
     "start_time": "2024-08-02T06:32:54.834802Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_xdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:55.182119Z",
     "start_time": "2024-08-02T06:32:55.167121Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_ydata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Load the model\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    rf = pickle.load(f)\n",
    "\n",
    "predicted = rf.predict(validation_xdata)\n",
    "\n",
    "# Calculate metrics\n",
    "r2 = round(rf.score(validation_xdata, validation_ydata), 2)\n",
    "mse = round(np.mean((validation_ydata - predicted) ** 2), 2)\n",
    "rmse = round(np.sqrt(np.mean((predicted - validation_ydata) ** 2)), 2)\n",
    "mae = round(mean_absolute_error(validation_ydata, predicted), 2)\n",
    "bias = round(np.mean(validation_ydata) - np.mean(predicted), 2)\n",
    "var = round(explained_variance_score(validation_ydata, predicted), 2)\n",
    "\n",
    "# Plot predicted vs observed data\n",
    "plt.scatter(predicted, validation_ydata, s=70, alpha=0.5, color='blue', edgecolors='w')\n",
    "\n",
    "# Data for the 1-for-1 line\n",
    "x = [-500, 40000]\n",
    "y = [-500, 40000]\n",
    "\n",
    "# Set the limits of the axis\n",
    "plt.xlim(-500, 40000)\n",
    "plt.ylim(-500, 40000)\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Observed Target', fontsize=14)\n",
    "plt.xlabel('Predicted Target', fontsize=14)\n",
    "plt.title(f'Data Used in {mdl} Validation', fontsize=16)\n",
    "\n",
    "# Annotate the stats in the top left corner\n",
    "plt.text(0.05, 0.95, f'r2: {r2:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}\\nn: {len(validation_ydata)}',\n",
    "         transform=plt.gca().transAxes, verticalalignment='top', horizontalalignment='left', fontsize=12)\n",
    "\n",
    "# 1-for-1 line\n",
    "plt.plot(x, y, color='red')\n",
    "\n",
    "# Save the plot\n",
    "output_plot = os.path.join(output, \"{0}_{1}_{2}_sel_{3}_data_validation.JPG\".format(var_, fac, mdl, str(sel_num)))\n",
    "plt.savefig(output_plot, dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"plot output: \", output_plot)\n",
    "print(\"Using: \", \"{0}_{1}_{2}_sel_{3}_model.pickle\".format(var_, fac, mdl, sel_num))\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"\\t - r2: {r2}\")\n",
    "print(f\"\\t - mse: {mse}\")\n",
    "print(f\"\\t - rmse: {rmse}\")\n",
    "print(f\"\\t - mae: {mae}\")\n",
    "print(f\"\\t - bias: {bias}\")\n",
    "print(f\"\\t - n: {len(validation_ydata)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Adding the site as a key-value pair\n",
    "metrics_dict['mdl'] = mdl\n",
    "metrics_dict['status'] = \"validate\"\n",
    "metrics_dict['var'] = var_\n",
    "metrics_dict['fac'] = fac\n",
    "metrics_dict['sel_num'] = sel_num\n",
    "metrics_dict['features'] = list(validation_df)\n",
    "metrics_dict['model'] = rf\n",
    "\n",
    "# Creating a DataFrame from the dictionary\n",
    "val_metrics_df = pd.DataFrame([metrics_dict])\n",
    "\n",
    "\n",
    "out_metrics = os.path.join(output, f\"{var_}_{mdl}_{fac}_top_{sel_num}_validate_metrics.csv\")\n",
    "val_metrics_df.to_csv(out_metrics, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:56.287966Z",
     "start_time": "2024-08-02T06:32:56.273918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the pickled model\n",
    "import pickle\n",
    "\n",
    "with open(pickle_file, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "# validation x data\n",
    "data = validation_xdata\n",
    "\n",
    "# Check the feature names used during training\n",
    "training_feature_names = model.feature_names_in_\n",
    "\n",
    "# Check the feature names in the new dataset\n",
    "new_feature_names = data.columns\n",
    "\n",
    "print(\"Training feature names:\", training_feature_names)\n",
    "print(\"New feature names:\", new_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:56.732934Z",
     "start_time": "2024-08-02T06:32:56.727934Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust to export model with no feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:56.902421Z",
     "start_time": "2024-08-02T06:32:56.882935Z"
    }
   },
   "outputs": [],
   "source": [
    "xarray = sel_x_train.to_numpy()\n",
    "yarray = sel_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:57.400147Z",
     "start_time": "2024-08-02T06:32:57.386587Z"
    }
   },
   "outputs": [],
   "source": [
    "select_tree_model_no_headers = best_model.fit(xarray, yarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export selected model as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:58.157028Z",
     "start_time": "2024-08-02T06:32:58.144029Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#rfrL8CHM = rfr()\n",
    "#rfrL8CHM.fit(sel_x_train, sel_y_train)\n",
    "pickle_file_no_headers = os.path.join(output, \"{0}_{1}_{2}_sel_{3}_{4}_model_no_headers.pickle\".format(var_, fac, mdl, sel_num, samp))\n",
    "with open(pickle_file_no_headers, 'wb') as f:\n",
    "    pickle.dump(select_tree_model_no_headers, f)\n",
    "print(\"pickle saved: \", pickle_file_no_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T06:32:59.114459Z",
     "start_time": "2024-08-02T06:32:59.098458Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
